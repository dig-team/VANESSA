{"id": "0", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is red?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Harry is kind.\nConclusion 1: Harry is red.\n\n", "ground_truth": [true], "logic_premises": "[[(4→5), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Harry is kind .", "3": "Harry is red .", "4": "Harry is kind .", "5": "Harry are red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}], "predicted_steps": [true]}
{"id": "1", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is red?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: Blue people are nice.\nPremise 1.2: Harry is not blue.\nConclusion 1: Harry is nice.\n\nPremise 2.1: If someone is nice then they are rough.\nPremise 2.2: Harry is not nice.\nConclusion 2: Harry is rough.\n\nPremise 3.1: All rough people are not red.\nPremise 3.2: Harry is rough.\nConclusion 3: Harry is red.\n\n", "ground_truth": [false, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3]", "correspondance": [{"0": "X is a Blue person .", "1": "X is nice .", "2": "Harry is not blue .", "3": "Harry is nice .", "4": "Harry is a Blue person .", "5": "Harry is nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Harry is not nice .", "3": "Harry is rough .", "4": "Harry is nice .", "5": "Harry are rough ."}, {"0": "X is a rough person .", "1": "X is not red .", "2": "Harry is rough .", "3": "Harry is red .", "4": "Harry is a rough person .", "5": "Harry is not red ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "(¬4)": ["2"]}, {"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "3": ["(¬5)"]}], "predicted_steps": [false, false, false]}
{"id": "2", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Bob is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Bob is not kind.\nConclusion 1: Bob is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Bob is red.\nConclusion 2: Bob is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Bob is smart.\nConclusion 3: Bob is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Bob is blue.\nConclusion 4: Bob is nice.\n\n", "ground_truth": [false, true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Bob is not kind .", "3": "Bob is red .", "4": "Bob is kind .", "5": "Bob are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Bob is red .", "3": "Bob is smart .", "4": "Bob is red .", "5": "Bob are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Bob is smart .", "3": "Bob is blue .", "4": "Bob is smart .", "5": "Bob are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Bob is blue .", "3": "Bob is nice .", "4": "Bob is a Blue person .", "5": "Bob is nice ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [false, true, true, true]}
{"id": "3", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Bob is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Bob is not white.\nConclusion 1: Bob is red.\n\nPremise 2.1: If someone is not red then they are not smart.\nPremise 2.2: Bob is red.\nConclusion 2: Bob is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Bob is smart.\nConclusion 3: Bob is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Bob is not blue.\nConclusion 4: Bob is nice.\n\n", "ground_truth": [false, false, true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Bob is not white .", "3": "Bob is red .", "4": "Bob is a white person .", "5": "Bob is red ."}, {"0": "X is not red .", "1": "X are not smart .", "2": "Bob is red .", "3": "Bob is smart .", "4": "Bob is not red .", "5": "Bob are not smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Bob is smart .", "3": "Bob is blue .", "4": "Bob is smart .", "5": "Bob are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Bob is not blue .", "3": "Bob is nice .", "4": "Bob is a Blue person .", "5": "Bob is nice ."}], "errors": [[]], "entailments_dict": [{"5": ["2", "3"], "3": ["2"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"5": ["3"], "(¬4)": ["2"]}], "predicted_steps": [false, false, true, false]}
{"id": "4", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Bob is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Bob is kind.\nConclusion 1: Bob is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Bob is red.\nConclusion 2: Bob is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Bob is smart.\nConclusion 3: Bob is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Bob is white.\nPremise 4.3: Bob is blue.\nConclusion 4: Bob is nice.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 3, 5]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Bob is kind .", "3": "Bob is red .", "4": "Bob is kind .", "5": "Bob are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Bob is red .", "3": "Bob is smart .", "4": "Bob is red .", "5": "Bob are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Bob is smart .", "3": "Bob is blue .", "4": "Bob is smart .", "5": "Bob are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Bob is white .", "4": "Bob is blue .", "5": "Bob is nice .", "6": "Bob is white .", "7": "Bob is blue .", "8": "Bob are nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6", "(¬4)"], "4": ["7", "(¬3)"], "8": ["5"]}], "predicted_steps": [true, true, true, "Contradiction in the premises"]}
{"id": "5", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Bob is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Bob is white.\nConclusion 1: Bob is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Bob is red.\nConclusion 2: Bob is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Bob is smart.\nConclusion 3: Bob is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Bob is white.\nPremise 4.3: Bob is blue.\nConclusion 4: Bob is nice.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 3, 5]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Bob is white .", "3": "Bob is red .", "4": "Bob is a white person .", "5": "Bob is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Bob is red .", "3": "Bob is smart .", "4": "Bob is red .", "5": "Bob are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Bob is smart .", "3": "Bob is blue .", "4": "Bob is smart .", "5": "Bob are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Bob is white .", "4": "Bob is blue .", "5": "Bob is nice .", "6": "Bob is white .", "7": "Bob is blue .", "8": "Bob are nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6", "(¬4)"], "4": ["7", "(¬3)"], "8": ["5"]}], "predicted_steps": ["Contradiction in the premises", true, true, "Contradiction in the premises"]}
{"id": "6", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is smart?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is red then they are smart.\nPremise 1.2: Harry is not red.\nConclusion 1: Harry is smart.\n\n", "ground_truth": [false], "logic_premises": "[[(4→5), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X is red .", "1": "X are smart .", "2": "Harry is not red .", "3": "Harry is smart .", "4": "Harry is red .", "5": "Harry are smart ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}], "predicted_steps": [false]}
{"id": "7", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is smart?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Harry is kind.\nConclusion 1: Harry is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Harry is not red.\nConclusion 2: Harry is smart.\n\n", "ground_truth": [true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Harry is kind .", "3": "Harry is red .", "4": "Harry is kind .", "5": "Harry are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Harry is not red .", "3": "Harry is smart .", "4": "Harry is red .", "5": "Harry are smart ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}], "predicted_steps": [true, false]}
{"id": "8", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is smart?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: Blue people are nice.\nPremise 1.2: Harry is not blue.\nConclusion 1: Harry is nice.\n\nPremise 2.1: If someone is not nice then they are not rough.\nPremise 2.2: Harry is nice.\nConclusion 2: Harry is rough.\n\nPremise 3.1: All rough people are not red.\nPremise 3.2: Harry is rough.\nConclusion 3: Harry is red.\n\nPremise 4.1: If someone is red then they are smart.\nPremise 4.2: Harry is red.\nConclusion 4: Harry is smart.\n\n", "ground_truth": [false, false, false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3]", "correspondance": [{"0": "X is a Blue person .", "1": "X is nice .", "2": "Harry is not blue .", "3": "Harry is nice .", "4": "Harry is a Blue person .", "5": "Harry is nice ."}, {"0": "X is not nice .", "1": "X are not rough .", "2": "Harry is nice .", "3": "Harry is rough .", "4": "Harry is not nice .", "5": "Harry are not rough ."}, {"0": "X is a rough person .", "1": "X is not red .", "2": "Harry is rough .", "3": "Harry is red .", "4": "Harry is a rough person .", "5": "Harry is not red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Harry is red .", "3": "Harry is smart .", "4": "Harry is red .", "5": "Harry are smart ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "(¬4)": ["2"]}, {"3": ["(¬5)", "(¬2)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [false, "Contradiction in the premises", false, true]}
{"id": "9", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is red and rough then they are nice.\nPremise 1.2: Erin is red.\nPremise 1.3: Erin is rough.\nConclusion 1: Erin is nice.\n\n", "ground_truth": [true], "logic_premises": "[[((6∧7)→8), 3, 4]]", "logic_conclusion": "[5]", "correspondance": [{"0": "X is red .", "1": "X is rough .", "2": "X are nice .", "3": "Erin is red .", "4": "Erin is rough .", "5": "Erin is nice .", "6": "Erin is red .", "7": "Erin is rough .", "8": "Erin are nice ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7", "(¬8)"], "8": ["5", "(¬4)"], "5": ["(¬4)"]}], "predicted_steps": ["Contradiction in the premises"]}
{"id": "10", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All rough people are not red.\nPremise 1.2: Erin is rough.\nConclusion 1: Erin is red.\n\nPremise 2.1: If someone is red and rough then they are nice.\nPremise 2.2: Erin is not red.\nPremise 2.3: Erin is rough.\nConclusion 2: Erin is nice.\n\n", "ground_truth": [false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5]", "correspondance": [{"0": "X is a rough person .", "1": "X is not red .", "2": "Erin is rough .", "3": "Erin is red .", "4": "Erin is a rough person .", "5": "Erin is not red ."}, {"0": "X is red .", "1": "X is rough .", "2": "X are nice .", "3": "Erin is not red .", "4": "Erin is rough .", "5": "Erin is nice .", "6": "Erin is red .", "7": "Erin is rough .", "8": "Erin are nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"4": ["7", "(¬8)"], "8": ["5", "(¬4)"], "5": ["(¬4)"], "(¬6)": ["3"], "(¬3)": ["6"]}], "predicted_steps": [false, false]}
{"id": "11", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is red then they are smart.\nPremise 1.2: Erin is red.\nConclusion 1: Erin is smart.\n\nPremise 2.1: If someone is smart then they are blue.\nPremise 2.2: Erin is smart.\nConclusion 2: Erin is blue.\n\nPremise 3.1: Blue people are nice.\nPremise 3.2: Erin is blue.\nConclusion 3: Erin is not nice.\n\n", "ground_truth": [true, true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3]", "correspondance": [{"0": "X is red .", "1": "X are smart .", "2": "Erin is red .", "3": "Erin is smart .", "4": "Erin is red .", "5": "Erin are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Erin is smart .", "3": "Erin is blue .", "4": "Erin is smart .", "5": "Erin are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Erin is blue .", "3": "Erin is not nice .", "4": "Erin is a Blue person .", "5": "Erin is nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "3": ["(¬5)"]}], "predicted_steps": [true, true, false]}
{"id": "12", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All rough people are not red.\nPremise 1.2: Erin is rough.\nConclusion 1: Erin is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Erin is red.\nConclusion 2: Erin is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Erin is smart.\nConclusion 3: Erin is blue.\n\nPremise 4.1: Blue people are not nice.\nPremise 4.2: Erin is blue.\nConclusion 4: Erin is nice.\n\n", "ground_truth": [false, true, true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3]", "correspondance": [{"0": "X is a rough person .", "1": "X is not red .", "2": "Erin is rough .", "3": "Erin is red .", "4": "Erin is a rough person .", "5": "Erin is not red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Erin is red .", "3": "Erin is smart .", "4": "Erin is red .", "5": "Erin are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Erin is smart .", "3": "Erin is blue .", "4": "Erin is smart .", "5": "Erin are blue ."}, {"0": "X is a Blue person .", "1": "X is not nice .", "2": "Erin is blue .", "3": "Erin is nice .", "4": "Erin is a Blue person .", "5": "Erin is not nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "3": ["(¬5)"]}], "predicted_steps": [false, true, true, false]}
{"id": "13", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is smart?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is not red.\nConclusion 2: Charlie is smart.\n\n", "ground_truth": [true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is not red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}], "predicted_steps": [true, false]}
{"id": "14", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is smart?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is not white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is not smart.\n\n", "ground_truth": [false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is not white .", "3": "Charlie is red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is not smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}], "errors": [[]], "entailments_dict": [{"5": ["2", "3"], "3": ["2"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "3": ["(¬5)"]}], "predicted_steps": [false, false]}
{"id": "15", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not smart?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\n", "ground_truth": [true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [true, true]}
{"id": "16", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not smart?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are not red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\n", "ground_truth": [false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is not red .", "2": "Charlie is white .", "3": "Charlie is red .", "4": "Charlie is a white person .", "5": "Charlie is not red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)", "(¬2)"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [false, true]}
{"id": "17", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is blue?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is not smart.\n\nPremise 3.1: If someone is not smart then they are not blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\n", "ground_truth": [true, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is not smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is not smart .", "1": "X are not blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is not smart .", "5": "Charlie are not blue ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}], "predicted_steps": [true, false, false]}
{"id": "18", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is blue?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is not red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\n", "ground_truth": [false, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is white .", "3": "Charlie is not red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["(¬2)"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": ["Contradiction in the premises", true, true]}
{"id": "19", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not blue?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\n", "ground_truth": [true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [true, true, true]}
{"id": "20", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not blue?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is not white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is not red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is not blue.\n\n", "ground_truth": [false, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is not white .", "3": "Charlie is red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is not red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is not blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}], "errors": [[]], "entailments_dict": [{"5": ["2", "3"], "3": ["2"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "3": ["(¬5)"]}], "predicted_steps": [false, false, false]}
{"id": "21", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is nice?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is not kind then they are not red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is not red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is not blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Charlie is not blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [false, false, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3]", "correspondance": [{"0": "X is not kind .", "1": "X are not red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is not kind .", "5": "Charlie are not red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is not red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is not blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is not blue .", "3": "Charlie is nice .", "4": "Charlie is a Blue person .", "5": "Charlie is nice ."}], "errors": [[]], "entailments_dict": [{"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "3": ["(¬5)"]}, {"5": ["3"], "(¬4)": ["2"]}], "predicted_steps": [false, false, false, false]}
{"id": "22", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is nice?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is not smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [true, false, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is white .", "3": "Charlie is red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is not smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is blue .", "3": "Charlie is nice .", "4": "Charlie is a Blue person .", "5": "Charlie is nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": ["Contradiction in the premises", false, true, true]}
{"id": "23", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is nice?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is not kind then they are not red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is not smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is not smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [false, false, false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 3, 5]", "correspondance": [{"0": "X is not kind .", "1": "X are not red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is not kind .", "5": "Charlie are not red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is not smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is not smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is white .", "4": "Charlie is blue .", "5": "Charlie is nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}], "errors": [[]], "entailments_dict": [{"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "3": ["(¬5)"]}, {"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"3": ["6", "(¬4)"], "4": ["7", "(¬3)"], "8": ["5"]}], "predicted_steps": [false, false, false, "Contradiction in the premises"]}
{"id": "24", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is nice?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is not red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [false, true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 3, 5]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is white .", "3": "Charlie is not red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is white .", "4": "Charlie is blue .", "5": "Charlie is nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["(¬2)"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6", "(¬4)"], "4": ["7", "(¬3)"], "8": ["5"]}], "predicted_steps": ["Contradiction in the premises", true, true, "Contradiction in the premises"]}
{"id": "25", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is not kind then they are not red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is not red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Charlie is not blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [false, false, true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3]", "correspondance": [{"0": "X is not kind .", "1": "X are not red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is not kind .", "5": "Charlie are not red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is not red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is not blue .", "3": "Charlie is nice .", "4": "Charlie is a Blue person .", "5": "Charlie is nice ."}], "errors": [[]], "entailments_dict": [{"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"5": ["3"], "(¬4)": ["2"]}], "predicted_steps": [false, false, true, false]}
{"id": "26", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is not smart then they are not blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [true, true, false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is white .", "3": "Charlie is red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is not smart .", "1": "X are not blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is not smart .", "5": "Charlie are not blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is blue .", "3": "Charlie is nice .", "4": "Charlie is a Blue person .", "5": "Charlie is nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": ["Contradiction in the premises", true, false, true]}
{"id": "27", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is not white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [true, true, true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 3, 5]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is not white .", "4": "Charlie is blue .", "5": "Charlie is nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"], "(¬3)": ["6"]}], "predicted_steps": [true, true, true, false]}
{"id": "28", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is not red.\n\nPremise 2.1: If someone is not red then they are not smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [false, false, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 3, 5]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is white .", "3": "Charlie is not red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is not red .", "1": "X are not smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is not red .", "5": "Charlie are not smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is white .", "4": "Charlie is blue .", "5": "Charlie is nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["(¬2)"], "3": ["(¬5)"]}, {"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6", "(¬4)"], "4": ["7", "(¬3)"], "8": ["5"]}], "predicted_steps": ["Contradiction in the premises", false, true, "Contradiction in the premises"]}
{"id": "29", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is rough?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is not red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is not smart.\n\nPremise 3.1: If someone is not smart then they are not blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Charlie is blue.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is nice then they are rough.\nPremise 5.2: Charlie is not nice.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [false, false, false, true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is not red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is not smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is not smart .", "1": "X are not blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is not smart .", "5": "Charlie are not blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is blue .", "3": "Charlie is nice .", "4": "Charlie is a Blue person .", "5": "Charlie is nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is not nice .", "3": "Charlie is rough .", "4": "Charlie is nice .", "5": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"5": ["3"], "(¬3)": ["4"], "(¬4)": ["2"], "(¬2)": ["4"]}], "predicted_steps": [false, false, false, true, true]}
{"id": "30", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is rough?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are not red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Charlie is blue.\nConclusion 4: Charlie is not nice.\n\nPremise 5.1: If someone is nice then they are rough.\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is not rough.\n\n", "ground_truth": [false, true, true, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is not red .", "2": "Charlie is white .", "3": "Charlie is red .", "4": "Charlie is a white person .", "5": "Charlie is not red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is blue .", "3": "Charlie is not nice .", "4": "Charlie is a Blue person .", "5": "Charlie is nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is nice .", "3": "Charlie is not rough .", "4": "Charlie is nice .", "5": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)", "(¬2)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "3": ["(¬5)"]}, {"2": ["4", "3", "(¬5)"], "5": ["(¬2)"], "3": ["(¬5)"]}], "predicted_steps": [false, true, true, false, "Contradiction in the premises"]}
{"id": "31", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is rough?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is not smart then they are not blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is not white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is not nice then they are not rough.\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [true, true, false, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is not smart .", "1": "X are not blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is not smart .", "5": "Charlie are not blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is not white .", "4": "Charlie is blue .", "5": "Charlie is nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}, {"0": "X is not nice .", "1": "X are not rough .", "2": "Charlie is nice .", "3": "Charlie is rough .", "4": "Charlie is not nice .", "5": "Charlie are not rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"], "(¬3)": ["6"]}, {"3": ["(¬5)", "(¬2)"], "(¬3)": ["2"], "(¬4)": ["2"], "(¬2)": ["4"]}], "predicted_steps": [true, true, false, false, "Contradiction in the premises"]}
{"id": "32", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is rough?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is not red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is not smart then they are not blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is nice then they are rough.\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [false, true, false, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is white .", "3": "Charlie is not red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is not smart .", "1": "X are not blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is not smart .", "5": "Charlie are not blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is white .", "4": "Charlie is blue .", "5": "Charlie is nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is nice .", "3": "Charlie is rough .", "4": "Charlie is nice .", "5": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["(¬2)"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"3": ["6", "(¬4)"], "4": ["7", "(¬3)"], "8": ["5"]}, {"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"], "(¬3)": ["4", "2"]}], "predicted_steps": ["Contradiction in the premises", true, false, "Contradiction in the premises", "Contradiction in the premises"]}
{"id": "33", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not rough?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is not red then they are not smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Charlie is not blue.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is nice then they are rough.\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [true, false, true, false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is not red .", "1": "X are not smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is not red .", "5": "Charlie are not smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is not blue .", "3": "Charlie is nice .", "4": "Charlie is a Blue person .", "5": "Charlie is nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is nice .", "3": "Charlie is rough .", "4": "Charlie is nice .", "5": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"5": ["3"], "(¬4)": ["2"]}, {"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"], "(¬3)": ["4", "2"]}], "predicted_steps": [true, false, true, false, "Contradiction in the premises"]}
{"id": "34", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not rough?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is not white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Charlie is blue.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is nice then they are rough.\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is not rough.\n\n", "ground_truth": [false, true, true, true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is not white .", "3": "Charlie is red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is blue .", "3": "Charlie is nice .", "4": "Charlie is a Blue person .", "5": "Charlie is nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is nice .", "3": "Charlie is not rough .", "4": "Charlie is nice .", "5": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"5": ["2", "3"], "3": ["2"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4", "3", "(¬5)"], "5": ["(¬2)"], "3": ["(¬5)"]}], "predicted_steps": [false, true, true, true, "Contradiction in the premises"]}
{"id": "35", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not rough?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is not red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is not smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is not nice.\n\nPremise 5.1: If someone is nice then they are rough.\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is not rough.\n\n", "ground_truth": [false, false, true, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is not red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is not smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is white .", "4": "Charlie is blue .", "5": "Charlie is not nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is nice .", "3": "Charlie is not rough .", "4": "Charlie is nice .", "5": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6", "(¬4)"], "4": ["7", "(¬3)"], "5": ["(¬8)"]}, {"2": ["4", "3", "(¬5)"], "5": ["(¬2)"], "3": ["(¬5)"]}], "predicted_steps": [false, false, true, "Contradiction in the premises", "Contradiction in the premises"]}
{"id": "36", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not rough?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is not red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is not smart.\n\nPremise 3.1: If someone is not smart then they are not blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is not nice.\n\nPremise 5.1: If someone is nice then they are rough.\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [false, false, false, false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is white .", "3": "Charlie is not red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is not smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is not smart .", "1": "X are not blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is not smart .", "5": "Charlie are not blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is white .", "4": "Charlie is blue .", "5": "Charlie is not nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is nice .", "3": "Charlie is rough .", "4": "Charlie is nice .", "5": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["(¬2)"], "3": ["(¬5)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["(¬5)"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"3": ["6", "(¬4)"], "4": ["7", "(¬3)"], "5": ["(¬8)"]}, {"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"], "(¬3)": ["4", "2"]}], "predicted_steps": ["Contradiction in the premises", false, false, "Contradiction in the premises", "Contradiction in the premises"]}
{"id": "37", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The cat is blue?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\n", "ground_truth": [true], "logic_premises": "[[((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}], "predicted_steps": [true]}
{"id": "38", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The bald eagle does not chase the tiger?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something is blue then it chases the tiger.\nPremise 1.2: The bald eagle is blue.\nConclusion 1: The bald eagle chases the tiger.\n\n", "ground_truth": [true], "logic_premises": "[[((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X is blue .", "1": "X chases the tiger .", "2": "The bald eagle is blue .", "3": "The bald eagle chases the tiger .", "4": "The bald eagle is blue .", "5": "The bald eagle chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}], "predicted_steps": [true]}
{"id": "39", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The cat chases the tiger?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is not blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\n", "ground_truth": [true, false], "logic_premises": "[[((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is not blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is not blue .", "5": "The cat chases the tiger .", "6": "the tiger is not blue .", "7": "the tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}], "predicted_steps": [true, false]}
{"id": "40", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The cat does not chase the tiger?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is not blue.\nConclusion 2: The cat chases the tiger.\n\n", "ground_truth": [true, false], "logic_premises": "[[((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is not blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"], "(¬6)": ["2"]}], "predicted_steps": [true, false]}
{"id": "41", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger likes the bald eagle?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 3.2: The tiger visits the cat.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\n", "ground_truth": [true, true, true], "logic_premises": "[[((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4]]", "logic_conclusion": "[3, 3, 5]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}], "predicted_steps": [true, true, "Contradiction in the premises"]}
{"id": "42", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger likes the bald eagle?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The tiger chases the mouse.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The tiger visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4]]", "logic_conclusion": "[3, 3, 3, 5]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "The tiger chases the mouse .", "3": "The tiger visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The tiger chases the mouse .", "7": "The tiger visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}], "predicted_steps": [true, true, true, "Contradiction in the premises"]}
{"id": "43", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger likes the bald eagle?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The cat chases the mouse.\nConclusion 1: The cat visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The cat visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4]]", "logic_conclusion": "[3, 3, 3, 5]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "the cat chases the mouse .", "3": "the cat visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The cat chases the mouse .", "7": "The cat visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}], "errors": [[]], "entailments_dict": [{"2": ["6", "8", "(¬5)"], "5": ["2"], "7": ["3"], "9": ["3"]}, {"2": ["6"], "7": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["7", "8"], "4": ["1"], "2": ["5"]}], "predicted_steps": [true, true, true, true]}
{"id": "44", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not like the bald eagle?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is not blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 3.2: The tiger visits the cat.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\n", "ground_truth": [false, true, true], "logic_premises": "[[((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4]]", "logic_conclusion": "[3, 3, 5]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is not blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "3": ["(¬7)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}], "predicted_steps": [false, true, "Contradiction in the premises"]}
{"id": "45", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not like the bald eagle?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The tiger chases the mouse.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The tiger visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4]]", "logic_conclusion": "[3, 3, 3, 5]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "The tiger chases the mouse .", "3": "The tiger visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The tiger chases the mouse .", "7": "The tiger visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}], "predicted_steps": [true, true, true, "Contradiction in the premises"]}
{"id": "46", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not like the bald eagle?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The cat chases the mouse.\nConclusion 1: The cat visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is not blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The cat visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\n", "ground_truth": [true, false, true, true], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4]]", "logic_conclusion": "[3, 3, 3, 5]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "the cat chases the mouse .", "3": "the cat visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The cat chases the mouse .", "7": "The cat visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is not blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is not blue .", "6": "The cat likes the bald eagle .", "7": "The cat is not blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}], "errors": [[]], "entailments_dict": [{"2": ["6", "8", "(¬5)"], "5": ["2"], "7": ["3"], "9": ["3"]}, {"2": ["6"], "3": ["(¬7)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["7", "8"], "4": ["1"], "2": ["5"]}], "predicted_steps": [true, false, true, true]}
{"id": "47", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is blue?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 3.2: The tiger visits the cat.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\nPremise 4.1: If something likes the bald eagle then it is blue.\nPremise 4.2: The tiger likes the bald eagle.\nConclusion 4: The tiger is blue.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 5, 3]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}, {"2": ["6"], "7": ["3"]}], "predicted_steps": [true, true, "Contradiction in the premises", true]}
{"id": "48", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is blue?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The tiger chases the mouse.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is not blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is not blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The tiger visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is not blue.\n\n", "ground_truth": [true, false, false, true, false], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "The tiger chases the mouse .", "3": "The tiger visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The tiger chases the mouse .", "7": "The tiger visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is not blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is not blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is not blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["6"], "3": ["(¬7)"]}, {"5": ["3"], "(¬6)": ["2"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}, {"2": ["6"], "3": ["(¬7)"]}], "predicted_steps": [true, false, false, "Contradiction in the premises", false]}
{"id": "49", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is blue?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The cat chases the mouse.\nConclusion 1: The cat visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The cat visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is blue.\n\n", "ground_truth": [true, true, true, true, true], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "the cat chases the mouse .", "3": "the cat visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The cat chases the mouse .", "7": "The cat visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}], "errors": [[]], "entailments_dict": [{"2": ["6", "8", "(¬5)"], "5": ["2"], "7": ["3"], "9": ["3"]}, {"2": ["6"], "7": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["7", "8"], "4": ["1"], "2": ["5"]}, {"2": ["6"], "7": ["3"]}], "predicted_steps": [true, true, true, true, true]}
{"id": "50", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is not blue?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 3.2: The tiger visits the cat.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\nPremise 4.1: If something likes the bald eagle then it is blue.\nPremise 4.2: The tiger likes the bald eagle.\nConclusion 4: The tiger is blue.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 5, 3]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}, {"2": ["6"], "7": ["3"]}], "predicted_steps": [true, true, "Contradiction in the premises", true]}
{"id": "51", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is not blue?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The tiger chases the mouse.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is not blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The tiger visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is blue.\n\n", "ground_truth": [true, false, true, true, true], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "The tiger chases the mouse .", "3": "The tiger visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The tiger chases the mouse .", "7": "The tiger visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is not blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is not blue .", "6": "The cat likes the bald eagle .", "7": "The cat is not blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["6"], "3": ["(¬7)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}, {"2": ["6"], "7": ["3"]}], "predicted_steps": [true, false, true, "Contradiction in the premises", true]}
{"id": "52", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is not blue?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The cat chases the mouse.\nConclusion 1: The cat visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The cat visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is blue.\n\n", "ground_truth": [true, true, true, true, true], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "the cat chases the mouse .", "3": "the cat visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The cat chases the mouse .", "7": "The cat visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}], "errors": [[]], "entailments_dict": [{"2": ["6", "8", "(¬5)"], "5": ["2"], "7": ["3"], "9": ["3"]}, {"2": ["6"], "7": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["7", "8"], "4": ["1"], "2": ["5"]}, {"2": ["6"], "7": ["3"]}], "predicted_steps": [true, true, true, true, true]}
{"id": "53", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger chases the tiger?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 3.2: The tiger visits the cat.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\nPremise 4.1: If something likes the bald eagle then it is blue.\nPremise 4.2: The tiger likes the bald eagle.\nConclusion 4: The tiger is blue.\n\nPremise 5.1: If something is blue then it chases the tiger.\nPremise 5.2: The tiger is blue.\nConclusion 5: The tiger chases the tiger.\n\n", "ground_truth": [true, true, true, true, true], "logic_premises": "[[((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 5, 3, 3]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "the tiger is blue .", "3": "the tiger chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The tiger is blue .", "7": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}, {"2": ["6"], "7": ["3"]}, {"2": ["4", "6"], "7": ["3"], "5": ["3"]}], "predicted_steps": [true, true, "Contradiction in the premises", true, true]}
{"id": "54", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger chases the tiger?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The tiger chases the mouse.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The tiger visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is not blue.\n\nPremise 6.1: If something is blue then it chases the tiger.\nPremise 6.2: The tiger is blue.\nConclusion 6: The tiger chases the tiger.\n\n", "ground_truth": [true, true, true, true, false, true], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3, 3]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "The tiger chases the mouse .", "3": "The tiger visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The tiger chases the mouse .", "7": "The tiger visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is not blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "the tiger is blue .", "3": "the tiger chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The tiger is blue .", "7": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}, {"2": ["6"], "3": ["(¬7)"]}, {"2": ["4", "6"], "7": ["3"], "5": ["3"]}], "predicted_steps": [true, true, true, "Contradiction in the premises", false, true]}
{"id": "55", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger chases the tiger?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The cat chases the mouse.\nConclusion 1: The cat visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is not blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The cat visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is blue.\n\nPremise 6.1: If something is not blue then it chases the tiger.\nPremise 6.2: The tiger is blue.\nConclusion 6: The tiger chases the tiger.\n\n", "ground_truth": [true, true, false, true, true, false], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3, 3]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "the cat chases the mouse .", "3": "the cat visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The cat chases the mouse .", "7": "The cat visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is not blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}, {"0": "X is not blue .", "1": "X chases the tiger .", "2": "the tiger is blue .", "3": "the tiger chases the tiger .", "4": "the tiger is not blue .", "5": "the tiger chases the tiger .", "6": "The tiger is not blue .", "7": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6", "8", "(¬5)"], "5": ["2"], "7": ["3"], "9": ["3"]}, {"2": ["6"], "7": ["3"]}, {"5": ["3"], "(¬6)": ["2"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"3": ["7", "8"], "4": ["1"], "2": ["5"]}, {"2": ["6"], "7": ["3"]}, {"7": ["3"], "5": ["3"], "(¬4)": ["2"], "(¬2)": ["4", "6"], "(¬6)": ["2"]}], "predicted_steps": [true, true, false, true, true, false]}
{"id": "56", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not chase the tiger?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is not blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 3.2: The tiger visits the cat.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\nPremise 4.1: If something likes the bald eagle then it is blue.\nPremise 4.2: The tiger likes the bald eagle.\nConclusion 4: The tiger is not blue.\n\nPremise 5.1: If something is blue then it chases the tiger.\nPremise 5.2: The tiger is blue.\nConclusion 5: The tiger chases the tiger.\n\n", "ground_truth": [false, true, true, false, true], "logic_premises": "[[((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 5, 3, 3]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is not blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is not blue .", "6": "The cat likes the bald eagle .", "7": "The cat is not blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is not blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "the tiger is blue .", "3": "the tiger chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The tiger is blue .", "7": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "3": ["(¬7)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}, {"2": ["6"], "3": ["(¬7)"]}, {"2": ["4", "6"], "7": ["3"], "5": ["3"]}], "predicted_steps": [false, true, "Contradiction in the premises", false, true]}
{"id": "57", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not chase the tiger?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The tiger chases the mouse.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is not blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is not blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The tiger visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is blue.\n\nPremise 6.1: If something is blue then it chases the tiger.\nPremise 6.2: The tiger is blue.\nConclusion 6: The tiger chases the tiger.\n\n", "ground_truth": [true, false, false, true, true, true], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3, 3]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "The tiger chases the mouse .", "3": "The tiger visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The tiger chases the mouse .", "7": "The tiger visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is not blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is not blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "the tiger is blue .", "3": "the tiger chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The tiger is blue .", "7": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["6"], "3": ["(¬7)"]}, {"5": ["3"], "(¬6)": ["2"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"4": ["1", "(¬3)"], "3": ["a", "9", "(¬4)"], "2": ["5"]}, {"2": ["6"], "7": ["3"]}, {"2": ["4", "6"], "7": ["3"], "5": ["3"]}], "predicted_steps": [true, false, false, "Contradiction in the premises", true, true]}
{"id": "58", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not chase the tiger?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The cat chases the mouse.\nConclusion 1: The cat visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is not blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The cat visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is blue.\n\nPremise 6.1: If something is blue then it chases the tiger.\nPremise 6.2: The tiger is blue.\nConclusion 6: The tiger chases the tiger.\n\n", "ground_truth": [true, false, true, true, true, true], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 3, 5, 3, 3]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "the cat chases the mouse .", "3": "the cat visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The cat chases the mouse .", "7": "The cat visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is not blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is not blue .", "6": "The cat likes the bald eagle .", "7": "The cat is not blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "The cat is blue .", "5": "The cat chases the tiger .", "6": "the tiger is blue .", "7": "the tiger chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the bald eagle visits the cat .", "7": "The cat visits the cat .", "8": "the cat visits the cat .", "9": "The tiger visits the cat .", "a": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "the tiger is blue .", "3": "the tiger chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The tiger is blue .", "7": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6", "8", "(¬5)"], "5": ["2"], "7": ["3"], "9": ["3"]}, {"2": ["6"], "3": ["(¬7)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["7", "8"], "4": ["1"], "2": ["5"]}, {"2": ["6"], "7": ["3"]}, {"2": ["4", "6"], "7": ["3"], "5": ["3"]}], "predicted_steps": [true, false, true, true, true, true]}
{"id": "59", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: Kind, big things are not red.\nPremise 1.2: Charlie is kind.\nPremise 1.3: Charlie is big.\nConclusion 1: Charlie is red.\n\n", "ground_truth": [false], "logic_premises": "[[((6∧7)→8), 3, 4]]", "logic_conclusion": "[5]", "correspondance": [{"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [false]}
{"id": "60", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: Kind things are big.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is big.\n\nPremise 2.1: Kind, big things are red.\nPremise 2.2: Charlie is kind.\nPremise 2.3: Charlie is big.\nConclusion 2: Charlie is not red.\n\n", "ground_truth": [true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5]", "correspondance": [{"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is not red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, false]}
{"id": "61", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is not cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: Kind, big things are red.\nPremise 2.2: Charlie is kind.\nPremise 2.3: Charlie is big.\nConclusion 2: Charlie is red.\n\n", "ground_truth": [false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, true]}
{"id": "62", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is not kind.\n\nPremise 2.1: Kind things are not big.\nPremise 2.2: Charlie is kind.\nConclusion 2: Charlie is big.\n\nPremise 3.1: Kind, big things are red.\nPremise 3.2: Charlie is kind.\nPremise 3.3: Charlie is big.\nConclusion 3: Charlie is red.\n\n", "ground_truth": [false, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, false, true]}
{"id": "63", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: Kind things are big.\nPremise 2.2: Charlie is kind.\nConclusion 2: Charlie is not big.\n\nPremise 3.1: Kind, big things are not red.\nPremise 3.2: Charlie is kind.\nPremise 3.3: Charlie is big.\nConclusion 3: Charlie is red.\n\n", "ground_truth": [true, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is not big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, false, false]}
{"id": "64", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are not kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind, big things are red.\nPremise 3.2: Charlie is kind.\nPremise 3.3: Charlie is big.\nConclusion 3: Charlie is red.\n\n", "ground_truth": [true, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, false, true]}
{"id": "65", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is not kind.\n\nPremise 3.1: Kind, big things are red.\nPremise 3.2: Charlie is kind.\nPremise 3.3: Charlie is big.\nConclusion 3: Charlie is not red.\n\n", "ground_truth": [true, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is not red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, false, false]}
{"id": "66", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is not smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is not kind.\n\nPremise 3.1: Kind, big things are red.\nPremise 3.2: Charlie is kind.\nPremise 3.3: Charlie is big.\nConclusion 3: Charlie is red.\n\n", "ground_truth": [false, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is not smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, false, true]}
{"id": "67", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are not big.\nPremise 3.2: Charlie is kind.\nConclusion 3: Charlie is big.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is not red.\n\n", "ground_truth": [true, true, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is not red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, true, false, false]}
{"id": "68", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are big.\nPremise 3.2: Charlie is kind.\nConclusion 3: Charlie is big.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, true, true, true]}
{"id": "69", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are not kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are big.\nPremise 3.2: Charlie is kind.\nConclusion 3: Charlie is not big.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is not big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, false, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is not big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [true, false, false, false]}
{"id": "70", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, true, true, true]}
{"id": "71", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is not cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are big.\nPremise 3.2: Charlie is kind.\nConclusion 3: Charlie is big.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, false, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, false, true, true]}
{"id": "72", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is not kind.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is not kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}], "predicted_steps": [true, true, true, false]}
{"id": "73", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is not cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is not cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is not smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is not kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, false, false, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is not kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}], "predicted_steps": [false, false, false, true, false]}
{"id": "74", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are not red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [true, true, true, true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, true, true, true, false]}
{"id": "75", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is not quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are not smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is not cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is not kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is not big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, false, false, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is not kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [false, false, false, false, false]}
{"id": "76", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is not smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are not big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are not red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [true, true, false, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, true, false, false, false]}
{"id": "77", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [true, true, true, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, true, true, true, true]}
{"id": "78", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is not kind.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is not red.\n\n", "ground_truth": [false, true, false, true, true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is not red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [false, true, false, true, true, false]}
{"id": "79", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All cold, quiet things are not smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is not smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are not big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is not kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [false, false, true, false, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is not cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is not kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"2": ["4"], "3": ["(¬5)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}], "predicted_steps": [false, false, true, false, false, false]}
{"id": "80", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are big.\nPremise 3.2: Charlie is kind.\nConclusion 3: Charlie is big.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is not big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [true, true, true, false]}
{"id": "81", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are not cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are not kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are big.\nPremise 3.2: Charlie is kind.\nConclusion 3: Charlie is big.\n\nPremise 4.1: Kind, big things are not red.\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [false, false, true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [false, false, true, false]}
{"id": "82", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is not big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [true, true, true, false]}
{"id": "83", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is not kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, true, true, false, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is not kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, true, true, false, true]}
{"id": "84", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is not kind.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are not red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, true, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [false, true, true, true, false]}
{"id": "85", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is not cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are not red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [true, true, false, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, true, false, true, false]}
{"id": "86", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is not smart.\n\nPremise 3.1: All cold, smart things are not kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is not big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is not big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, false, false, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is not smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is not big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [false, false, false, false, false]}
{"id": "87", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is not quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [true, true, false, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is not quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, true, false, true, true]}
{"id": "88", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is not cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are not kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [true, true, false, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5, 5, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, true, false, false, true]}
{"id": "89", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is not cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is not smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are not big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, false, true, false, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, false, true, false, false, true]}
{"id": "90", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is not smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, false, true, true, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, false, true, true, true, true]}
{"id": "91", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is not cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is not kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is not quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is not big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [false, false, false, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [false, false, false, true, true, false]}
{"id": "92", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is not quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is not smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All cold, smart things are not kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is not kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are not red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [false, true, false, false, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is not kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [false, true, false, false, false, false]}
{"id": "93", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are not kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is not quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is not cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is not big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is not big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, false, false, false, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is not quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is not big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [true, false, false, false, false, false]}
{"id": "94", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are not cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, smart things are not kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are not big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [false, true, true, false, false, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 3, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, true, true, false, false, true]}
{"id": "95", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is not quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is not quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is not quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is not kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [false, false, false, false, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is not quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "(¬4)": ["2"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, false, false, false, true, true]}
{"id": "96", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is not kind.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is not cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are not kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, false, false, false, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, false, false, false, true, true]}
{"id": "97", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is not cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is not cold.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is not red.\n\n", "ground_truth": [false, false, false, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is not cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is not red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [false, false, false, true, true, false]}
{"id": "98", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are not smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is not big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, true, false, true, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is not big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, true, false, true, false, true]}
{"id": "99", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is not smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is not kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is not big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is not big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, false, true, true, true, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is not smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is not big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [false, false, true, true, true, false, false]}
{"id": "100", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are not cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is not cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is not quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are not big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, true, false, false, true, false, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is not quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, true, false, false, true, false, true]}
{"id": "101", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is not smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is not big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, false, true, true, true, false, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is not smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is not big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, false, true, true, true, false, true]}
{"id": "102", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is not smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are not big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is not big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, true, true, true, false, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [true, true, true, true, false, false, false]}
{"id": "103", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is not quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is not smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are not big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, false, false, true, true, false, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is not quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, false, false, true, true, false, true]}
{"id": "104", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is not quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is not cold.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is not kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is not big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, false, true, false, true, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is not quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is not kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [true, false, true, false, true, false, false]}
{"id": "105", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All quiet things are not cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is not smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is not kind.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, false, false, false, true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is not smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, false, false, false, true, true, true]}
{"id": "106", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is not smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is not smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are not red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, false, true, false, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is not smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, false, true, false, true, true, false]}
{"id": "107", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is not smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are not smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are not kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is not red.\n\n", "ground_truth": [false, false, true, true, false, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is not smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is not red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [false, false, true, true, false, true, false]}
{"id": "108", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are not kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is not cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, true, false, true, false, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 3, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, true, false, true, false, true, true]}
{"id": "109", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is not cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is not smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are not big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is not big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, true, false, false, true, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is not cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [false, true, false, false, true, false, false]}
{"id": "110", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is not smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is not smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is not big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, false, true, true, true, false, true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is not smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [true, false, true, true, true, false, true, false]}
{"id": "111", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is not kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is not quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is not smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is not smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is not big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is not red.\n\n", "ground_truth": [true, true, false, false, false, false, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is not smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is not big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is not red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, true, false, false, false, false, false, false]}
{"id": "112", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are not cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are not kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are not kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is not kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are not red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, false, true, false, true, false, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is not kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, false, true, false, true, false, false, false]}
{"id": "113", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is not cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is not kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is not kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [false, true, false, true, true, false, false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 3, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is not kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, true, false, true, true, false, false, true]}
{"id": "114", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is not big and smart then it is not cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are not kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is not quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is not smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is not kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are not red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [false, true, false, false, false, true, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is not big .", "1": "X is not smart .", "2": "X is not cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is not big .", "7": "Charlie is not smart .", "8": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is not smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is not kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"5": ["(¬8)"], "(¬6)": ["3"], "(¬3)": ["6"], "(¬7)": ["4"], "(¬4)": ["7"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [false, true, false, false, false, true, false, false]}
{"id": "115", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is not big and smart then it is not cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is not quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are not kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is not kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [false, false, true, true, true, false, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5, 5, 5, 5, 3, 5]", "correspondance": [{"0": "X is not big .", "1": "X is not smart .", "2": "X is not cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is not big .", "7": "Charlie is not smart .", "8": "Charlie is not cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is not kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"5": ["(¬8)"], "(¬6)": ["3"], "(¬3)": ["6"], "(¬7)": ["4"], "(¬4)": ["7"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, false, true, true, true, false, false, true]}
{"id": "116", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is not cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is not cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, false, false, true, true, true, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5, 5, 3, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, false, false, true, true, true, true, true]}
{"id": "117", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are not cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is not quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is not smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, quiet things are smart.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.1: Kind things are not big.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are red.\nPremise 9.2: Charlie is kind.\nPremise 9.3: Charlie is not big.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [false, true, false, false, true, true, true, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is not quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [false, true, false, false, true, true, true, false, false]}
{"id": "118", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is not quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, quiet things are smart.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.1: Kind things are big.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are not red.\nPremise 9.2: Charlie is kind.\nPremise 9.3: Charlie is big.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [true, true, true, true, false, true, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, true, true, true, false, true, true, true, false]}
{"id": "119", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are not smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is not smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [true, false, false, true, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is not smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, false, false, true, true]}
{"id": "120", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [false, true, true, true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, true, true, true, true, true]}
{"id": "121", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is not big.\n\nPremise 6.1: Kind, big things are not red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, true, true, true, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is not big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, true, true, true, false, false]}
{"id": "122", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is not quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are not smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is not kind.\n\nPremise 6.1: Kind things are not big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is not kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, false, true, false, false, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is not kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"5": ["3"], "(¬4)": ["2"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}], "predicted_steps": [true, false, true, false, false, false, false]}
{"id": "123", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is not smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is not cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is not cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is not cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, false, true, false, false, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is not smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, false, true, false, false, true, true]}
{"id": "124", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is not cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, true, true, false, true, true, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, true, true, false, true, true, true]}
{"id": "125", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is not big and smart then it is not cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are not cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is not cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, true, false, false, true, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is not big .", "1": "X is not smart .", "2": "X is not cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is not big .", "7": "Charlie is not smart .", "8": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"5": ["(¬8)"], "(¬6)": ["3"], "(¬3)": ["6"], "(¬7)": ["4"], "(¬4)": ["7"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, true, false, false, true, true, true]}
{"id": "126", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is not cold.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is not big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, true, false, true, true, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [true, true, false, true, true, true, true, false]}
{"id": "127", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are not cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is not quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is not cold.\n\nPremise 5.1: All cold, quiet things are not smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is not cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [false, false, true, false, false, false, true, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is not quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, false, true, false, false, false, true, true]}
{"id": "128", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are not cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is not cold.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are not big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [false, true, false, true, true, true, false, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, true, false, true, true, true, false, true]}
{"id": "129", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are not smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is not cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is not cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is not cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, false, true, false, false, false, true, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, false, true, false, false, false, true, true]}
{"id": "130", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is not kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is not kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, false, true, true, true, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is not kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}], "predicted_steps": [true, false, true, true, true, true, true, false]}
{"id": "131", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are not smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are not kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are not red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, true, true, true, false, false, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is not red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is not red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, true, true, true, false, false, true, false]}
{"id": "132", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is not quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is not cold.\n\nPremise 6.1: All cold, quiet things are smart.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.1: Kind things are big.\nPremise 8.2: Charlie is not kind.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are red.\nPremise 9.2: Charlie is not kind.\nPremise 9.3: Charlie is big.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [false, true, true, false, false, true, true, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is not kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is not kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"5": ["3"], "(¬4)": ["2"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"5": ["3"], "(¬4)": ["2"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}], "predicted_steps": [false, true, true, false, false, true, true, false, false]}
{"id": "133", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All cold, quiet things are not smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are not kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is not cold.\n\nPremise 6.1: All cold, quiet things are smart.\nPremise 6.2: Charlie is not cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is not kind.\n\nPremise 8.1: Kind things are not big.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are red.\nPremise 9.2: Charlie is not kind.\nPremise 9.3: Charlie is big.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [false, false, false, true, false, false, false, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is not kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is not cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is not kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "3": ["(¬5)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}], "predicted_steps": [false, false, false, true, false, false, false, false, false]}
{"id": "134", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are not cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is not quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is not smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is not kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, quiet things are smart.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is not quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.1: Kind things are not big.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are red.\nPremise 9.2: Charlie is kind.\nPremise 9.3: Charlie is big.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [false, false, false, false, true, false, true, false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is not smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is not quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, false, false, false, true, false, true, false, true]}
{"id": "135", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is not big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is not kind.\n\nPremise 4.1: All quiet things are not cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All quiet things are not cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, quiet things are not smart.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.2: Charlie is not cold.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.1: Kind things are big.\nPremise 8.2: Charlie is not kind.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are red.\nPremise 9.2: Charlie is kind.\nPremise 9.3: Charlie is not big.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [false, true, false, false, false, false, false, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 5, 3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is not big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is not kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "8": ["5"], "(¬6)": ["3"], "(¬3)": ["6"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [false, true, false, false, false, false, false, false, false]}
{"id": "136", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is not cold.\n\nPremise 2.1: All quiet things are not cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is not smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is not kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is not cold.\n\nPremise 6.1: All cold, quiet things are not smart.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.1: Kind things are big.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are red.\nPremise 9.2: Charlie is kind.\nPremise 9.3: Charlie is not big.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [false, false, false, false, false, false, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5, 5, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is not cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is not smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is not cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is not smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is not big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"], "(¬4)": ["7"]}], "predicted_steps": [false, false, false, false, false, false, true, true, false]}
{"id": "137", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is not cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All quiet things are not cold.\nPremise 6.2: Charlie is quiet.\nConclusion 6: Charlie is cold.\n\nPremise 7.1: All cold, quiet things are smart.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is quiet.\nConclusion 7: Charlie is smart.\n\nPremise 8.1: All cold, smart things are kind.\nPremise 8.2: Charlie is cold.\nPremise 8.3: Charlie is smart.\nConclusion 8: Charlie is not kind.\n\nPremise 9.1: Kind things are not big.\nPremise 9.2: Charlie is kind.\nConclusion 9: Charlie is big.\n\nPremise 10.1: Kind, big things are red.\nPremise 10.2: Charlie is kind.\nPremise 10.3: Charlie is big.\nConclusion 10: Charlie is not red.\n\n", "ground_truth": [true, true, true, false, true, false, true, false, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is not cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is not kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is not red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, true, true, false, true, false, true, false, false, false]}
{"id": "138", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is not quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is not cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All quiet things are cold.\nPremise 6.2: Charlie is not quiet.\nConclusion 6: Charlie is cold.\n\nPremise 7.1: All cold, quiet things are smart.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is quiet.\nConclusion 7: Charlie is smart.\n\nPremise 8.1: All cold, smart things are kind.\nPremise 8.2: Charlie is cold.\nPremise 8.3: Charlie is smart.\nConclusion 8: Charlie is kind.\n\nPremise 9.1: Kind things are not big.\nPremise 9.2: Charlie is kind.\nConclusion 9: Charlie is big.\n\nPremise 10.1: Kind, big things are red.\nPremise 10.2: Charlie is kind.\nPremise 10.3: Charlie is big.\nConclusion 10: Charlie is red.\n\n", "ground_truth": [true, true, false, false, true, false, true, true, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 5, 5, 3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is not quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is not cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is not quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is not big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is not big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "8": ["5"], "(¬7)": ["4"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"2": ["4"], "5": ["3"]}, {"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, true, false, false, true, false, true, true, false, true]}
{"id": "139", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is big?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: Kind things are not big.\nPremise 1.2: Erin is kind.\nConclusion 1: Erin is big.\n\n", "ground_truth": [false], "logic_premises": "[[(4→5), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X is a Kind thing .", "1": "X is not big .", "2": "Erin is kind .", "3": "Erin is big .", "4": "Erin is a Kind thing .", "5": "Erin is not big ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}], "predicted_steps": [false]}
{"id": "140", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is not cold?", "ground truth": "No", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Fiona is not quiet.\nConclusion 1: Fiona is cold.\n\n", "ground_truth": [false], "logic_premises": "[[(4→5), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is not quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}], "predicted_steps": [false]}
{"id": "141", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is smart?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Fiona is quiet.\nConclusion 1: Fiona is cold.\n\nPremise 2.1: All cold, quiet things are not smart.\nPremise 2.2: Fiona is cold.\nPremise 2.3: Fiona is quiet.\nConclusion 2: Fiona is smart.\n\n", "ground_truth": [true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is not smart .", "3": "Fiona is cold .", "4": "Fiona is quiet .", "5": "Fiona is smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is not smart ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}], "predicted_steps": [true, false]}
{"id": "142", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is not red?", "ground truth": "No", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: Kind things are big.\nPremise 1.2: Harry is kind.\nConclusion 1: Harry is big.\n\nPremise 2.1: Kind, big things are red.\nPremise 2.2: Harry is kind.\nPremise 2.3: Harry is big.\nConclusion 2: Harry is red.\n\n", "ground_truth": [true, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5]", "correspondance": [{"0": "X is a Kind thing .", "1": "X is big .", "2": "Harry is kind .", "3": "Harry is big .", "4": "Harry is a Kind thing .", "5": "Harry is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Harry is kind .", "4": "Harry is big .", "5": "Harry is red .", "6": "Harry is a Kind thing .", "7": "Harry is a big thing .", "8": "Harry is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, true]}
{"id": "143", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is kind?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Fiona is not quiet.\nConclusion 1: Fiona is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Fiona is quiet.\nConclusion 2: Fiona is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Fiona is cold.\nPremise 3.3: Fiona is quiet.\nConclusion 3: Fiona is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Fiona is cold.\nPremise 4.3: Fiona is smart.\nConclusion 4: Fiona is kind.\n\n", "ground_truth": [false, true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is not quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is cold .", "4": "Fiona is quiet .", "5": "Fiona is smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Fiona is cold .", "4": "Fiona is smart .", "5": "Fiona is kind .", "6": "Fiona is a cold thing .", "7": "Fiona is a smart thing .", "8": "Fiona is kind ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [false, true, true, true]}
{"id": "144", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is not cold?", "ground truth": "No", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: Kind things are big.\nPremise 1.2: Erin is not kind.\nConclusion 1: Erin is big.\n\nPremise 2.1: Kind, big things are red.\nPremise 2.2: Erin is kind.\nPremise 2.3: Erin is big.\nConclusion 2: Erin is red.\n\nPremise 3.1: All red things are cold.\nPremise 3.2: Erin is red.\nConclusion 3: Erin is not cold.\n\n", "ground_truth": [false, true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2]]", "logic_conclusion": "[3, 5, 3]", "correspondance": [{"0": "X is a Kind thing .", "1": "X is big .", "2": "Erin is not kind .", "3": "Erin is big .", "4": "Erin is a Kind thing .", "5": "Erin is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Erin is kind .", "4": "Erin is big .", "5": "Erin is red .", "6": "Erin is a Kind thing .", "7": "Erin is a big thing .", "8": "Erin is red ."}, {"0": "X is a red thing .", "1": "X is cold .", "2": "Erin is red .", "3": "Erin is not cold .", "4": "Erin is a red thing .", "5": "Erin is cold ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "(¬4)": ["2"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "3": ["(¬5)"]}], "predicted_steps": [false, true, false]}
{"id": "145", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is big?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Fiona is quiet.\nConclusion 1: Fiona is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Fiona is quiet.\nConclusion 2: Fiona is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Fiona is cold.\nPremise 3.3: Fiona is quiet.\nConclusion 3: Fiona is not smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Fiona is cold.\nPremise 4.3: Fiona is smart.\nConclusion 4: Fiona is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Fiona is not kind.\nConclusion 5: Fiona is big.\n\n", "ground_truth": [true, true, false, true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2]]", "logic_conclusion": "[3, 3, 5, 5, 3]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is cold .", "4": "Fiona is quiet .", "5": "Fiona is not smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Fiona is cold .", "4": "Fiona is smart .", "5": "Fiona is kind .", "6": "Fiona is a cold thing .", "7": "Fiona is a smart thing .", "8": "Fiona is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Fiona is not kind .", "3": "Fiona is big .", "4": "Fiona is a Kind thing .", "5": "Fiona is big ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"5": ["3"], "(¬4)": ["2"]}], "predicted_steps": [true, true, false, true, false]}
{"id": "146", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is not big?", "ground truth": "No", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Fiona is quiet.\nConclusion 1: Fiona is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Fiona is quiet.\nConclusion 2: Fiona is not cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Fiona is not cold.\nPremise 3.3: Fiona is quiet.\nConclusion 3: Fiona is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Fiona is cold.\nPremise 4.3: Fiona is smart.\nConclusion 4: Fiona is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Fiona is not kind.\nConclusion 5: Fiona is big.\n\n", "ground_truth": [true, false, false, true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2]]", "logic_conclusion": "[3, 3, 5, 5, 3]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is not cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is not cold .", "4": "Fiona is quiet .", "5": "Fiona is smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Fiona is cold .", "4": "Fiona is smart .", "5": "Fiona is kind .", "6": "Fiona is a cold thing .", "7": "Fiona is a smart thing .", "8": "Fiona is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Fiona is not kind .", "3": "Fiona is big .", "4": "Fiona is a Kind thing .", "5": "Fiona is big ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "3": ["(¬5)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"5": ["3"], "(¬4)": ["2"]}], "predicted_steps": [true, false, false, true, false]}
{"id": "147", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Fiona is quiet.\nConclusion 1: Fiona is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Fiona is quiet.\nConclusion 2: Fiona is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Fiona is cold.\nPremise 3.3: Fiona is quiet.\nConclusion 3: Fiona is not smart.\n\nPremise 4.1: All cold, smart things are not kind.\nPremise 4.2: Fiona is cold.\nPremise 4.3: Fiona is smart.\nConclusion 4: Fiona is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Fiona is not quiet.\nConclusion 5: Fiona is cold.\n\nPremise 6.1: All quiet things are cold.\nPremise 6.2: Fiona is not quiet.\nConclusion 6: Fiona is cold.\n\nPremise 7.1: All cold, quiet things are smart.\nPremise 7.2: Fiona is cold.\nPremise 7.3: Fiona is quiet.\nConclusion 7: Fiona is smart.\n\nPremise 8.1: All cold, smart things are kind.\nPremise 8.2: Fiona is cold.\nPremise 8.3: Fiona is smart.\nConclusion 8: Fiona is kind.\n\nPremise 9.1: Kind things are big.\nPremise 9.2: Fiona is kind.\nConclusion 9: Fiona is big.\n\nPremise 10.1: Kind, big things are red.\nPremise 10.2: Fiona is kind.\nPremise 10.3: Fiona is big.\nConclusion 10: Fiona is red.\n\n", "ground_truth": [true, true, false, false, false, false, true, true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is cold .", "4": "Fiona is quiet .", "5": "Fiona is not smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Fiona is cold .", "4": "Fiona is smart .", "5": "Fiona is kind .", "6": "Fiona is a cold thing .", "7": "Fiona is a smart thing .", "8": "Fiona is not kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is not quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is not quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is cold .", "4": "Fiona is quiet .", "5": "Fiona is smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Fiona is cold .", "4": "Fiona is smart .", "5": "Fiona is kind .", "6": "Fiona is a cold thing .", "7": "Fiona is a smart thing .", "8": "Fiona is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Fiona is kind .", "3": "Fiona is big .", "4": "Fiona is a Kind thing .", "5": "Fiona is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Fiona is kind .", "4": "Fiona is big .", "5": "Fiona is red .", "6": "Fiona is a Kind thing .", "7": "Fiona is a big thing .", "8": "Fiona is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"5": ["3"], "(¬4)": ["2"], "(¬2)": ["4"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}], "predicted_steps": [true, true, false, false, false, false, true, true, true, true]}
{"id": "148", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is not red?", "ground truth": "No", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are not cold.\nPremise 1.2: Fiona is quiet.\nConclusion 1: Fiona is cold.\n\nPremise 2.1: All quiet things are not cold.\nPremise 2.2: Fiona is quiet.\nConclusion 2: Fiona is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Fiona is cold.\nPremise 3.3: Fiona is quiet.\nConclusion 3: Fiona is smart.\n\nPremise 4.1: All cold, smart things are not kind.\nPremise 4.2: Fiona is cold.\nPremise 4.3: Fiona is smart.\nConclusion 4: Fiona is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Fiona is quiet.\nConclusion 5: Fiona is cold.\n\nPremise 6.1: All quiet things are cold.\nPremise 6.2: Fiona is quiet.\nConclusion 6: Fiona is not cold.\n\nPremise 7.1: All cold, quiet things are smart.\nPremise 7.2: Fiona is not cold.\nPremise 7.3: Fiona is quiet.\nConclusion 7: Fiona is smart.\n\nPremise 8.1: All cold, smart things are not kind.\nPremise 8.2: Fiona is cold.\nPremise 8.3: Fiona is smart.\nConclusion 8: Fiona is kind.\n\nPremise 9.1: Kind things are big.\nPremise 9.2: Fiona is kind.\nConclusion 9: Fiona is big.\n\nPremise 10.1: Kind, big things are red.\nPremise 10.2: Fiona is not kind.\nPremise 10.3: Fiona is big.\nConclusion 10: Fiona is red.\n\n", "ground_truth": [false, false, true, false, true, false, false, false, true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 3, 3, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is not cold ."}, {"0": "X is a quiet thing .", "1": "X is not cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is not cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is cold .", "4": "Fiona is quiet .", "5": "Fiona is smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Fiona is cold .", "4": "Fiona is smart .", "5": "Fiona is kind .", "6": "Fiona is a cold thing .", "7": "Fiona is a smart thing .", "8": "Fiona is not kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is not cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is not cold .", "4": "Fiona is quiet .", "5": "Fiona is smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is not kind .", "3": "Fiona is cold .", "4": "Fiona is smart .", "5": "Fiona is kind .", "6": "Fiona is a cold thing .", "7": "Fiona is a smart thing .", "8": "Fiona is not kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Fiona is kind .", "3": "Fiona is big .", "4": "Fiona is a Kind thing .", "5": "Fiona is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Fiona is not kind .", "4": "Fiona is big .", "5": "Fiona is red .", "6": "Fiona is a Kind thing .", "7": "Fiona is a big thing .", "8": "Fiona is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "3": ["(¬5)"]}, {"2": ["4"], "3": ["(¬5)"]}, {"3": ["6"], "4": ["7"], "8": ["5"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "3": ["(¬5)"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}, {"3": ["6"], "4": ["7"], "5": ["(¬8)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "8": ["5"], "(¬6)": ["3"]}], "predicted_steps": [false, false, true, false, true, false, false, false, true, false]}
