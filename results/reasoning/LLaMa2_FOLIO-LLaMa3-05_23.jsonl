{"text": "All employees who schedule a meeting with their customers will appear in the company today. Everyone who has lunch in the company schedules meetings with their customers. Employees will either have lunch in the company or have lunch at home. If an employee has lunch at home, then he/she is working remotely from home. All employees who are in other countries work remotely from home. No managers work remotely from home. James is either a manager and appears in the company today or neither a manager nor appears in the company today.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that James has lunch in the company?", "id": "0", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All employees who schedule a meeting with their customers will appear in the company today.\nPremise 1.2: Everyone who has lunch in the company schedules meetings with their customers.\nConclusion 1: All employees who have lunch in the company will appear in the company today.\n\nPremise 2.1: Employees will either have lunch in the company or have lunch at home.\nPremise 2.2: If an employee has lunch at home, then he/she is working remotely from home.\nConclusion 2: If an employee is working remotely from home, then he/she will not appear in the company today.\n\nPremise 3.1: All employees who are in other countries work remotely from home.\nPremise 3.2: No managers work remotely from home.\nConclusion 3: If James is a manager, then he will not work remotely from home.\n\nPremise 4.1: James is either a manager and appears in the company today or neither a manager nor appears in the company today.\nConclusion 4: If James is not a manager, then he will not appear in the company today.\n\nPremise 5.1: If James has lunch in the company, then he will appear in the company today.\nConclusion 5: It is uncertain whether James has lunch in the company.\n\nTherefore, the answer is C. Uncertain.", "logic_premises": "[[(0→1), (2→3)], [(0→(1⊻2)), ((3∧4)→5)], [(6→7), (8→9)], [(0⊻(1∧2))], [(0→1)]]", "logic_conclusion": "[(4→5), ((6∧7)→8), (4→5), (3→4), 2]", "correspondance": [{"0": "X is an employee who schedules a meeting with their customers .", "1": "X will appear in the company today .", "2": "X is a person who has lunch in the company .", "3": "X schedules meetings with their customers .", "4": "X is an employee who has lunch in the company .", "5": "X will appear in the company today ."}, {"0": "X is an Employee .", "1": "X will have lunch in the company .", "2": "X will have lunch at home .", "3": "X is an employee", "4": "X has lunch at home .", "5": "X is working remotely from home .", "6": "X is an employee", "7": "X is working remotely from home .", "8": "X will not appear in the company today ."}, {"0": "X is an employee who is in other a country .", "1": "X works remotely from home .", "2": "X is a manager .", "3": "X does not work remotely from home .", "4": "James is a manager .", "5": "James will not work remotely from home .", "6": "James is an employee who is in other a country .", "7": "James works remotely from home .", "8": "James is a manager .", "9": "James does not work remotely from home ."}, {"0": "James is a manager and appears in the company today .", "1": "James is neither a manager .", "2": "James is today .", "3": "James is not a manager .", "4": "James will not appear in the company today ."}, {"0": "James has lunch in the company .", "1": "James will appear in the company today .", "2": "It is uncertain that James has lunch in the company ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"], "1": ["5"]}, {"2": ["4"], "6": ["0", "3"], "5": ["8"]}, {"4": ["8"], "9": ["5", "(¬7)"], "7": ["(¬9)"]}, {"3": ["1"], "0": ["(¬1)"], "(¬4)": ["0"]}, {}], "predicted_steps": [true, false, true, true, false]}
{"text": "If people perform in school talent shows often, then they attend and are very engaged with school events. People either perform in school talent shows often or are inactive and disinterested members of their community. If people chaperone high school dances, then they are not students who attend the school. All people who are inactive and disinterested members of their community chaperone high school dances. All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school. Bonnie either both attends and is very engaged with school events and is a student who attends the school, or she neither attends and is very engaged with school events nor is a student who attends the school.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Bonnie performs in school talent shows often?", "id": "1", "ground_truth": "Uncertain", "reasoning": " Here is my reasoning:\n\nPremise 1.1: People who perform in school talent shows often attend and are very engaged with school events.\nPremise 1.2: People either perform in school talent shows often or are inactive and disinterested members of their community.\nConclusion 1: People who perform in school talent shows often are not inactive and disinterested members of their community.\n\nPremise 2.1: If people chaperone high school dances, then they are not students who attend the school.\nPremise 2.2: All people who are inactive and disinterested members of their community chaperone high school dances.\nConclusion 2: People who chaperone high school dances are not students who attend the school.\n\nPremise 3.1: All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school.\nPremise 3.2: Bonnie either attends and is very engaged with school events or she neither attends and is very engaged with school events nor is a student who attends the school.\nConclusion 3: Bonnie is a student who attends the school.\n\nPremise 4.1: Bonnie is a student who attends the school.\nPremise 4.2: People who perform in school talent shows often attend and are very engaged with school events.\nConclusion 4: Bonnie performs in school talent shows often.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→(1∧2)), (3→(4∨(5∧6)))], [(0→1), ((2∧3)→4)], [((((b∧c)∧(d∧e))→f)∪(((g∧h)∧(i∧j))→k)), ((5∧6)⊻((7∨8)∧9))], [0, ((5→(6∧7))∪(8→(9∧a)))]]", "logic_conclusion": "[(7→(8∧9)), (5→6), a, 4]", "correspondance": [{"0": "X is a person who performs in school talent shows .", "1": "X often attends school events .", "2": "X often is very engaged with school events .", "3": "X is a person .", "4": "X either performs in school talent shows often .", "5": "X either is inactive a member of People 's community .", "6": "X either is disinterested a member of People 's community .", "7": "X is a person who performs in school talent shows .", "8": "X often is not inactive a member of their community .", "9": "X often is not disinterested a member of their community ."}, {"0": "X chaperone high school dances .", "1": "X are not students who attend the school .", "2": "X is a person who is inactive a member of their community .", "3": "X is a person who is disinterested a member of their community .", "4": "X chaperones high school dances .", "5": "X is a person who chaperones high school dances .", "6": "X is not a student who attends the school ."}, {"0": "X is a a young child who wishes to furthers their academic careers .", "1": "X is a a young teenager who wishes to furthers their academic careers .", "2": "X is a a young child who wishes to furthers their educational opportunities .", "3": "X is a a young teenager who wishes to furthers their educational opportunities .", "4": "X is a student who attends the school .", "5": "Bonnie attends .", "6": "Bonnie is very engaged with school events .", "7": "Bonnie does not attend .", "8": "Bonnie is not very engaged with school events .", "9": "Bonnie is not a student who attends the school .", "a": "Bonnie is a student who attends the school .", "b": "the school is a a young child who wishes to furthers their academic careers .", "c": "the school is a a young teenager who wishes to furthers their academic careers .", "d": "the school is a a young child who wishes to furthers their educational opportunities .", "e": "the school is a a young teenager who wishes to furthers their educational opportunities .", "f": "the school is a student who attends the school .", "g": "Bonnie is a a young child who wishes to furthers their academic careers .", "h": "Bonnie is a a young teenager who wishes to furthers their academic careers .", "i": "Bonnie is a a young child who wishes to furthers their educational opportunities .", "j": "Bonnie is a a young teenager who wishes to furthers their educational opportunities .", "k": "Bonnie is a student who attends the school ."}, {"0": "Bonnie is a student who attends the school .", "1": "X is a person who performs in school talent shows .", "2": "X often attends school events .", "3": "X often is very engaged with school events .", "4": "Bonnie performs in school talent shows often .", "5": "the school is a person who performs in school talent shows .", "6": "the school often attends school events .", "7": "the school often is very engaged with school events .", "8": "Bonnie is a person who performs in school talent shows .", "9": "Bonnie often attends school events .", "a": "Bonnie often is very engaged with school events ."}], "errors": [[]], "entailments_dict": [{"2": ["3", "9"], "1": ["3"], "4": ["0"], "7": ["0", "3"]}, {"4": ["0", "6"], "5": ["0"], "1": ["6"]}, {"f": ["5", "a", "(¬9)", "(¬7)"], "k": ["5", "a", "(¬9)"], "a": ["g", "j", "i", "5", "(¬f)", "(¬9)"], "6": ["a", "(¬7)", "(¬8)", "(¬9)"], "5": ["a", "(¬7)", "(¬9)"], "9": ["(¬k)", "(¬f)"], "7": ["(¬k)", "(¬f)"], "(¬a)": ["7", "9"], "(¬9)": ["g", "j", "i"]}, {"a": ["0"], "9": ["0"], "4": ["0", "8"]}], "predicted_steps": [false, true, false, false]}
{"text": "If people perform in school talent shows often, then they attend and are very engaged with school events. People either perform in school talent shows often or are inactive and disinterested members of their community. If people chaperone high school dances, then they are not students who attend the school. All people who are inactive and disinterested members of their community chaperone high school dances. All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school. Bonnie either both attends and is very engaged with school events and is a student who attends the school, or she neither attends and is very engaged with school events nor is a student who attends the school.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Bonnie is either both a young child or teenager who wishes to further her academic career and educational opportunities and chaperones high school dances or neither is a young child nor teenager who wishes to further her academic career and educational opportunities, then Bonnie is either a student who attends the school or is an inactive and disinterested member of the community?", "id": "2", "ground_truth": "True", "reasoning": " Yes.\n\nReasoning:\n\nPremise 1.1: People who perform in school talent shows often attend and are very engaged with school events.\nPremise 1.2: People who are inactive and disinterested members of their community chaperone high school dances.\nConclusion 1: People who chaperone high school dances are not students who attend the school.\nPremise 2.1: All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school.\nPremise 2.2: Bonnie either attends and is very engaged with school events or neither attends nor is engaged with school events.\nConclusion 2: Bonnie is either a student who attends the school or an inactive and disinterested member of the community.\nPremise 3.1: If Bonnie is a young child or teenager who wishes to further her academic career and educational opportunities, then she is a student who attends the school.\nPremise 3.2: If Bonnie is not a young child or teenager who wishes to further her academic career and educational opportunities, then she is an inactive and disinterested member of the community.\nConclusion 3: Bonnie is either a student who attends the school or an inactive and disinterested member of the community.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→(1∧2)), ((3∧4)→5)], [((((c∧d)∧(e∧f))→g)∪((((h∧i)∧(j∧k))→l)∪(((m∧n)∧(o∧p))→q))), ((5∧6)∨(7⊻8))], [(((0∨1)∧(2∨3))→4), (((5∨6)∧(7∨8))→(9∧a))]]", "logic_conclusion": "[(6→7), (9⊻(a∧b)), (b⊻(c∧d))]", "correspondance": [{"0": "X is a person who performs in school talent shows .", "1": "X often attends school events .", "2": "X often is very engaged with school events .", "3": "X is a person who is inactive a member of their community .", "4": "X is a person who is disinterested a member of their community .", "5": "X chaperones high school dances .", "6": "X is a person who chaperones high school dances .", "7": "X is not a student who attends the school ."}, {"0": "X is a a young child who wishes to furthers their academic careers .", "1": "X is a a young teenager who wishes to furthers their academic careers .", "2": "X is a a young child who wishes to furthers their educational opportunities .", "3": "X is a a young teenager who wishes to furthers their educational opportunities .", "4": "X is a student who attends the school .", "5": "Bonnie either attends school events .", "6": "Bonnie either is very engaged with school events .", "7": "Bonnie neither attends school events .", "8": "Bonnie neither is engaged with school events .", "9": "Bonnie is a student who attends the school .", "a": "Bonnie is an inactive member of the community .", "b": "Bonnie is an disinterested member of the community .", "c": "the community is a a young child who wishes to furthers their academic careers .", "d": "the community is a a young teenager who wishes to furthers their academic careers .", "e": "the community is a a young child who wishes to furthers their educational opportunities .", "f": "the community is a a young teenager who wishes to furthers their educational opportunities .", "g": "the community is a student who attends the school .", "h": "the school is a a young child who wishes to furthers their academic careers .", "i": "the school is a a young teenager who wishes to furthers their academic careers .", "j": "the school is a a young child who wishes to furthers their educational opportunities .", "k": "the school is a a young teenager who wishes to furthers their educational opportunities .", "l": "the school is a student who attends the school .", "m": "Bonnie is a a young child who wishes to furthers their academic careers .", "n": "Bonnie is a a young teenager who wishes to furthers their academic careers .", "o": "Bonnie is a a young child who wishes to furthers their educational opportunities .", "p": "Bonnie is a a young teenager who wishes to furthers their educational opportunities .", "q": "Bonnie is a student who attends the school ."}, {"0": "Bonnie is a young child who wishes to further Bonnie 's academic career .", "1": "Bonnie is a young teenager who wishes to further Bonnie 's academic career .", "2": "Bonnie is a young child who wishes to further Bonnie 's educational opportunities .", "3": "Bonnie is a young teenager who wishes to further Bonnie 's educational opportunities .", "4": "Bonnie is a student who attends the school .", "5": "Bonnie is not a young child who wishes to further Bonnie 's academic career .", "6": "Bonnie is not a young teenager who wishes to further Bonnie 's academic career .", "7": "Bonnie is not a young child who wishes to further Bonnie 's educational opportunities .", "8": "Bonnie is not a young teenager who wishes to further Bonnie 's educational opportunities .", "9": "Bonnie is an inactive member of the community .", "a": "Bonnie is an disinterested member of the community .", "b": "Bonnie is a student who attends the school .", "c": "Bonnie is an inactive member of the community .", "d": "Bonnie is an disinterested member of the community ."}], "errors": [[]], "entailments_dict": [{"5": ["7"]}, {"q": ["5", "9", "(¬7)"], "9": ["p", "m", "o", "5", "(¬l)", "(¬7)"], "b": ["7", "8"], "a": ["7", "8"], "l": ["9"], "g": ["9"], "5": ["9"], "(¬9)": ["7", "8"]}, {"b": ["3", "2"], "4": ["b"], "9": ["c"], "a": ["d"], "(¬0)": ["7", "5", "6"], "(¬2)": ["5", "7"], "(¬6)": ["3", "1"], "(¬3)": ["5", "6", "8", "7"], "(¬1)": ["7", "5", "6", "8"], "(¬7)": ["2", "0"], "(¬8)": ["1", "3"], "(¬5)": ["2", "0"]}], "predicted_steps": [false, false, false]}
{"text": "If people perform in school talent shows often, then they attend and are very engaged with school events. People either perform in school talent shows often or are inactive and disinterested members of their community. If people chaperone high school dances, then they are not students who attend the school. All people who are inactive and disinterested members of their community chaperone high school dances. All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school. Bonnie either both attends and is very engaged with school events and is a student who attends the school, or she neither attends and is very engaged with school events nor is a student who attends the school.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Bonnie either chaperones high school dances or, if she does not, she performs in school talent shows often, then Bonnie is both a young child or teenager who wishes to further her academic career and educational opportunities and an inactive and disinterested member of the community?", "id": "3", "ground_truth": "False", "reasoning": " No.\n\nPremise 1: People who perform in school talent shows often attend and are very engaged with school events.\nPremise 2: People who chaperone high school dances are not students who attend the school.\nPremise 3: All people who are inactive and disinterested members of their community chaperone high school dances.\nPremise 4: All young children and teenagers who wish to further their academic careers and educational opportunities are students who attend the school.\nPremise 5: Bonnie either attends and is very engaged with school events and is a student who attends the school, or she neither attends and is very engaged with school events nor is a student who attends the school.\n\nConclusion 1: Bonnie is either a student who attends the school and is very engaged with school events, or she is not a student who attends the school and is inactive and disinterested in the community.\n\nPremise 6: If Bonnie chaperones high school dances, then she is not a student who attends the school.\nPremise 7: If Bonnie does not chaperone high school dances, then she performs in school talent shows often.\n\nConclusion 2: Bonnie is not a student who attends the school and is inactive and disinterested in the community, or she performs in school talent shows often.\n\nConclusion 3: Bonnie cannot be both a young child or teenager who wishes to further her academic career and educational opportunities and an inactive and disinterested member of the community.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((m→(n∧o))∪((p→(q∧r))∪(s→(t∧u)))), ((v→w)∪((x→y)∪(z→A))), (((B∧C)→D)∪(((E∧F)→G)∪((H∧I)→J))), ((((K∧L)∧(M∧N))→O)∪((((P∧Q)∧(R∧S))→T)∪(((U∧V)∧(W∧X))→Y))), (((d∧e)∧f)⊻((g∨h)∧i))], [(0→1), (2→3)]]", "logic_conclusion": "[(j⊻(k∧l)), ((4∧5)∨6)]", "correspondance": [{"0": "X is a person who performs in school talent shows .", "1": "X often attends school events .", "2": "X often is very engaged with school events .", "3": "X is a person who chaperones high school dances .", "4": "X is not a student who attends the school .", "5": "X is a person who is inactive a member of their community .", "6": "X is a person who is disinterested a member of their community .", "7": "X chaperones high school dances .", "8": "X is a a young child who wishes to furthers their academic careers .", "9": "X is a a young teenager who wishes to furthers their academic careers .", "a": "X is a a young child who wishes to furthers their educational opportunities .", "b": "X is a a young teenager who wishes to furthers their educational opportunities .", "c": "X is a student who attends the school .", "d": "Bonnie attends .", "e": "Bonnie is very engaged with school events .", "f": "Bonnie is a student who attends the school .", "g": "Bonnie does not attend .", "h": "Bonnie is not very engaged with school events .", "i": "Bonnie is not a student who attends the school .", "j": "Bonnie is a student who attends the school and is very engaged with school events .", "k": "Bonnie is not a student who attends the school .", "l": "Bonnie is inactive and disinterested in the community .", "m": "the community is a person who performs in school talent shows .", "n": "the community often attends school events .", "o": "the community often is very engaged with school events .", "p": "the school is a person who performs in school talent shows .", "q": "the school often attends school events .", "r": "the school often is very engaged with school events .", "s": "Bonnie is a person who performs in school talent shows .", "t": "Bonnie often attends school events .", "u": "Bonnie often is very engaged with school events .", "v": "the community is a person who chaperones high school dances .", "w": "the community is not a student who attends the school .", "x": "the school is a person who chaperones high school dances .", "y": "the school is not a student who attends the school .", "z": "Bonnie is a person who chaperones high school dances .", "A": "Bonnie is not a student who attends the school .", "B": "the community is a person who is inactive a member of their community .", "C": "the community is a person who is disinterested a member of their community .", "D": "the community chaperones high school dances .", "E": "the school is a person who is inactive a member of their community .", "F": "the school is a person who is disinterested a member of their community .", "G": "the school chaperones high school dances .", "H": "Bonnie is a person who is inactive a member of their community .", "I": "Bonnie is a person who is disinterested a member of their community .", "J": "Bonnie chaperones high school dances .", "K": "the community is a a young child who wishes to furthers their academic careers .", "L": "the community is a a young teenager who wishes to furthers their academic careers .", "M": "the community is a a young child who wishes to furthers their educational opportunities .", "N": "the community is a a young teenager who wishes to furthers their educational opportunities .", "O": "the community is a student who attends the school .", "P": "the school is a a young child who wishes to furthers their academic careers .", "Q": "the school is a a young teenager who wishes to furthers their academic careers .", "R": "the school is a a young child who wishes to furthers their educational opportunities .", "S": "the school is a a young teenager who wishes to furthers their educational opportunities .", "T": "the school is a student who attends the school .", "U": "Bonnie is a a young child who wishes to furthers their academic careers .", "V": "Bonnie is a a young teenager who wishes to furthers their academic careers .", "W": "Bonnie is a a young child who wishes to furthers their educational opportunities .", "X": "Bonnie is a a young teenager who wishes to furthers their educational opportunities .", "Y": "Bonnie is a student who attends the school ."}, {"0": "Bonnie chaperones high school dances .", "1": "Bonnie is not a student who attends the school .", "2": "Bonnie does not chaperone high school dances .", "3": "Bonnie performs in school talent shows often .", "4": "Bonnie is not a student who attends the school .", "5": "Bonnie is inactive and disinterested in the community .", "6": "Bonnie performs in school talent shows often ."}], "errors": [[]], "entailments_dict": [{"J": ["i", "z", "e", "k"], "t": ["f", "d", "j", "(¬A)", "(¬g)", "(¬i)", "(¬y)"], "O": ["f", "d", "(¬A)", "(¬w)", "(¬g)", "(¬i)", "(¬y)"], "f": ["W", "U", "X", "j", "(¬A)", "(¬w)", "(¬T)", "(¬y)", "(¬i)"], "A": ["g", "i", "k", "(¬T)", "(¬Y)", "(¬d)", "(¬f)"], "Y": ["d", "f", "j", "(¬y)", "(¬i)", "(¬A)", "(¬w)"], "T": ["d", "f", "(¬g)", "(¬G)", "(¬y)", "(¬i)", "(¬A)", "(¬w)", "(¬r)", "(¬q)"], "u": ["f", "e", "j", "(¬A)", "(¬h)", "(¬i)"], "l": ["H", "I", "g", "h", "(¬u)", "(¬t)", "(¬J)", "(¬d)", "(¬e)"], "j": ["U", "X", "V", "W", "d", "f", "e", "(¬w)", "(¬h)", "(¬y)", "(¬T)"], "k": ["g", "i", "(¬T)", "(¬Y)", "(¬d)", "(¬f)"], "d": ["j", "(¬A)", "(¬g)", "(¬i)", "(¬y)"], "e": ["j", "(¬A)", "(¬g)", "(¬h)", "(¬i)", "(¬y)"], "g": ["k", "(¬t)", "(¬T)", "(¬Y)", "(¬J)"], "i": ["k", "(¬T)", "(¬Y)"], "y": ["i", "g", "k", "(¬G)", "(¬Y)", "(¬d)", "(¬f)", "(¬T)", "(¬q)", "(¬O)"], "r": ["j", "(¬y)"], "h": ["(¬J)", "(¬u)", "(¬t)"], "w": ["(¬Y)", "(¬d)", "(¬O)", "(¬f)", "(¬T)"], "G": ["(¬T)", "(¬y)"], "q": ["(¬T)", "(¬y)"], "n": ["(¬y)"], "(¬l)": ["e", "g"], "(¬j)": ["h", "i"], "(¬k)": ["U", "X", "W", "d", "f"], "(¬i)": ["X", "W", "U"], "(¬H)": ["g"], "(¬B)": ["g"], "(¬I)": ["g"]}, {"5": ["2", "(¬3)"], "1": ["4"], "3": ["6", "(¬1)"], "6": ["(¬1)"], "(¬0)": ["2"], "(¬2)": ["0"]}], "predicted_steps": [false, "Contradiction in the premises"]}
{"text": "All employees who schedule a meeting with their customers will appear in the company today. Everyone who has lunch in the company schedules meetings with their customers. Employees will either have lunch in the company or have lunch at home. If an employee has lunch at home, then he/she is working remotely from home. All employees who are in other countries work remotely from home. No managers work remotely from home. James is either a manager and appears in the company today or neither a manager nor appears in the company today.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that James does not have lunch in the company?", "id": "4", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All employees who schedule a meeting with their customers will appear in the company today.\nPremise 1.2: Everyone who has lunch in the company schedules meetings with their customers.\nConclusion 1: All employees who have lunch in the company will appear in the company today.\n\nPremise 2.1: Employees will either have lunch in the company or have lunch at home.\nPremise 2.2: If an employee has lunch at home, then he/she is working remotely from home.\nConclusion 2: If an employee is working remotely from home, then he/she will not appear in the company today.\n\nPremise 3.1: All employees who are in other countries work remotely from home.\nPremise 3.2: No managers work remotely from home.\nConclusion 3: If James is a manager, then he will not work remotely from home.\n\nPremise 4.1: James is either a manager and appears in the company today or neither a manager nor appears in the company today.\nConclusion 4: If James is not a manager, then he will not appear in the company today.\n\nPremise 5.1: If James does not have lunch in the company, then he is working remotely from home.\nConclusion 5: James does not have lunch in the company.\n\nTherefore, the answer is A. Yes. It is true that James does not have lunch in the company.", "logic_premises": "[[(0→1), (2→3)], [(0→(1⊻2)), ((3∧4)→5)], [(6→7), (8→9)], [(0⊻(1∧2))], [(0→1)]]", "logic_conclusion": "[(4→5), ((6∧7)→8), (4→5), (3→4), 2]", "correspondance": [{"0": "X is an employee who schedules a meeting with their customers .", "1": "X will appear in the company today .", "2": "X is a person who has lunch in the company .", "3": "X schedules meetings with their customers .", "4": "X is an employee who has lunch in the company .", "5": "X will appear in the company today ."}, {"0": "X is an Employee .", "1": "X will have lunch in the company .", "2": "X will have lunch at home .", "3": "X is an employee", "4": "X has lunch at home .", "5": "X is working remotely from home .", "6": "X is an employee", "7": "X is working remotely from home .", "8": "X will not appear in the company today ."}, {"0": "X is an employee who is in other a country .", "1": "X works remotely from home .", "2": "X is a manager .", "3": "X does not work remotely from home .", "4": "James is a manager .", "5": "James will not work remotely from home .", "6": "James is an employee who is in other a country .", "7": "James works remotely from home .", "8": "James is a manager .", "9": "James does not work remotely from home ."}, {"0": "James is a manager and appears in the company today .", "1": "James is neither a manager .", "2": "James is today .", "3": "James is not a manager .", "4": "James will not appear in the company today ."}, {"0": "James does not have lunch in the company .", "1": "James is working remotely from home .", "2": "James does not have lunch in the company ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"], "1": ["5"]}, {"2": ["4"], "6": ["0", "3"], "5": ["8"]}, {"4": ["8"], "9": ["5", "(¬7)"], "7": ["(¬9)"]}, {"3": ["1"], "0": ["(¬1)"], "(¬4)": ["0"]}, {"2": ["0"]}], "predicted_steps": [true, false, true, true, false]}
{"text": "All employees who schedule a meeting with their customers will appear in the company today. Everyone who has lunch in the company schedules meetings with their customers. Employees will either have lunch in the company or have lunch at home. If an employee has lunch at home, then he/she is working remotely from home. All employees who are in other countries work remotely from home. No managers work remotely from home. James is either a manager and appears in the company today or neither a manager nor appears in the company today.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If James is either a manager or in other countries, then James either has lunch at home and works remotely from home, or neither has lunch at home nor works remotely from home?", "id": "5", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All employees who schedule a meeting with their customers will appear in the company today.\nPremise 1.2: Everyone who has lunch in the company schedules meetings with their customers.\nConclusion 1: All employees who have lunch in the company will appear in the company today.\n\nPremise 2.1: Employees will either have lunch in the company or have lunch at home.\nPremise 2.2: If an employee has lunch at home, then he/she is working remotely from home.\nConclusion 2: All employees who have lunch at home will work remotely from home.\n\nPremise 3.1: All employees who are in other countries work remotely from home.\nPremise 3.2: No managers work remotely from home.\nConclusion 3: If James is a manager, then he will not work remotely from home.\n\nPremise 4.1: James is either a manager or in other countries.\nPremise 4.2: If James is a manager, then he will not work remotely from home.\nConclusion 4: If James is in other countries, then he will work remotely from home.\n\nPremise 5.1: James either has lunch at home and works remotely from home, or neither has lunch at home nor works remotely from home.\nConclusion 5: It is true that If James is either a manager or in other countries, then James either has lunch at home and works remotely from home, or neither has lunch at home nor works remotely from home.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→(1⊻2)), ((3∧4)→5)], [(6→7), (8→9)], [0, (1→2)], [((0∧1)⊻2)]]", "logic_conclusion": "[(4→5), (6→7), (4→5), (3→4), (3→((4⊻5)∨(6⊻7)))]", "correspondance": [{"0": "X is an employee who schedules a meeting with their customers .", "1": "X will appear in the company today .", "2": "X is a person who has lunch in the company .", "3": "X schedules meetings with their customers .", "4": "X is an employee who has lunch in the company .", "5": "X will appear in the company today ."}, {"0": "X is an Employee .", "1": "X will have lunch in the company .", "2": "X will have lunch at home .", "3": "X is an employee", "4": "X has lunch at home .", "5": "X is working remotely from home .", "6": "X is an employee who has lunch at home .", "7": "X will work remotely from home ."}, {"0": "X is an employee who is in other a country .", "1": "X works remotely from home .", "2": "X is a manager .", "3": "X does not work remotely from home .", "4": "James is a manager .", "5": "James will not work remotely from home .", "6": "James is an employee who is in other a country .", "7": "James works remotely from home .", "8": "James is a manager .", "9": "James does not work remotely from home ."}, {"0": "James is either a manager or in other countries .", "1": "James is a manager .", "2": "James will not work remotely from home .", "3": "James is in other countries .", "4": "James will work remotely from home ."}, {"0": "James has lunch at home .", "1": "James works remotely from home .", "2": "neither has lunch at home nor works remotely from home .", "3": "It is true that James is either a manager or in other countries .", "4": "It is true that James has lunch at home .", "5": "It is true that James works remotely from home .", "6": "It is true that James neither has lunch at home .", "7": "It is true that James neither works remotely from home ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"], "1": ["5"]}, {"2": ["4"], "6": ["0", "4", "3", "(¬1)"], "5": ["7"]}, {"4": ["8"], "9": ["5", "(¬7)"], "7": ["(¬9)"]}, {"0": ["1"]}, {"1": ["5", "(¬2)"], "2": ["7", "6"], "0": ["4", "(¬2)"]}], "predicted_steps": [true, true, true, false, false]}
{"text": "Monkeypox is an infectious disease caused by the monkeypox virus. Monkeypox virus can occur in certain animals, including humans. Humans are mammals. Mammals are animals. Symptons of Monkeypox include fever, headache, muscle pains, feeling tired, and so on. People feel tired when they get a glu.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that There is an animal?", "id": "6", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Monkeypox is an infectious disease caused by the monkeypox virus.\nPremise 1.2: Monkeypox virus can occur in certain animals, including humans.\nConclusion 1: Humans can get monkeypox.\n\nPremise 2.1: Humans are mammals.\nPremise 2.2: Mammals are animals.\nConclusion 2: Humans are animals.\n\nPremise 3.1: Symptoms of Monkeypox include fever, headache, muscle pains, feeling tired, and so on.\nPremise 3.2: People feel tired when they get a glu.\nConclusion 3: People can get tired from monkeypox.\n\nPremise 4.1: Humans can get monkeypox.\nPremise 4.2: People can get tired from monkeypox.\nConclusion 4: Therefore, there is an animal (humans) that can get monkeypox and feel tired.\n\nConclusion 5: Answer A. Yes.", "logic_premises": "[[0, 1], [(0→1), (2→3)], [(0→1), (2→3)], [(0→1), (2→3)]]", "logic_conclusion": "[((4→5)∪(6→7)), (4→5), (4→5), 4]", "correspondance": [{"0": "Monkeypox is an infectious disease caused by the monkeypox virus .", "1": "the monkeypox virus can occur in certain animals , including humans .", "2": "X is a Human .", "3": "X can get Monkeypox .", "4": "Monkeypox is a Human .", "5": "Monkeypox can get Monkeypox .", "6": "the monkeypox virus is a Human .", "7": "the monkeypox virus can get Monkeypox ."}, {"0": "X is a Human .", "1": "X is a mammal .", "2": "X is a Mammal .", "3": "X is an animal .", "4": "X is a Human .", "5": "X is an animal ."}, {"0": "X is a Symptom of Monkeypox .", "1": "X includes fever , headache , muscle pains , feeling tired , and so on .", "2": "X is a person .", "3": "X feels tired that People gets a glu .", "4": "X is a person .", "5": "X can get tired from Monkeypox ."}, {"0": "X is a Human .", "1": "X can get monkeypox .", "2": "X is a person .", "3": "X can get tired from monkeypox .", "4": "Therefore , there is an animal ."}], "errors": [[]], "entailments_dict": [{"1": ["0", "7"], "0": ["1", "7", "5"], "4": ["0"], "6": ["0"]}, {"1": ["2", "5"], "4": ["0", "2", "(¬3)"], "3": ["5"], "(¬5)": ["0"]}, {"4": ["2"]}, {"1": ["2"]}], "predicted_steps": [false, "Contradiction in the premises", false, false]}
{"text": "Monkeypox is an infectious disease caused by the monkeypox virus. Monkeypox virus can occur in certain animals, including humans. Humans are mammals. Mammals are animals. Symptons of Monkeypox include fever, headache, muscle pains, feeling tired, and so on. People feel tired when they get a glu.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that No one gets flu?", "id": "7", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Monkeypox is an infectious disease caused by the monkeypox virus.\nPremise 1.2: Monkeypox virus can occur in certain animals, including humans.\nConclusion 1: Humans can get monkeypox.\n\nPremise 2.1: Humans are mammals.\nPremise 2.2: Mammals are animals.\nConclusion 2: Humans are animals.\n\nPremise 3.1: Symptoms of Monkeypox include fever, headache, muscle pains, feeling tired, and so on.\nPremise 3.2: People feel tired when they get a glu.\nConclusion 3: People can get tired when they have Monkeypox.\n\nPremise 4.1: No one gets flu.\nConclusion 4: It is uncertain whether no one gets flu.\n\nBased on the information provided, it is uncertain whether no one gets flu. Therefore, the answer is C. Uncertain.", "logic_premises": "[[0, 1], [(0→1), (2→3)], [(0→1), (2→3)], [(0→1)]]", "logic_conclusion": "[((4→5)∪(6→7)), (4→5), (4→5), (2→3)]", "correspondance": [{"0": "Monkeypox is an infectious disease caused by the monkeypox virus .", "1": "the monkeypox virus can occur in certain animals , including humans .", "2": "X is a Human .", "3": "X can get Monkeypox .", "4": "Monkeypox is a Human .", "5": "Monkeypox can get Monkeypox .", "6": "the monkeypox virus is a Human .", "7": "the monkeypox virus can get Monkeypox ."}, {"0": "X is a Human .", "1": "X is a mammal .", "2": "X is a Mammal .", "3": "X is an animal .", "4": "X is a Human .", "5": "X is an animal ."}, {"0": "X is a Symptom of Monkeypox .", "1": "X includes fever , headache , muscle pains , feeling tired , and so on .", "2": "X is a person .", "3": "X feels tired that People gets a glu .", "4": "X is a person .", "5": "X can get tired that People have Monkeypox ."}, {"0": "X is a person .", "1": "X does not get flu .", "2": "X is a person .", "3": "It is not uncertain that X gets flu ."}], "errors": [[]], "entailments_dict": [{"1": ["0", "7"], "0": ["1", "7", "5"], "4": ["0"], "6": ["0"]}, {"1": ["2", "5"], "4": ["0", "2", "(¬3)"], "3": ["5"], "(¬5)": ["0"]}, {"4": ["2"]}, {"2": ["0"]}], "predicted_steps": [false, "Contradiction in the premises", false, false]}
{"text": "Monkeypox is an infectious disease caused by the monkeypox virus. Monkeypox virus can occur in certain animals, including humans. Humans are mammals. Mammals are animals. Symptons of Monkeypox include fever, headache, muscle pains, feeling tired, and so on. People feel tired when they get a glu.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Symptons of Monkeypox include coughing?", "id": "8", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Symptoms of Monkeypox include fever, headache, muscle pains, and feeling tired.\nPremise 1.2: Feeling tired is a symptom of Monkeypox.\nConclusion 1: Feeling tired is a symptom of Monkeypox.\n\nPremise 2.1: People feel tired when they get a glu.\nConclusion 2: Getting a glu can cause feeling tired.\n\nPremise 3.1: Feeling tired is a symptom of Monkeypox.\nPremise 3.2: Getting a glu can cause feeling tired.\nConclusion 3: Monkeypox can cause feeling tired.\n\nPremise 4.1: Coughing is not mentioned as a symptom of Monkeypox.\nConclusion 4: Symptoms of Monkeypox do not include coughing.\n\nTherefore, the answer is B. No.", "logic_premises": "[[(4→5), 2], [(0→1)], [0, 1], [0]]", "logic_conclusion": "[3, 2, 2, (3→4)]", "correspondance": [{"0": "X is a Symptom of Monkeypox .", "1": "X includes fever , headache , muscle pains , and feeling tired .", "2": "Feeling tired is a symptom of Monkeypox .", "3": "Feeling tired is a symptom of Monkeypox .", "4": "Monkeypox is a Symptom of Monkeypox .", "5": "Monkeypox includes fever , headache , muscle pains , and feeling tired ."}, {"0": "X is a person .", "1": "X feels tired that people gets a glu .", "2": "Getting a glu can cause feeling tired ."}, {"0": "Feeling tired is a symptom of Monkeypox .", "1": "Getting a glu can cause feeling tired .", "2": "Monkeypox can cause feeling tired ."}, {"0": "Coughing is not mentioned as a symptom of Monkeypox .", "1": "X is a Symptom of Monkeypox .", "2": "X does not includes coughing .", "3": "Monkeypox is a Symptom of Monkeypox .", "4": "Monkeypox does not includes coughing ."}], "errors": [[]], "entailments_dict": [{"5": ["2", "3"], "2": ["4", "3"], "3": ["4", "2"]}, {"1": ["2"]}, {"2": ["0"], "0": ["2"]}, {"0": ["4"]}], "predicted_steps": [true, false, true, false]}
{"text": "There are six types of wild turkeys: Eastern wild turkey, Osceola wild turkey, Gould’s wild turkey, Merriam’s wild turkey, Rio Grande wild turkey, and Ocellated wild turkey. Tom is not an Eastern wild turkey. Tom is not an Osceola wild turkey. Tom is also not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey. Tom is a wild turkey.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Tom is an Ocellated wild turkey?", "id": "9", "ground_truth": "True", "reasoning": " Here is my reasoning:\n\nPremise 1.1: Tom is not an Eastern wild turkey.\nPremise 1.2: Tom is not an Osceola wild turkey.\nPremise 1.3: Tom is not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey.\nConclusion 1: Tom is not one of the first five types of wild turkeys mentioned.\n\nPremise 2.1: Tom is a wild turkey.\nConclusion 2: Tom is a type of wild turkey that is not one of the first five mentioned.\n\nPremise 3.1: The only type of wild turkey that is not mentioned is the Ocellated wild turkey.\nConclusion 3: Tom is an Ocellated wild turkey.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, 1, (2∨(3∨4))], [0], [0]]", "logic_conclusion": "[5, 1, 1]", "correspondance": [{"0": "Tom is not an Eastern wild turkey .", "1": "Tom is not an Osceola wild turkey .", "2": "Tom is not a Gould 's wild turkey .", "3": "Tom is not a Merriam 's wild turkey .", "4": "Tom is not a Rio Grande wild turkey .", "5": "Tom is not one of the first five types of wild turkeys mentioned ."}, {"0": "Tom is a wild turkey .", "1": "Tom is a type of wild turkey that is not one of the first five mentioned ."}, {"0": "The only type of wild turkey that is not mentioned is the Ocellated wild turkey .", "1": "Tom is an Ocellated wild turkey ."}], "errors": [[]], "entailments_dict": [{"0": ["2", "4", "3", "1"], "5": ["3", "2"], "(¬4)": ["1", "0"]}, {"1": ["0"], "(¬1)": ["0"]}, {"1": ["(¬0)"], "(¬1)": ["0"]}], "predicted_steps": [false, false, false]}
{"text": "There are six types of wild turkeys: Eastern wild turkey, Osceola wild turkey, Gould’s wild turkey, Merriam’s wild turkey, Rio Grande wild turkey, and Ocellated wild turkey. Tom is not an Eastern wild turkey. Tom is not an Osceola wild turkey. Tom is also not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey. Tom is a wild turkey.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Tom is an Eastern wild turkey?", "id": "10", "ground_truth": "False", "reasoning": " Here is my reasoning:\n\nPremise 1.1: Tom is not an Eastern wild turkey.\nPremise 1.2: Tom is not an Osceola wild turkey.\nConclusion 1: Tom is not one of the first two types of wild turkeys.\n\nPremise 2.1: Tom is not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey.\nConclusion 2: Tom is not one of the last four types of wild turkeys.\n\nPremise 3.1: Tom is a wild turkey.\nConclusion 3: Tom is a type of wild turkey that is not one of the six mentioned.\n\nConclusion 4: Tom is an Ocellated wild turkey.\n\nTherefore, the answer is B. No, it is not true that Tom is an Eastern wild turkey.", "logic_premises": "[[0, 1], [(0∨(1∨2))], [0]]", "logic_conclusion": "[2, 3, 1]", "correspondance": [{"0": "Tom is not an Eastern wild turkey .", "1": "Tom is not an Osceola wild turkey .", "2": "Tom is not one of the first two types of wild turkeys ."}, {"0": "Tom is not a Gould 's wild turkey .", "1": "Tom is not a Merriam 's wild turkey .", "2": "Tom is not a Rio Grande wild turkey .", "3": "Tom is not one of the last four types of wild turkeys ."}, {"0": "Tom is a wild turkey .", "1": "Tom is a type of wild turkey that is not one of the six mentioned ."}], "errors": [[]], "entailments_dict": [{"0": ["1"], "2": ["1"], "1": ["2"]}, {}, {"1": ["0"], "(¬1)": ["0"]}], "predicted_steps": [true, false, false]}
{"text": "There are six types of wild turkeys: Eastern wild turkey, Osceola wild turkey, Gould’s wild turkey, Merriam’s wild turkey, Rio Grande wild turkey, and Ocellated wild turkey. Tom is not an Eastern wild turkey. Tom is not an Osceola wild turkey. Tom is also not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey. Tom is a wild turkey.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Joey is a wild turkey?", "id": "11", "ground_truth": "Uncertain", "reasoning": " Here is my reasoning:\n\nPremise 1.1: Tom is not an Eastern wild turkey.\nPremise 1.2: Tom is not an Osceola wild turkey.\nPremise 1.3: Tom is not a Gould's wild turkey, or a Merriam's wild turkey, or a Rio Grande wild turkey.\nConclusion 1: Tom is an Ocellated wild turkey.\n\nPremise 2.1: Tom is a wild turkey.\nConclusion 2: Joey is a wild turkey.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, 1, (2∨(3∨4))], [0]]", "logic_conclusion": "[5, 1]", "correspondance": [{"0": "Tom is not an Eastern wild turkey .", "1": "Tom is not an Osceola wild turkey .", "2": "Tom is not a Gould 's wild turkey .", "3": "Tom is not a Merriam 's wild turkey .", "4": "Tom is not a Rio Grande wild turkey .", "5": "Tom is an Ocellated wild turkey ."}, {"0": "Tom is a wild turkey .", "1": "Joey is a wild turkey ."}], "errors": [[]], "entailments_dict": [{"0": ["2", "4", "3", "1"], "5": ["(¬0)", "(¬4)", "(¬3)", "(¬2)"], "(¬4)": ["1", "0"]}, {}], "predicted_steps": [false, false]}
{"text": "A Japanese game company created the game the Legend of Zelda. All games in the Top 10 list are made by Japanese game companies. [BG] If a game sells more than one million copies, then it will be selected into the Top 10 list. The Legend of Zelda sold more than one million copies.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The Legend of Zelda is in the Top 10 list?", "id": "12", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All games in the Top 10 list are made by Japanese game companies.\nPremise 1.2: The Legend of Zelda is a game made by a Japanese game company.\nConclusion 1: The Legend of Zelda is in the Top 10 list.\n\nPremise 2.1: If a game sells more than one million copies, then it will be selected into the Top 10 list.\nPremise 2.2: The Legend of Zelda sold more than one million copies.\nConclusion 2: The Legend of Zelda is in the Top 10 list.\n\nConclusion: The answer is A. Yes. The Legend of Zelda is in the Top 10 list.", "logic_premises": "[[((4→5)∪(6→7)), 2], [(((5∧6)→7)∪((8∧9)→a)), 3]]", "logic_conclusion": "[3, 4]", "correspondance": [{"0": "X is a game in the Top 10 list .", "1": "X is made by Japanese game companies .", "2": "The Legend of Zelda is a game made by a Japanese game company .", "3": "The Legend of Zelda is in the Top 10 list .", "4": "the Top 10 list is a game in the Top 10 list .", "5": "the Top 10 list is made by Japanese game companies .", "6": "The Legend of Zelda is a game in the Top 10 list .", "7": "The Legend of Zelda is made by Japanese game companies ."}, {"0": "X is a game", "1": "X sells more than one million copies .", "2": "X will be selected into the Top 10 list .", "3": "The Legend of Zelda sold more than one million copies .", "4": "The Legend of Zelda is in the Top 10 list .", "5": "the Top 10 list is a game", "6": "the Top 10 list sells more than one million copies .", "7": "the Top 10 list will be selected into the Top 10 list .", "8": "The Legend of Zelda is a game", "9": "The Legend of Zelda sells more than one million copies .", "a": "The Legend of Zelda will be selected into the Top 10 list ."}], "errors": [[]], "entailments_dict": [{"7": ["2"], "3": ["6"], "5": ["2"]}, {"3": ["9", "8"], "4": ["8"], "a": ["4"]}], "predicted_steps": [false, true]}
{"text": "A Japanese game company created the game the Legend of Zelda. All games in the Top 10 list are made by Japanese game companies. [BG] If a game sells more than one million copies, then it will be selected into the Top 10 list. The Legend of Zelda sold more than one million copies.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that FIFA 22 is made by a Japanese video game company?", "id": "13", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All games in the Top 10 list are made by Japanese game companies.\nPremise 1.2: The Legend of Zelda sold more than one million copies and is in the Top 10 list.\nConclusion 1: The Legend of Zelda is made by a Japanese game company.\n\nPremise 2.1: The Legend of Zelda is made by a Japanese game company.\nPremise 2.2: FIFA 22 is not the Legend of Zelda.\nConclusion 2: FIFA 22 is not made by a Japanese game company.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((5→6)∪(7→8)), (2∧3)], [0, 1]]", "logic_conclusion": "[4, 2]", "correspondance": [{"0": "X is a game in the Top 10 list .", "1": "X is made by Japanese game companies .", "2": "The Legend of Zelda sold more than one million copies .", "3": "The Legend of Zelda is in the Top 10 list .", "4": "The Legend of Zelda is made by a Japanese game company .", "5": "the Top 10 list is a game in the Top 10 list .", "6": "the Top 10 list is made by Japanese game companies .", "7": "The Legend of Zelda is a game in the Top 10 list .", "8": "The Legend of Zelda is made by Japanese game companies ."}, {"0": "the Legend of Zelda is made by a Japanese game company .", "1": "FIFA 22 is not the Legend of Zelda .", "2": "FIFA 22 is not made by a Japanese game company ."}], "errors": [[]], "entailments_dict": [{"3": ["7"], "8": ["4"], "6": ["4"]}, {"2": ["1"], "(¬2)": ["1"]}], "predicted_steps": [true, false]}
{"text": "A Japanese game company created the game the Legend of Zelda. All games in the Top 10 list are made by Japanese game companies. [BG] If a game sells more than one million copies, then it will be selected into the Top 10 list. The Legend of Zelda sold more than one million copies.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The Legend of Zelda is not in the Top 10 list?", "id": "14", "ground_truth": "False", "reasoning": " No, it is not true that The Legend of Zelda is not in the Top 10 list.\n\nPremise 1: All games in the Top 10 list are made by Japanese game companies.\nPremise 2: The Legend of Zelda is made by a Japanese game company.\nConclusion 1: The Legend of Zelda is in the Top 10 list.\n\nPremise 3: If a game sells more than one million copies, then it will be selected into the Top 10 list.\nPremise 4: The Legend of Zelda sold more than one million copies.\nConclusion 2: The Legend of Zelda is in the Top 10 list.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((4→5)∪(6→7)), 2], [(((5∧6)→7)∪((8∧9)→a)), 3]]", "logic_conclusion": "[3, 4]", "correspondance": [{"0": "X is a game in the Top 10 list .", "1": "X is made by Japanese game companies .", "2": "The Legend of Zelda is made by a Japanese game company .", "3": "The Legend of Zelda is in the Top 10 list .", "4": "the Top 10 list is a game in the Top 10 list .", "5": "the Top 10 list is made by Japanese game companies .", "6": "The Legend of Zelda is a game in the Top 10 list .", "7": "The Legend of Zelda is made by Japanese game companies ."}, {"0": "X is a game", "1": "X sells more than one million copies .", "2": "X will be selected into the Top 10 list .", "3": "The Legend of Zelda sold more than one million copies .", "4": "The Legend of Zelda is in the Top 10 list .", "5": "the Top 10 list is a game", "6": "the Top 10 list sells more than one million copies .", "7": "the Top 10 list will be selected into the Top 10 list .", "8": "The Legend of Zelda is a game", "9": "The Legend of Zelda sells more than one million copies .", "a": "The Legend of Zelda will be selected into the Top 10 list ."}], "errors": [[]], "entailments_dict": [{"7": ["2"], "5": ["2"], "3": ["6"]}, {"3": ["9", "8"], "4": ["8"], "a": ["4"]}], "predicted_steps": [false, true]}
{"text": "All squares have four sides. All four-sided things are shapes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that All squares are shapes?", "id": "15", "ground_truth": "True", "reasoning": " Sure! Here's my reasoning:\n\nPremise 1.1: All squares have four sides.\nPremise 1.2: All four-sided things are shapes.\nConclusion 1: All squares are four-sided.\n\nPremise 2.1: All squares are four-sided.\nPremise 2.2: All four-sided things are shapes.\nConclusion 2: All squares are shapes.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)]]", "logic_conclusion": "[(4→5), (4→5)]", "correspondance": [{"0": "X is a square .", "1": "X has four sides .", "2": "X is a four - sided thing .", "3": "X is a shape .", "4": "X is a square .", "5": "X is four - sided ."}, {"0": "X is a square .", "1": "X is four - sided .", "2": "X is a four - sided thing .", "3": "X is a shape .", "4": "X is a square .", "5": "X is a shape ."}], "errors": [[]], "entailments_dict": [{"1": ["2", "5"], "4": ["0", "2"]}, {"1": ["2", "5"], "4": ["0", "2"], "3": ["5"]}], "predicted_steps": [true, true]}
{"text": "All rabbits are cute. Some turtles exist. An animal is either a rabbit or a squirrel. If something is skittish, then it is not still. All squirrels are skittish. Rock is still.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Rock is a turtle?", "id": "16", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All rabbits are cute.\nPremise 1.2: Some turtles exist.\nConclusion 1: Some turtles are cute.\n\nPremise 2.1: An animal is either a rabbit or a squirrel.\nPremise 2.2: All squirrels are skittish.\nConclusion 2: If something is skittish, then it is not a rabbit.\n\nPremise 3.1: If something is skittish, then it is not still.\nPremise 3.2: Rock is still.\nConclusion 3: Rock is not skittish.\n\nPremise 4.1: All squirrels are skittish.\nPremise 4.2: Rock is not skittish.\nConclusion 4: Rock is not a squirrel.\n\nPremise 5.1: Rock is not a squirrel.\nPremise 5.2: An animal is either a rabbit or a squirrel.\nConclusion 5: Rock is a rabbit.\n\nTherefore, the answer is A. Yes, Rock is a turtle.", "logic_premises": "[[(0→1), 2], [(0→(1⊻2)), (3→4)], [(0→1), 2], [(4→5), 2], [0, (5→(6⊻7))]]", "logic_conclusion": "[3, (5→6), 3, 3, 4]", "correspondance": [{"0": "X is a rabbit .", "1": "X is cute .", "2": "Some turtles exist .", "3": "Some turtles are cute ."}, {"0": "X is An animal", "1": "X is a rabbit .", "2": "X is a squirrel .", "3": "X is a squirrel .", "4": "X is skittish .", "5": "X is skittish .", "6": "X is not a rabbit ."}, {"0": "X is skittish .", "1": "X is not still .", "2": "Rock is still .", "3": "Rock is not skittish ."}, {"0": "X is a squirrel .", "1": "X is skittish .", "2": "Rock is not skittish .", "3": "Rock is not a squirrel .", "4": "Rock is a squirrel .", "5": "Rock is skittish ."}, {"0": "Rock is not a squirrel .", "1": "X is An animal", "2": "X is a rabbit .", "3": "X is a squirrel .", "4": "Rock is a rabbit .", "5": "Rock is An animal", "6": "Rock is a rabbit .", "7": "Rock is a squirrel ."}], "errors": [[]], "entailments_dict": [{"3": ["2"]}, {"2": ["3", "6"], "1": ["(¬2)"], "(¬6)": ["0"]}, {"2": ["3", "(¬1)"], "1": ["(¬2)"]}, {"5": ["(¬2)"], "2": ["(¬5)"], "(¬3)": ["4"]}, {"6": ["0", "4", "(¬7)"], "4": ["0", "5", "(¬7)"], "7": ["(¬0)"], "0": ["(¬7)"], "(¬0)": ["5"], "(¬5)": ["0"]}], "predicted_steps": [false, false, true, true, false]}
{"text": "All rabbits are cute. Some turtles exist. An animal is either a rabbit or a squirrel. If something is skittish, then it is not still. All squirrels are skittish. Rock is still.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Rock is not a turtle?", "id": "17", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All rabbits are cute.\nPremise 1.2: Some turtles exist.\nConclusion 1: Some turtles are not cute.\n\nPremise 2.1: An animal is either a rabbit or a squirrel.\nPremise 2.2: All squirrels are skittish.\nConclusion 2: If an animal is skittish, then it is not a rabbit.\n\nPremise 3.1: If something is skittish, then it is not still.\nPremise 3.2: Rock is still.\nConclusion 3: Rock is not skittish.\n\nPremise 4.1: All squirrels are skittish.\nPremise 4.2: Rock is not skittish.\nConclusion 4: Rock is not a squirrel.\n\nPremise 5.1: Rock is not a squirrel.\nPremise 5.2: Rock is not a turtle.\nConclusion 5: Rock is not a turtle.\n\nTherefore, the answer is A. Yes, it is true that Rock is not a turtle.", "logic_premises": "[[(0→1), 2], [(0→(1⊻2)), (3→4)], [(0→1), 2], [(4→5), 2], [0, 1]]", "logic_conclusion": "[3, ((5∧6)→7), 3, 3, 2]", "correspondance": [{"0": "X is a rabbit .", "1": "X is cute .", "2": "Some turtles exist .", "3": "Some turtles are not cute ."}, {"0": "X is An animal", "1": "X is a rabbit .", "2": "X is a squirrel .", "3": "X is a squirrel .", "4": "X is skittish .", "5": "X is an animal", "6": "X is skittish .", "7": "X is not a rabbit ."}, {"0": "X is skittish .", "1": "X is not still .", "2": "Rock is still .", "3": "Rock is not skittish ."}, {"0": "X is a squirrel .", "1": "X is skittish .", "2": "Rock is not skittish .", "3": "Rock is not a squirrel .", "4": "Rock is a squirrel .", "5": "Rock is skittish ."}, {"0": "Rock is not a squirrel .", "1": "Rock is not a turtle .", "2": "Rock is not a turtle ."}], "errors": [[]], "entailments_dict": [{"(¬3)": ["2"]}, {"2": ["3", "7"], "5": ["0"], "1": ["(¬2)"], "(¬7)": ["0"]}, {"2": ["3", "(¬1)"], "1": ["(¬2)"]}, {"5": ["(¬2)"], "2": ["(¬5)"], "(¬3)": ["4"]}, {"2": ["1"], "1": ["2"], "(¬2)": ["0"], "(¬1)": ["0"]}], "predicted_steps": [false, false, true, true, true]}
{"text": "All rabbits are cute. Some turtles exist. An animal is either a rabbit or a squirrel. If something is skittish, then it is not still. All squirrels are skittish. Rock is still.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Rock is a turtle or cute?", "id": "18", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All rabbits are cute.\nPremise 1.2: Some turtles exist.\nConclusion 1: Some cute animals exist.\n\nPremise 2.1: An animal is either a rabbit or a squirrel.\nPremise 2.2: All squirrels are skittish.\nConclusion 2: If an animal is skittish, then it is not a rabbit.\n\nPremise 3.1: If something is skittish, then it is not still.\nPremise 3.2: Rock is still.\nConclusion 3: Rock is not skittish.\n\nPremise 4.1: If an animal is not skittish, then it is a rabbit or a turtle.\nPremise 4.2: Rock is not skittish.\nConclusion 4: Rock is a rabbit or a turtle.\n\nPremise 5.1: All turtles are cute.\nConclusion 5: Rock is cute.\n\nTherefore, the answer is A. Yes, Rock is a turtle or cute.", "logic_premises": "[[(0→1), 2], [(0→(1⊻2)), (3→4)], [(0→1), 2], [((0∧1)→2), 3], [(0→1)]]", "logic_conclusion": "[3, ((5∧6)→7), 3, (4∨5), 2]", "correspondance": [{"0": "X is a rabbit .", "1": "X is cute .", "2": "Some turtles exist .", "3": "Some cute animals exist ."}, {"0": "X is An animal", "1": "X is a rabbit .", "2": "X is a squirrel .", "3": "X is a squirrel .", "4": "X is skittish .", "5": "X is an animal", "6": "X is skittish .", "7": "X is not a rabbit ."}, {"0": "X is skittish .", "1": "X is not still .", "2": "Rock is still .", "3": "Rock is not skittish ."}, {"0": "X is an animal", "1": "X is not skittish .", "2": "X is a rabbit or a turtle .", "3": "Rock is not skittish .", "4": "Rock is a rabbit .", "5": "Rock is a turtle ."}, {"0": "X is a turtle .", "1": "X is cute .", "2": "Rock is cute ."}], "errors": [[]], "entailments_dict": [{"2": ["3"]}, {"2": ["3", "7"], "5": ["0"], "1": ["(¬2)"], "(¬7)": ["0"]}, {"2": ["3", "(¬1)"], "1": ["(¬2)"]}, {"5": ["0"]}, {}], "predicted_steps": [true, false, true, false, false]}
{"text": "All rabbits are cute. Some turtles exist. An animal is either a rabbit or a squirrel. If something is skittish, then it is not still. All squirrels are skittish. Rock is still.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Rock is not both a turtle and a squirrel, then Rock is either cute or skittish?", "id": "19", "ground_truth": "True", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: All rabbits are cute.\nPremise 1.2: Some turtles exist.\nPremise 1.3: An animal is either a rabbit or a squirrel.\nPremise 2.1: If something is skittish, then it is not still.\nPremise 2.2: All squirrels are skittish.\nPremise 2.3: Rock is still.\n\nConclusion 1: Rock is not a squirrel. (follows from 1.3 and 2.2)\n\nConclusion 2: Rock is not skittish. (follows from 2.1 and 2.3)\n\nConclusion 3: Rock is cute or skittish. (follows from 1.1 and 2.3)\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(c→d), 2, (e→(f⊻g)), (h→i), (j→k), a]]", "logic_conclusion": "[b]", "correspondance": [{"0": "X is a rabbit .", "1": "X is cute .", "2": "Some turtles exist .", "3": "X is An animal", "4": "X is a rabbit .", "5": "X is a squirrel .", "6": "X is skittish .", "7": "X is not still .", "8": "X is a squirrel .", "9": "X is skittish .", "a": "Rock is still .", "b": "Rock is not a squirrel . .", "c": "Rock is a rabbit .", "d": "Rock is cute .", "e": "Rock is An animal", "f": "Rock is a rabbit .", "g": "Rock is a squirrel .", "h": "Rock is skittish .", "i": "Rock is not still .", "j": "Rock is a squirrel .", "k": "Rock is skittish ."}], "errors": [[]], "entailments_dict": [{"k": ["e", "h"], "f": ["c", "b", "(¬g)"], "g": ["j"], "b": ["e", "(¬g)"], "a": ["(¬k)", "(¬i)"], "i": ["(¬a)"], "(¬b)": ["e", "j"]}], "predicted_steps": [false]}
{"text": "All rabbits are cute. Some turtles exist. An animal is either a rabbit or a squirrel. If something is skittish, then it is not still. All squirrels are skittish. Rock is still.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Rock is cute and still, then Rock is a turtle and skittish?", "id": "20", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All rabbits are cute.\nPremise 1.2: Some turtles exist.\nConclusion 1: Some cute animals exist.\n\nPremise 2.1: An animal is either a rabbit or a squirrel.\nPremise 2.2: All squirrels are skittish.\nConclusion 2: If an animal is skittish, then it is not a rabbit.\n\nPremise 3.1: If something is skittish, then it is not still.\nPremise 3.2: Rock is still.\nConclusion 3: Rock is not skittish.\n\nPremise 4.1: If Rock is cute and still, then Rock is a turtle.\nPremise 4.2: Rock is not skittish.\nConclusion 4: Rock is not a turtle.\n\nConclusion 5: Therefore, the statement \"If Rock is cute and still, then Rock is a turtle and skittish\" is false.\n\nAnswer: B. No", "logic_premises": "[[(0→1), 2], [(0→(1⊻2)), (3→4)], [(0→1), 2], [((0∧1)→2), 3]]", "logic_conclusion": "[3, ((5∧6)→7), 3, 4]", "correspondance": [{"0": "X is a rabbit .", "1": "X is cute .", "2": "Some turtles exist .", "3": "Some cute animals exist ."}, {"0": "X is An animal", "1": "X is a rabbit .", "2": "X is a squirrel .", "3": "X is a squirrel .", "4": "X is skittish .", "5": "X is an animal", "6": "X is skittish .", "7": "X is not a rabbit ."}, {"0": "X is skittish .", "1": "X is not still .", "2": "Rock is still .", "3": "Rock is not skittish ."}, {"0": "Rock is cute .", "1": "Rock is still .", "2": "Rock is a turtle .", "3": "Rock is not skittish .", "4": "Rock is not a turtle ."}], "errors": [[]], "entailments_dict": [{"2": ["3"]}, {"2": ["3", "7"], "5": ["0"], "1": ["(¬2)"], "(¬7)": ["0"]}, {"2": ["3", "(¬1)"], "1": ["(¬2)"]}, {"4": ["(¬2)"], "(¬4)": ["1"]}], "predicted_steps": [true, false, true, false]}
{"text": "\"Stranger Things\" is a popular Netflix show. If a Netflix show is popular, Karen will binge-watch it. If and only if Karen binge-watches a Netflix show, she will download it. Karen does not download \"Black Mirror\". \"Black Mirror\" is a Netflix show. If Karen binge-watches a Netflix show, she will share it to Lisa.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Karen will share \"Stranger Things\" to Lisa?", "id": "21", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a Netflix show is popular, Karen will binge-watch it.\nPremise 1.2: \"Stranger Things\" is a popular Netflix show.\nConclusion 1: Karen will binge-watch \"Stranger Things\".\n\nPremise 2.1: If Karen binge-watches a Netflix show, she will download it.\nPremise 2.2: Karen does not download \"Black Mirror\".\nConclusion 2: Karen does not binge-watch \"Black Mirror\".\n\nPremise 3.1: If Karen binge-watches a Netflix show, she will share it to Lisa.\nPremise 3.2: Karen binge-watches \"Stranger Things\".\nConclusion 3: Karen will share \"Stranger Things\" to Lisa.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(((5∧6)→7)∪((8∧9)→a)), 3], [(0→1), 2], [(0→1), 2]]", "logic_conclusion": "[4, 3, 3]", "correspondance": [{"0": "X is a Netflix show", "1": "X is popular .", "2": "Karen will binge - watch X .", "3": "\" Stranger Things \" is a popular Netflix show .", "4": "Karen will binge - watch \" Stranger Things \" .", "5": "Karen is a Netflix show", "6": "Karen is popular .", "7": "Karen will binge - watch Karen .", "8": "Stranger Things is a Netflix show", "9": "Stranger Things is popular .", "a": "Karen will binge - watch Stranger Things ."}, {"0": "Karen binge - watches a Netflix show .", "1": "Karen will download a Netflix show .", "2": "Karen does not download \" Black Mirror \" .", "3": "Karen does not binge - watch \" Black Mirror \" ."}, {"0": "Karen binge - watches a Netflix show .", "1": "Karen will share a Netflix show to Lisa .", "2": "Karen binge - watches \" Stranger Things \" .", "3": "Karen will share \" Stranger Things \" to Lisa ."}], "errors": [[]], "entailments_dict": [{"3": ["9", "8"], "a": ["3", "4"], "4": ["8", "3"]}, {"2": ["3"], "(¬3)": ["0"], "(¬2)": ["0"]}, {"2": ["0"], "3": ["0"]}], "predicted_steps": [true, true, false]}
{"text": "\"Stranger Things\" is a popular Netflix show. If a Netflix show is popular, Karen will binge-watch it. If and only if Karen binge-watches a Netflix show, she will download it. Karen does not download \"Black Mirror\". \"Black Mirror\" is a Netflix show. If Karen binge-watches a Netflix show, she will share it to Lisa.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that \"Black Mirror\" is popular?", "id": "22", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a Netflix show is popular, Karen will binge-watch it.\nPremise 1.2: \"Stranger Things\" is a popular Netflix show.\nConclusion 1: Karen will binge-watch \"Stranger Things\".\n\nPremise 2.1: If and only if Karen binge-watches a Netflix show, she will download it.\nPremise 2.2: Karen does not download \"Black Mirror\".\nConclusion 2: Karen did not binge-watch \"Black Mirror\".\n\nPremise 3.1: If Karen binge-watches a Netflix show, she will share it to Lisa.\nPremise 3.2: Karen did not binge-watch \"Black Mirror\".\nConclusion 3: Karen did not share \"Black Mirror\" to Lisa.\n\nPremise 4.1: If \"Black Mirror\" is a popular Netflix show, Karen will binge-watch it.\nPremise 4.2: Karen did not binge-watch \"Black Mirror\".\nConclusion 4: \"Black Mirror\" is not a popular Netflix show.\n\nConclusion 5: The answer is B. No, it is not true that \"Black Mirror\" is popular.", "logic_premises": "[[(((5∧6)→7)∪((8∧9)→a)), 3], [(0∧1), 2], [(0→1), 2], [(0→1), 2]]", "logic_conclusion": "[4, 3, 3, 3]", "correspondance": [{"0": "X is a Netflix show", "1": "X is popular .", "2": "Karen will binge - watch X .", "3": "\" Stranger Things \" is a popular Netflix show .", "4": "Karen will binge - watch \" Stranger Things \" .", "5": "Karen is a Netflix show", "6": "Karen is popular .", "7": "Karen will binge - watch Karen .", "8": "Stranger Things is a Netflix show", "9": "Stranger Things is popular .", "a": "Karen will binge - watch Stranger Things ."}, {"0": "Karen binge - watches a Netflix show .", "1": "Karen will download a Netflix show .", "2": "Karen does not download \" Black Mirror \" .", "3": "Karen did not binge - watch \" Black Mirror \" ."}, {"0": "Karen binge - watches a Netflix show .", "1": "Karen will share a Netflix show to Lisa .", "2": "Karen did not binge - watch \" Black Mirror \" .", "3": "Karen did not share \" Black Mirror \" to Lisa ."}, {"0": "\" Black Mirror \" is a popular Netflix show .", "1": "Karen will binge - watch \" Black Mirror \" .", "2": "Karen did not binge - watch \" Black Mirror \" .", "3": "\" Black Mirror \" is not a popular Netflix show ."}], "errors": [[]], "entailments_dict": [{"3": ["9", "8"], "a": ["3", "4"], "4": ["8", "3"]}, {"2": ["3"], "(¬3)": ["0"], "(¬2)": ["0"]}, {"(¬2)": ["0"]}, {"1": ["(¬2)"], "(¬3)": ["0"], "(¬2)": ["0"]}], "predicted_steps": [true, true, false, true]}
{"text": "\"Stranger Things\" is a popular Netflix show. If a Netflix show is popular, Karen will binge-watch it. If and only if Karen binge-watches a Netflix show, she will download it. Karen does not download \"Black Mirror\". \"Black Mirror\" is a Netflix show. If Karen binge-watches a Netflix show, she will share it to Lisa.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Karen will share \"Black Mirror\" to Lisa?", "id": "23", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a Netflix show is popular, Karen will binge-watch it.\nPremise 1.2: \"Stranger Things\" is a popular Netflix show.\nConclusion 1: Karen will binge-watch \"Stranger Things\".\n\nPremise 2.1: If Karen binge-watches a Netflix show, she will download it.\nPremise 2.2: Karen does not download \"Black Mirror\".\nConclusion 2: Karen does not binge-watch \"Black Mirror\".\n\nPremise 3.1: If Karen binge-watches a Netflix show, she will share it to Lisa.\nPremise 3.2: Karen does not binge-watch \"Black Mirror\".\nConclusion 3: Karen will not share \"Black Mirror\" to Lisa.\n\nTherefore, the answer is B. No.", "logic_premises": "[[(((5∧6)→7)∪((8∧9)→a)), 3], [(0→1), 2], [(0→1), 2]]", "logic_conclusion": "[4, 3, 3]", "correspondance": [{"0": "X is a Netflix show", "1": "X is popular .", "2": "Karen will binge - watch X .", "3": "\" Stranger Things \" is a popular Netflix show .", "4": "Karen will binge - watch \" Stranger Things \" .", "5": "Karen is a Netflix show", "6": "Karen is popular .", "7": "Karen will binge - watch Karen .", "8": "Stranger Things is a Netflix show", "9": "Stranger Things is popular .", "a": "Karen will binge - watch Stranger Things ."}, {"0": "Karen binge - watches a Netflix show .", "1": "Karen will download a Netflix show .", "2": "Karen does not download \" Black Mirror \" .", "3": "Karen does not binge - watch \" Black Mirror \" ."}, {"0": "Karen binge - watches a Netflix show .", "1": "Karen will share a Netflix show to Lisa .", "2": "Karen does not binge - watch \" Black Mirror \" .", "3": "Karen will not share \" Black Mirror \" to Lisa ."}], "errors": [[]], "entailments_dict": [{"3": ["9", "8"], "a": ["3", "4"], "4": ["8", "3"]}, {"2": ["3"], "(¬3)": ["0"], "(¬2)": ["0"]}, {"(¬2)": ["0"]}], "predicted_steps": [true, true, false]}
{"text": "Beijing is the capital of the People's Republic of China. Beijing is the world's most populous national capital city. Beijing is located in Northern China. Beijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games. Beijing has hosted both the Summer and Winter Olympics, along with the Summer and Winter Paralympics Many of Beijing's 91 universities consistently rank among the best in the Asia-Pacific and the world.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Beijing has hosted both the 2008 Summer Olympics and a winter olympics?", "id": "24", "ground_truth": "True", "reasoning": " Premise 1: Beijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.\nConclusion 1: Beijing has hosted the Summer Olympics and Summer Paralympics.\nPremise 2: Beijing has hosted both the Summer and Winter Olympics, along with the Summer and Winter Paralympics.\nConclusion 2: Beijing has hosted both the Summer and Winter Olympics.\nPremise 3: Beijing has hosted both the Summer and Winter Paralympics.\nConclusion 3: Beijing has hosted a winter Olympics.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0∧1)], [0], [0]]", "logic_conclusion": "[(2∧3), 1, 1]", "correspondance": [{"0": "Beijing hosted the 2008 Summer Olympics .", "1": "Beijing hosted 2008 Summer Paralympics Games .", "2": "Beijing has hosted the 2008 Summer Olympics .", "3": "Beijing has hosted 2008 Summer Paralympics Games ."}, {"0": "Beijing has hosted both the Summer and Winter Olympics , along with the Summer and Winter Paralympics .", "1": "Beijing has hosted both the Summer and Winter Olympics ."}, {"0": "Beijing has hosted both the Summer and Winter Paralympics .", "1": "Beijing has hosted a winter Olympics ."}], "errors": [[]], "entailments_dict": [{"3": ["1", "0"], "2": ["1", "0"], "1": ["3", "2"], "0": ["3", "2"]}, {"1": ["0"], "0": ["1"]}, {"0": ["1"]}], "predicted_steps": [true, true, true]}
{"text": "Beijing is the capital of the People's Republic of China. Beijing is the world's most populous national capital city. Beijing is located in Northern China. Beijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games. Beijing has hosted both the Summer and Winter Olympics, along with the Summer and Winter Paralympics Many of Beijing's 91 universities consistently rank among the best in the Asia-Pacific and the world.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Beijing is located in southern China?", "id": "25", "ground_truth": "Uncertain", "reasoning": " Premise 1: Beijing is located in Northern China.\nConclusion 1: Beijing is not located in southern China.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0]]", "logic_conclusion": "[1]", "correspondance": [{"0": "Beijing is located in Northern China .", "1": "Beijing is not located in southern China ."}], "errors": [[]], "entailments_dict": [{"1": ["0"]}], "predicted_steps": [false]}
{"text": "Beijing is the capital of the People's Republic of China. Beijing is the world's most populous national capital city. Beijing is located in Northern China. Beijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games. Beijing has hosted both the Summer and Winter Olympics, along with the Summer and Winter Paralympics Many of Beijing's 91 universities consistently rank among the best in the Asia-Pacific and the world.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Beijing is the second largest Chinese city by urban population?", "id": "26", "ground_truth": "Uncertain", "reasoning": " Premise 1: Beijing is the capital of the People's Republic of China.\nPremise 2: Beijing is the world's most populous national capital city.\nConclusion 1: Beijing has a large population.\nPremise 3: Beijing is located in Northern China.\nPremise 4: Beijing hosted the 2008 Summer Olympics and 2008 Summer Paralympics Games.\nConclusion 2: Beijing is a significant city in China.\nPremise 5: Many of Beijing's 91 universities consistently rank among the best in the Asia-Pacific and the world.\nConclusion 3: Beijing has a strong education system.\nPremise 6: Beijing has hosted both the Summer and Winter Olympics, along with the Summer and Winter Paralympics.\nConclusion 4: Beijing has a rich sports history.\nPremise 7: Beijing is the second largest Chinese city by urban population.\nConclusion 5: The statement is true.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [0, (1∧2)], [(0∧1)], [0], [0]]", "logic_conclusion": "[3, 3, 2, 1, 1]", "correspondance": [{"0": "X is a the capital of the a person 's Republic of China .", "1": "Beijing is X .", "2": "Beijing is the world 's most populous national capital city .", "3": "Beijing has a large population .", "4": "the capital of the Peoples Republic of China is a the capital of the a person 's Republic of China .", "5": "Beijing is the capital of the Peoples Republic of China .", "6": "Beijing is a the capital of the a person 's Republic of China .", "7": "Beijing is Beijing .", "8": "the worlds most populous national capital city is a the capital of the a person 's Republic of China .", "9": "Beijing is the worlds most populous national capital city ."}, {"0": "Beijing is located in Northern China .", "1": "Beijing hosted the 2008 Summer Olympics .", "2": "Beijing hosted 2008 Summer Paralympics Games .", "3": "Beijing is a significant city in China ."}, {"0": "Many of Beijing 's 's 91 universities consistently rank among the best in the Asia - Pacific .", "1": "Many of Beijing 's 's 91 universities consistently rank among the best in the world .", "2": "Beijing 's has a strong education system ."}, {"0": "Beijing has hosted both the Summer and Winter Olympics , along with the Summer and Winter Paralympics .", "1": "Beijing has a rich sports history ."}, {"0": "Beijing is the second largest Chinese city by urban population .", "1": "The statement is true ."}], "errors": [[]], "entailments_dict": [{"3": ["2", "4", "8"], "2": ["3", "4", "8", "6"], "7": ["2"], "9": ["2", "3"]}, {"1": ["0", "3"], "0": ["2", "1", "3"], "3": ["0", "1", "2"], "2": ["3"]}, {"2": ["1", "0"], "1": ["2"], "0": ["2"]}, {"1": ["0"], "0": ["1"]}, {"0": ["1"]}], "predicted_steps": [true, true, true, true, true]}
{"text": "All aliens are extraterrestrial. If someone is from Mars, then they are aliens. No extraterrestrial is human. Everyone from Earth is a human. Marvin cannot be from Earth and from Mars. If Marvin is not from Earth, then Marvin is an extraterrestrial.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Marvin is an alien?", "id": "27", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All aliens are extraterrestrial.\nPremise 1.2: If someone is from Mars, then they are aliens.\nConclusion 1: If someone is from Mars, then they are extraterrestrial.\n\nPremise 2.1: No extraterrestrial is human.\nPremise 2.2: Everyone from Earth is a human.\nConclusion 2: If someone is from Earth, then they are not extraterrestrial.\n\nPremise 3.1: Marvin cannot be from Earth and from Mars.\nPremise 3.2: If Marvin is not from Earth, then Marvin is an extraterrestrial.\nConclusion 3: If Marvin is not from Earth, then Marvin is an alien.\n\nPremise 4.1: Marvin is not from Earth.\nConclusion 4: Marvin is an alien.\n\nTherefore, the answer is A. Yes, it is true that Marvin is an alien.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [0, (1→2)], [0]]", "logic_conclusion": "[(4→5), (4→5), (3→4), 1]", "correspondance": [{"0": "X is an alien .", "1": "X is extraterrestrial .", "2": "X is from Mars .", "3": "X are aliens .", "4": "X is from Mars .", "5": "X are extraterrestrial ."}, {"0": "X is an extraterrestrial .", "1": "X is not human .", "2": "X is a person from Earth .", "3": "X is a human .", "4": "X is from Earth .", "5": "X are not extraterrestrial ."}, {"0": "Marvin can not be from Earth and from Mars .", "1": "Marvin is not from Earth .", "2": "Marvin is an extraterrestrial .", "3": "Marvin is not from Earth .", "4": "Marvin is an alien ."}, {"0": "Marvin is not from Earth .", "1": "Marvin is an alien ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"], "1": ["5"]}, {"4": ["2"], "3": ["5", "(¬1)"], "1": ["(¬3)"], "(¬5)": ["0"], "(¬2)": ["0"]}, {"0": ["1", "4"], "2": ["0", "4"], "3": ["0", "1"], "(¬4)": ["1"]}, {"1": ["0"], "0": ["1"], "(¬1)": ["0"]}], "predicted_steps": [true, true, false, true]}
{"text": "All aliens are extraterrestrial. If someone is from Mars, then they are aliens. No extraterrestrial is human. Everyone from Earth is a human. Marvin cannot be from Earth and from Mars. If Marvin is not from Earth, then Marvin is an extraterrestrial.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Marvin is neither a human nor from Mars?", "id": "28", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All aliens are extraterrestrial.\nPremise 1.2: If someone is from Mars, then they are aliens.\nConclusion 1: If someone is from Mars, then they are extraterrestrial.\n\nPremise 2.1: No extraterrestrial is human.\nPremise 2.2: Everyone from Earth is a human.\nConclusion 2: If someone is extraterrestrial, then they are not human.\n\nPremise 3.1: Marvin cannot be from Earth and from Mars.\nPremise 3.2: If Marvin is not from Earth, then Marvin is an extraterrestrial.\nConclusion 3: If Marvin is not from Earth, then Marvin is not human.\n\nPremise 4.1: If Marvin is not human, then Marvin is an extraterrestrial.\nConclusion 4: Marvin is an extraterrestrial.\n\nConclusion 5: Therefore, the answer is A. Yes, Marvin is neither a human nor from Mars.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [0, (1→2)], [(0→1)]]", "logic_conclusion": "[(4→5), (4→5), (3→4), 2]", "correspondance": [{"0": "X is an alien .", "1": "X is extraterrestrial .", "2": "X is from Mars .", "3": "X are aliens .", "4": "X is from Mars .", "5": "X are extraterrestrial ."}, {"0": "X is an extraterrestrial .", "1": "X is not human .", "2": "X is a person from Earth .", "3": "X is a human .", "4": "X is extraterrestrial .", "5": "X are not human ."}, {"0": "Marvin can not be from Earth and from Mars .", "1": "Marvin is not from Earth .", "2": "Marvin is an extraterrestrial .", "3": "Marvin is not from Earth .", "4": "Marvin is not human ."}, {"0": "Marvin is not human .", "1": "Marvin is an extraterrestrial .", "2": "Marvin is an extraterrestrial ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"], "1": ["5"]}, {"4": ["0", "(¬3)"], "1": ["5", "(¬3)"], "3": ["(¬1)"], "(¬5)": ["2"], "(¬2)": ["0"]}, {"0": ["1"], "2": ["0", "4"], "3": ["0", "1"]}, {"2": ["0"], "1": ["2"]}], "predicted_steps": [true, true, false, false]}
{"text": "All aliens are extraterrestrial. If someone is from Mars, then they are aliens. No extraterrestrial is human. Everyone from Earth is a human. Marvin cannot be from Earth and from Mars. If Marvin is not from Earth, then Marvin is an extraterrestrial.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Marvin is not from Mars, then Marvin is a human?", "id": "29", "ground_truth": "Uncertain", "reasoning": " No.\n\nPremise 1: All aliens are extraterrestrial.\nPremise 2: If someone is from Mars, then they are aliens.\nPremise 3: No extraterrestrial is human.\nPremise 4: Everyone from Earth is a human.\nPremise 5: Marvin cannot be from Earth and from Mars.\nPremise 6: If Marvin is not from Earth, then Marvin is an extraterrestrial.\nConclusion: If Marvin is not from Mars, then Marvin is not a human.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((d→e)∪((f→g)∪(h→i))), ((j→k)∪((l→m)∪(n→o))), ((p→q)∪((r→s)∪(t→u))), ((v→w)∪((x→y)∪(z→A))), 8, (9→a)]]", "logic_conclusion": "[(b→c)]", "correspondance": [{"0": "X is an alien .", "1": "X is extraterrestrial .", "2": "X is from Mars .", "3": "X are aliens .", "4": "X is an extraterrestrial .", "5": "X is not human .", "6": "X is a person from Earth .", "7": "X is a human .", "8": "Marvin can not be from Earth and from Mars .", "9": "Marvin is not from Earth .", "a": "Marvin is an extraterrestrial .", "b": "Marvin is not from Mars .", "c": "Marvin is not a human .", "d": "Marvin is an alien .", "e": "Marvin is extraterrestrial .", "f": "Mars is an alien .", "g": "Mars is extraterrestrial .", "h": "Earth is an alien .", "i": "Earth is extraterrestrial .", "j": "Marvin is from Mars .", "k": "Marvin are aliens .", "l": "Mars is from Mars .", "m": "Mars are aliens .", "n": "Earth is from Mars .", "o": "Earth are aliens .", "p": "Marvin is an extraterrestrial .", "q": "Marvin is not human .", "r": "Mars is an extraterrestrial .", "s": "Mars is not human .", "t": "Earth is an extraterrestrial .", "u": "Earth is not human .", "v": "Marvin is a person from Earth .", "w": "Marvin is a human .", "x": "Mars is a person from Earth .", "y": "Mars is a human .", "z": "Earth is a person from Earth .", "A": "Earth is a human ."}], "errors": [[]], "entailments_dict": [{"m": ["r", "f", "p", "8", "(¬w)", "(¬y)"], "k": ["8", "p", "9", "d", "c", "(¬y)", "(¬A)", "(¬w)"], "e": ["8", "p", "9", "c", "(¬w)", "(¬y)"], "a": ["8", "p", "d", "c", "(¬w)", "(¬y)"], "g": ["8", "r", "(¬y)"], "8": ["p", "d", "9", "(¬o)", "(¬y)", "(¬i)"], "s": ["8", "f", "(¬y)"], "q": ["d", "c", "(¬y)", "(¬w)"], "i": ["t", "(¬k)", "(¬w)", "(¬u)", "(¬a)", "(¬o)", "(¬y)", "(¬8)", "(¬A)", "(¬m)"], "b": ["v", "8", "(¬k)", "(¬a)"], "A": ["(¬s)", "(¬8)", "(¬q)", "(¬m)", "(¬i)", "(¬k)", "(¬u)", "(¬e)", "(¬a)", "(¬o)", "(¬g)"], "u": ["(¬A)", "(¬o)", "(¬y)"], "y": ["(¬i)", "(¬8)", "(¬k)", "(¬e)", "(¬g)", "(¬s)", "(¬u)", "(¬a)", "(¬q)", "(¬m)", "(¬o)"], "o": ["(¬g)", "(¬u)", "(¬e)", "(¬a)", "(¬w)", "(¬s)", "(¬8)", "(¬q)", "(¬y)", "(¬i)", "(¬A)"], "w": ["(¬u)", "(¬e)", "(¬a)", "(¬o)", "(¬s)", "(¬8)", "(¬q)", "(¬k)"], "(¬c)": ["v"], "(¬8)": ["j"], "(¬9)": ["v"], "(¬v)": ["p", "9", "d", "8"], "(¬j)": ["8"], "(¬n)": ["8"], "(¬d)": ["v", "9"], "(¬x)": ["r"], "(¬p)": ["v", "9"]}], "predicted_steps": [false]}
{"text": "A person is either a Grand Slam champion or an Oscar-nominated actor. All people who are Grand Slam champions are professional tennis players. All Oscar-nominated actors are celebrities. All professional tennis players are athletes. If a person is a celebrity then they are well paid. If a person is an athlete then they are famous. All well-paid people live in tax havens. If Djokovic is famous and is an athlete, then Djokovic lives in well paid.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Djokovic is a Grand Slam champion?", "id": "30", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: A person is either a Grand Slam champion or an Oscar-nominated actor.\nPremise 1.2: All people who are Grand Slam champions are professional tennis players.\nPremise 1.3: All professional tennis players are athletes.\nPremise 1.4: If a person is a celebrity, then they are well-paid.\nPremise 1.5: If a person is an athlete, then they are famous.\nPremise 1.6: All well-paid people live in tax havens.\nPremise 1.7: Djokovic is famous and is an athlete.\nConclusion 1: Djokovic lives in a tax haven.\n\nPremise 2.1: Djokovic lives in a tax haven.\nConclusion 2: Djokovic is a Grand Slam champion.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((i→(j⊻k))∪((l→(m⊻n))∪(o→(p⊻q)))), ((r→s)∪((t→u)∪(v→w))), ((x→y)∪((z→A)∪(B→C))), (((D∧E)→F)∪(((G∧H)→I)∪((J∧K)→L))), (((M∧N)→O)∪(((P∧Q)→R)∪((S∧T)→U))), ((V→W)∪((X→Y)∪(Z→!))), (f∧g)], [0]]", "logic_conclusion": "[h, 1]", "correspondance": [{"0": "X is A person", "1": "X is a Grand Slam champion .", "2": "X is an Oscar - nominated actor .", "3": "X is a person who is Grand Slam champions .", "4": "X is professional tennis a player .", "5": "X is a professional tennis player .", "6": "X is an athlete .", "7": "X is a person", "8": "X is a celebrity .", "9": "X are well - paid .", "a": "X is a person", "b": "X is an athlete .", "c": "X are famous .", "d": "X is a well - paid person .", "e": "X lives in tax havens .", "f": "Djokovic is famous .", "g": "Djokovic is an athlete .", "h": "Djokovic lives in a tax haven .", "i": "Oscar is A person", "j": "Oscar is a Grand Slam champion .", "k": "Oscar is an Oscar - nominated actor .", "l": "Grand Slam champions is A person", "m": "Grand Slam champions is a Grand Slam champion .", "n": "Grand Slam champions is an Oscar - nominated actor .", "o": "Djokovic is A person", "p": "Djokovic is a Grand Slam champion .", "q": "Djokovic is an Oscar - nominated actor .", "r": "Oscar is a person who is Grand Slam champions .", "s": "Oscar is professional tennis a player .", "t": "Grand Slam champions is a person who is Grand Slam champions .", "u": "Grand Slam champions is professional tennis a player .", "v": "Djokovic is a person who is Grand Slam champions .", "w": "Djokovic is professional tennis a player .", "x": "Oscar is a professional tennis player .", "y": "Oscar is an athlete .", "z": "Grand Slam champions is a professional tennis player .", "A": "Grand Slam champions is an athlete .", "B": "Djokovic is a professional tennis player .", "C": "Djokovic is an athlete .", "D": "Oscar is a person", "E": "Oscar is a celebrity .", "F": "Oscar are well - paid .", "G": "Grand Slam champions is a person", "H": "Grand Slam champions is a celebrity .", "I": "Grand Slam champions are well - paid .", "J": "Djokovic is a person", "K": "Djokovic is a celebrity .", "L": "Djokovic are well - paid .", "M": "Oscar is a person", "N": "Oscar is an athlete .", "O": "Oscar are famous .", "P": "Grand Slam champions is a person", "Q": "Grand Slam champions is an athlete .", "R": "Grand Slam champions are famous .", "S": "Djokovic is a person", "T": "Djokovic is an athlete .", "U": "Djokovic are famous .", "V": "Oscar is a well - paid person .", "W": "Oscar lives in tax havens .", "X": "Grand Slam champions is a well - paid person .", "Y": "Grand Slam champions lives in tax havens .", "Z": "Djokovic is a well - paid person .", "!": "Djokovic lives in tax havens ."}, {"0": "Djokovic lives in a tax haven .", "1": "Djokovic is a Grand Slam champion ."}], "errors": [[]], "entailments_dict": [{"m": ["r", "t", "G", "H", "T", "z", "Q", "J", "P", "S", "v", "g"], "w": ["z", "Q", "J", "S", "f", "g", "o", "l", "T", "G", "P", "B", "(¬q)"], "U": ["l", "g", "o", "t", "H", "v", "B", "f", "K", "J"], "L": ["Z", "S", "o", "B", "X"], "u": ["S", "g", "o", "X", "H", "T", "G", "P", "B", "z", "Q", "J", "l", "(¬n)"], "j": ["Q", "J", "S", "g", "D", "t", "E", "X", "v", "x", "T", "N", "r", "B", "M"], "C": ["P", "S", "f", "K", "l", "v", "g", "o", "t", "G", "H", "T", "Q", "J", "(¬q)"], "s": ["D", "M", "Q", "l", "g", "x", "T", "i", "N", "(¬q)"], "p": ["B", "Q", "J", "S", "f", "K", "v", "T", "g", "t"], "g": ["o", "t", "G", "H", "v", "B", "T", "Q", "P", "S", "K", "J", "l", "(¬q)"], "A": ["l", "X", "v", "T", "g", "r", "t", "G", "P", "i", "Q", "J", "S", "o"], "R": ["K", "v", "t", "H", "f"], "W": ["i"], "f": ["B", "Q", "K", "J", "S", "o", "t", "l", "H", "v", "T"], "y": ["i", "N", "D", "M"], "!": ["S", "J", "o", "h"], "O": ["E"], "k": ["D", "M", "E"], "F": ["V"], "n": ["t", "H", "(¬A)"], "I": ["X", "Z", "v"], "h": ["o", "J", "S"], "q": ["(¬s)"], "(¬l)": ["t"]}, {}], "predicted_steps": [true, false]}
{"text": "A person is either a Grand Slam champion or an Oscar-nominated actor. All people who are Grand Slam champions are professional tennis players. All Oscar-nominated actors are celebrities. All professional tennis players are athletes. If a person is a celebrity then they are well paid. If a person is an athlete then they are famous. All well-paid people live in tax havens. If Djokovic is famous and is an athlete, then Djokovic lives in well paid.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Djokovic lives in a tax haven?", "id": "31", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: A person is either a Grand Slam champion or an Oscar-nominated actor.\nPremise 1.2: All people who are Grand Slam champions are professional tennis players.\nPremise 1.3: All Oscar-nominated actors are celebrities.\nPremise 2.1: All professional tennis players are athletes.\nPremise 2.2: If a person is a celebrity, then they are well paid.\nPremise 2.3: If a person is an athlete, then they are famous.\nPremise 3.1: All well-paid people live in tax havens.\nPremise 3.2: If Djokovic is famous and is an athlete, then Djokovic lives in well paid.\nConclusion 1: Djokovic is a professional tennis player.\nConclusion 2: Djokovic is a celebrity.\nConclusion 3: Djokovic is famous.\nConclusion 4: Djokovic lives in a tax haven.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((l→(m⊻n))∪((o→(p⊻q))∪(r→(s⊻t)))), ((u→v)∪((w→x)∪(y→z))), ((A→B)∪((C→D)∪(E→F))), ((G→H)∪((I→J)∪(K→L))), (((M∧N)→O)∪(((P∧Q)→R)∪((S∧T)→U))), (((V∧W)→X)∪(((Y∧Z)→!)∪((\"∧#)→$))), ((%→&)∪((*→+)∪(,→-))), ((h∧i)→j)]]", "logic_conclusion": "[k]", "correspondance": [{"0": "X is A person", "1": "X is a Grand Slam champion .", "2": "X is an Oscar - nominated actor .", "3": "X is a person who is Grand Slam champions .", "4": "X is professional tennis a player .", "5": "X is an Oscar - nominated actor .", "6": "X is a celebrity .", "7": "X is a professional tennis player .", "8": "X is an athlete .", "9": "X is a person", "a": "X is a celebrity .", "b": "X are well paid .", "c": "X is a person", "d": "X is an athlete .", "e": "X are famous .", "f": "X is a well - paid person .", "g": "X lives in tax havens .", "h": "Djokovic is famous .", "i": "Djokovic is an athlete .", "j": "Djokovic lives in well paid .", "k": "Djokovic is a professional tennis player .", "l": "Oscar is A person", "m": "Oscar is a Grand Slam champion .", "n": "Oscar is an Oscar - nominated actor .", "o": "Grand Slam champions is A person", "p": "Grand Slam champions is a Grand Slam champion .", "q": "Grand Slam champions is an Oscar - nominated actor .", "r": "Djokovic is A person", "s": "Djokovic is a Grand Slam champion .", "t": "Djokovic is an Oscar - nominated actor .", "u": "Oscar is a person who is Grand Slam champions .", "v": "Oscar is professional tennis a player .", "w": "Grand Slam champions is a person who is Grand Slam champions .", "x": "Grand Slam champions is professional tennis a player .", "y": "Djokovic is a person who is Grand Slam champions .", "z": "Djokovic is professional tennis a player .", "A": "Oscar is an Oscar - nominated actor .", "B": "Oscar is a celebrity .", "C": "Grand Slam champions is an Oscar - nominated actor .", "D": "Grand Slam champions is a celebrity .", "E": "Djokovic is an Oscar - nominated actor .", "F": "Djokovic is a celebrity .", "G": "Oscar is a professional tennis player .", "H": "Oscar is an athlete .", "I": "Grand Slam champions is a professional tennis player .", "J": "Grand Slam champions is an athlete .", "K": "Djokovic is a professional tennis player .", "L": "Djokovic is an athlete .", "M": "Oscar is a person", "N": "Oscar is a celebrity .", "O": "Oscar are well paid .", "P": "Grand Slam champions is a person", "Q": "Grand Slam champions is a celebrity .", "R": "Grand Slam champions are well paid .", "S": "Djokovic is a person", "T": "Djokovic is a celebrity .", "U": "Djokovic are well paid .", "V": "Oscar is a person", "W": "Oscar is an athlete .", "X": "Oscar are famous .", "Y": "Grand Slam champions is a person", "Z": "Grand Slam champions is an athlete .", "!": "Grand Slam champions are famous .", "\"": "Djokovic is a person", "#": "Djokovic is an athlete .", "$": "Djokovic are famous .", "%": "Oscar is a well - paid person .", "&": "Oscar lives in tax havens .", "*": "Grand Slam champions is a well - paid person .", "+": "Grand Slam champions lives in tax havens .", ",": "Djokovic is a well - paid person .", "-": "Djokovic lives in tax havens ."}], "errors": [[]], "entailments_dict": [{"v": ["l", "o", "G", "W", "i", "#", "Z", "V", "M", "(¬t)"], "J": ["\"", "y", "i", "*", "r", "Y", "#", "Z", "P", "l", "S", "w", "u", "o", "k"], "L": ["Q", "#", "Z", "P", "S", "T", "w", "o", "r", "\"", "h", "y", "i", "Y", "k", "(¬t)"], "z": ["P", "K", "S", "I", "o", "\"", "h", "i", "r", "Y", "#", "Z", "k", "(¬t)"], "p": ["\"", "y", "i", "Y", "Q", "#", "Z", "P", "S", "w", "u", "I"], "x": ["Y", "Q", "#", "Z", "S", "I", "o", "K", "\"", "r", "P", "i", "*", "k", "(¬q)"], "$": ["w", "o", "T", "y", "h", "i", "r", "Q", "K", "S", "k"], "H": ["V", "M", "l", "W"], "m": ["G", "\"", "W", "y", "i", "*", "N", "#", "Z", "V", "S", "M", "K", "w", "u", "k"], "-": ["\"", "S", "r"], "F": ["\"", "T", "h", "y", "i", "*", "Y", "Q", "#", "Z", "P", "S", "K", "w", "o", "r", ",", "k"], "n": ["V", "A", "M", "N"], "!": ["Q", "w", "T", "h", "y"], "q": ["C", "Q", "w", "(¬J)"], "s": ["K", "w", "\"", "T", "h", "y", "i", "#", "Z", "S", "k"], "D": ["\"", "T", "r", "P", "y", "h", "i", "*", "Y", "Q", "#", "Z", "S", "w", "I", "o"], "B": ["V", "M", "l", "N"], "U": ["r", "\"", "*", ",", "K", "k"], "t": ["E", "(¬v)"], "R": ["y", ","], "j": [",", "(¬U)"], "O": ["%"], "X": ["N"], "&": ["l"], "k": ["r", "o", "y", "w", "K", "P", "S", "Q", "T", "\"", "Z", "#", "Y", ",", "h", "i", "(¬t)"], "(¬o)": ["w"], "(¬E)": ["r"], "(¬C)": ["Z"]}], "predicted_steps": [false]}
{"text": "A person is either a Grand Slam champion or an Oscar-nominated actor. All people who are Grand Slam champions are professional tennis players. All Oscar-nominated actors are celebrities. All professional tennis players are athletes. If a person is a celebrity then they are well paid. If a person is an athlete then they are famous. All well-paid people live in tax havens. If Djokovic is famous and is an athlete, then Djokovic lives in well paid.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Djokovic does not live in a tax haven?", "id": "32", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: A person is either a Grand Slam champion or an Oscar-nominated actor.\nPremise 1.2: All people who are Grand Slam champions are professional tennis players.\nPremise 1.3: All Oscar-nominated actors are celebrities.\nPremise 2.1: All professional tennis players are athletes.\nPremise 2.2: If a person is a celebrity, then they are well paid.\nPremise 2.3: If a person is an athlete, then they are famous.\nPremise 3.1: All well-paid people live in tax havens.\nPremise 3.2: If Djokovic is famous and is an athlete, then Djokovic lives in well paid.\n\nConclusion 1: Djokovic is a professional tennis player and an athlete.\nConclusion 2: Djokovic is famous.\nConclusion 3: Djokovic is well paid.\nConclusion 4: Djokovic lives in a tax haven.\n\nTherefore, the answer is B. No, it is not true that Djokovic does not live in a tax haven.", "logic_premises": "[[((m→(n⊻o))∪((p→(q⊻r))∪(s→(t⊻u)))), ((v→w)∪((x→y)∪(z→A))), ((B→C)∪((D→E)∪(F→G))), ((H→I)∪((J→K)∪(L→M))), (((N∧O)→P)∪(((Q∧R)→S)∪((T∧U)→V))), (((W∧X)→Y)∪(((Z∧!)→\")∪((#∧$)→%))), ((&→*)∪((+→,)∪(-→.))), ((h∧i)→j)]]", "logic_conclusion": "[(k∧l)]", "correspondance": [{"0": "X is A person", "1": "X is a Grand Slam champion .", "2": "X is an Oscar - nominated actor .", "3": "X is a person who is Grand Slam champions .", "4": "X is professional tennis a player .", "5": "X is an Oscar - nominated actor .", "6": "X is a celebrity .", "7": "X is a professional tennis player .", "8": "X is an athlete .", "9": "X is a person", "a": "X is a celebrity .", "b": "X are well paid .", "c": "X is a person", "d": "X is an athlete .", "e": "X are famous .", "f": "X is a well - paid person .", "g": "X lives in tax havens .", "h": "Djokovic is famous .", "i": "Djokovic is an athlete .", "j": "Djokovic lives in well paid .", "k": "Djokovic is a professional tennis player .", "l": "Djokovic is an athlete .", "m": "Oscar is A person", "n": "Oscar is a Grand Slam champion .", "o": "Oscar is an Oscar - nominated actor .", "p": "Grand Slam champions is A person", "q": "Grand Slam champions is a Grand Slam champion .", "r": "Grand Slam champions is an Oscar - nominated actor .", "s": "Djokovic is A person", "t": "Djokovic is a Grand Slam champion .", "u": "Djokovic is an Oscar - nominated actor .", "v": "Oscar is a person who is Grand Slam champions .", "w": "Oscar is professional tennis a player .", "x": "Grand Slam champions is a person who is Grand Slam champions .", "y": "Grand Slam champions is professional tennis a player .", "z": "Djokovic is a person who is Grand Slam champions .", "A": "Djokovic is professional tennis a player .", "B": "Oscar is an Oscar - nominated actor .", "C": "Oscar is a celebrity .", "D": "Grand Slam champions is an Oscar - nominated actor .", "E": "Grand Slam champions is a celebrity .", "F": "Djokovic is an Oscar - nominated actor .", "G": "Djokovic is a celebrity .", "H": "Oscar is a professional tennis player .", "I": "Oscar is an athlete .", "J": "Grand Slam champions is a professional tennis player .", "K": "Grand Slam champions is an athlete .", "L": "Djokovic is a professional tennis player .", "M": "Djokovic is an athlete .", "N": "Oscar is a person", "O": "Oscar is a celebrity .", "P": "Oscar are well paid .", "Q": "Grand Slam champions is a person", "R": "Grand Slam champions is a celebrity .", "S": "Grand Slam champions are well paid .", "T": "Djokovic is a person", "U": "Djokovic is a celebrity .", "V": "Djokovic are well paid .", "W": "Oscar is a person", "X": "Oscar is an athlete .", "Y": "Oscar are famous .", "Z": "Grand Slam champions is a person", "!": "Grand Slam champions is an athlete .", "\"": "Grand Slam champions are famous .", "#": "Djokovic is a person", "$": "Djokovic is an athlete .", "%": "Djokovic are famous .", "&": "Oscar is a well - paid person .", "*": "Oscar lives in tax havens .", "+": "Grand Slam champions is a well - paid person .", ",": "Grand Slam champions lives in tax havens .", "-": "Djokovic is a well - paid person .", ".": "Djokovic lives in tax havens ."}], "errors": [[]], "entailments_dict": [{"n": ["#", "O", "L", "X", "v", "x", "T", "+", "!", "H", "W", "$", "i", "N", "z", "l", "k"], "M": ["z", "Q", "#", "Z", "R", "U", "p", "$", "x", "T", "h", "s", "!", "i", "l", "k", "(¬u)"], "G": ["i", "z", "L", "Q", "#", "Z", "R", "-", "U", "p", "x", "T", "s", "+", "!", "$", "h", "l", "k"], "V": ["-", "s", "+", "L", "#", "k"], "C": ["O", "m", "W", "N"], "E": ["$", "x", "T", "h", "i", "z", "#", "Z", "U", "Q", "J", "R", "p", "s", "+", "!", "l"], "\"": ["x", "h", "z", "R", "U"], "K": ["!", "$", "i", "z", "Q", "#", "Z", "m", "p", "v", "x", "T", "s", "+", "l", "k"], "I": ["N", "W", "m", "X"], "y": ["!", "$", "i", "L", "Q", "#", "Z", "J", "R", "p", "T", "s", "+", "l", "k", "(¬r)"], "t": ["L", "U", "x", "T", "!", "$", "h", "i", "z", "#", "l", "k"], "%": ["p", "x", "T", "s", "h", "i", "z", "L", "R", "U", "l", "k"], "q": ["z", "Q", "J", "R", "v", "$", "x", "T", "i", "!", "#", "Z", "l"], "A": ["p", "T", "s", "!", "$", "h", "i", "L", "Q", "#", "Z", "J", "l", "k", "(¬u)"], "w": ["m", "X", "p", "$", "N", "!", "H", "W", "i", "l", "(¬u)"], ".": ["T", "#", "s"], "o": ["W", "B", "N", "O"], "*": ["m"], "u": ["F", "(¬w)"], "Y": ["O"], "S": ["z", "-"], "r": ["R", "D", "x", "(¬K)"], "P": ["&"], "j": ["-", "(¬V)"], "l": ["s", "p", "z", "x", "L", "U", "R", "Q", "T", "Z", "$", "#", "!", "h", "i", "(¬u)"], "k": ["s", "p", "z", "x", "L", "U", "R", "Q", "T", "Z", "$", "#", "!", "-", "h", "i", "(¬u)"], "(¬D)": ["!"], "(¬p)": ["x"], "(¬F)": ["s"]}], "predicted_steps": [false]}
{"text": "Diamond Mine is a professional wrestling stable, formed in WWE. Roderick Strong leads Diamond Mine. Diamond Mine includes the Creed Brothers, and Ivy Nile. Imperium has a feud with Diamond Mine.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Roderick strong leads a professional wrestling stable?", "id": "33", "ground_truth": "True", "reasoning": " Premise 1: Roderick Strong leads Diamond Mine.\nConclusion 1: Roderick Strong leads a professional wrestling stable.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0]]", "logic_conclusion": "[1]", "correspondance": [{"0": "Roderick Strong leads Diamond Mine .", "1": "Roderick Strong leads a professional wrestling stable ."}], "errors": [[]], "entailments_dict": [{"1": ["0"], "0": ["1"], "(¬1)": ["0"]}], "predicted_steps": [true]}
{"text": "Diamond Mine is a professional wrestling stable, formed in WWE. Roderick Strong leads Diamond Mine. Diamond Mine includes the Creed Brothers, and Ivy Nile. Imperium has a feud with Diamond Mine.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Roderick strong leads the Creed Brothers?", "id": "34", "ground_truth": "Uncertain", "reasoning": " Premise 1.1: Roderick Strong leads Diamond Mine.\nPremise 1.2: Diamond Mine includes the Creed Brothers.\nConclusion 1: Roderick Strong leads the Creed Brothers.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, 1]]", "logic_conclusion": "[2]", "correspondance": [{"0": "Roderick Strong leads Diamond Mine .", "1": "Diamond Mine includes the Creed Brothers .", "2": "Roderick Strong leads the Creed Brothers ."}], "errors": [[]], "entailments_dict": [{"1": ["0", "2"], "0": ["1", "2"]}], "predicted_steps": [true]}
{"text": "Diamond Mine is a professional wrestling stable, formed in WWE. Roderick Strong leads Diamond Mine. Diamond Mine includes the Creed Brothers, and Ivy Nile. Imperium has a feud with Diamond Mine.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Imperium doesn't have a feud with a professional wrestling stable that includes Ivy Nile?", "id": "35", "ground_truth": "False", "reasoning": " Premise 1: Diamond Mine is a professional wrestling stable, formed in WWE.\nPremise 2: Roderick Strong leads Diamond Mine.\nPremise 3: Diamond Mine includes the Creed Brothers and Ivy Nile.\nPremise 4: Imperium has a feud with Diamond Mine.\nConclusion 1: Imperium has a feud with a professional wrestling stable that includes Ivy Nile.\n\nTherefore, the answer is B. No. Imperium does have a feud with a professional wrestling stable that includes Ivy Nile.", "logic_premises": "[[0, 1, (2∧3), 4]]", "logic_conclusion": "[5]", "correspondance": [{"0": "Diamond Mine is a professional wrestling stable , formed in WWE .", "1": "Roderick Strong leads Diamond Mine .", "2": "Diamond Mine includes the Creed Brothers .", "3": "Diamond Mine includes Ivy Nile .", "4": "Imperium has a feud with Diamond Mine .", "5": "Imperium has a feud with a professional wrestling stable that includes Ivy Nile ."}], "errors": [[]], "entailments_dict": [{"0": ["2", "3", "1"], "2": ["1", "0", "5"], "1": ["3", "0", "2", "5"], "5": ["0", "3"], "4": ["5"]}], "predicted_steps": [true]}
{"text": "Symphony No. 9 is a music piece. Composers write music pieces. Beethoven wrote Symphony No. 9. Vienna Music Society premiered Symphony No. 9. Vienna Music Society is an orchestra. Beethoven leads the Vienna Music Society. Orchestras are led by conductors.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Beethoven is a composer?", "id": "36", "ground_truth": "True", "reasoning": " Yes, it is true that Beethoven is a composer.\n\nPremise 1: Composers write music pieces.\nPremise 2: Beethoven wrote Symphony No. 9.\nConclusion 1: Beethoven is a composer.\n\nThis conclusion follows logically from the premises. Therefore, the answer is A. Yes.", "logic_premises": "[[((5→6)∪(7→8)), ((9→a)∪(b→c))]]", "logic_conclusion": "[4]", "correspondance": [{"0": "X is a Composer .", "1": "X writes music pieces .", "2": "X is a Symphony . 9 .", "3": "Beethoven did not write X .", "4": "Beethoven is a composer .", "5": "Beethoven is a Composer .", "6": "Beethoven writes music pieces .", "7": "Symphony No. 9 is a Composer .", "8": "Symphony No. 9 writes music pieces .", "9": "Beethoven is a Symphony . 9 .", "a": "Beethoven did not write Beethoven .", "b": "Symphony No. 9 is a Symphony . 9 .", "c": "Beethoven did not write Symphony No. 9 ."}], "errors": [[]], "entailments_dict": [{"6": ["b", "4", "(¬c)", "(¬a)"], "8": ["b", "4", "(¬c)", "(¬a)"], "4": ["5", "b", "(¬a)"], "c": ["(¬8)"], "(¬7)": ["b"]}], "predicted_steps": [false]}
{"text": "Symphony No. 9 is a music piece. Composers write music pieces. Beethoven wrote Symphony No. 9. Vienna Music Society premiered Symphony No. 9. Vienna Music Society is an orchestra. Beethoven leads the Vienna Music Society. Orchestras are led by conductors.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Some orchestras premiered music pieces?", "id": "37", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Composers write music pieces.\nPremise 1.2: Beethoven wrote Symphony No. 9.\nConclusion 1: Beethoven is a composer.\n\nPremise 2.1: Symphony No. 9 is a music piece.\nPremise 2.2: Beethoven wrote Symphony No. 9.\nConclusion 2: Beethoven wrote Symphony No. 9.\n\nPremise 3.1: Vienna Music Society premiered Symphony No. 9.\nPremise 3.2: Vienna Music Society is an orchestra.\nConclusion 3: An orchestra premiered Symphony No. 9.\n\nPremise 4.1: Beethoven leads the Vienna Music Society.\nPremise 4.2: Orchestras are led by conductors.\nConclusion 4: Beethoven is a conductor.\n\nPremise 5.1: Some orchestras are led by conductors.\nConclusion 5: Some orchestras premiered music pieces.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((5→6)∪(7→8)), ((9→a)∪(b→c))], [0, ((5→6)∪(7→8))], [((5→6)∪(7→8)), 2], [0, 1], [0]]", "logic_conclusion": "[4, ((9→a)∪(b→c)), ((9→a)∪(b→c)), 2, 1]", "correspondance": [{"0": "X is a Composer .", "1": "X writes music pieces .", "2": "X is a Symphony . 9 .", "3": "Beethoven did not write X .", "4": "Beethoven is a composer .", "5": "Beethoven is a Composer .", "6": "Beethoven writes music pieces .", "7": "Symphony No. 9 is a Composer .", "8": "Symphony No. 9 writes music pieces .", "9": "Beethoven is a Symphony . 9 .", "a": "Beethoven did not write Beethoven .", "b": "Symphony No. 9 is a Symphony . 9 .", "c": "Beethoven did not write Symphony No. 9 ."}, {"0": "Symphony No . 9 is a music piece .", "1": "X is a Symphony . 9 .", "2": "Beethoven did not write X .", "3": "X is a Symphony . 9 .", "4": "Beethoven did not write X .", "5": "Beethoven is a Symphony . 9 .", "6": "Beethoven did not write Beethoven .", "7": "Symphony No. 9 is a Symphony . 9 .", "8": "Beethoven did not write Symphony No. 9 .", "9": "Beethoven is a Symphony . 9 .", "a": "Beethoven did not write Beethoven .", "b": "Symphony No. 9 is a Symphony . 9 .", "c": "Beethoven did not write Symphony No. 9 ."}, {"0": "X is a Symphony . 9 .", "1": "Vienna Music Society did not premiere X .", "2": "Vienna Music Society is an orchestra .", "3": "X is a Symphony . 9 .", "4": "An orchestra did not premiere X .", "5": "Vienna Music Society is a Symphony . 9 .", "6": "Vienna Music Society did not premiere Vienna Music Society .", "7": "Symphony No. 9 is a Symphony . 9 .", "8": "Vienna Music Society did not premiere Symphony No. 9 .", "9": "Vienna Music Society is a Symphony . 9 .", "a": "An orchestra did not premiere Vienna Music Society .", "b": "Symphony No. 9 is a Symphony . 9 .", "c": "An orchestra did not premiere Symphony No. 9 ."}, {"0": "Beethoven leads the Vienna Music Society .", "1": "Orchestras are led by conductors .", "2": "Beethoven is a conductor ."}, {"0": "Some orchestras are led by conductors .", "1": "Some orchestras premiered music pieces ."}], "errors": [[]], "entailments_dict": [{"6": ["b", "4", "(¬c)", "(¬a)"], "8": ["b", "4", "(¬c)", "(¬a)"], "4": ["5", "b", "(¬a)"], "c": ["(¬8)"], "(¬7)": ["b"]}, {"0": ["5", "7", "(¬8)", "(¬6)"], "9": ["5", "0", "7", "(¬8)", "(¬6)"], "b": ["7", "0", "5", "(¬8)"], "8": ["c"], "6": ["a", "c"], "(¬7)": ["0"], "(¬c)": ["0", "7"], "(¬a)": ["0", "7", "5"]}, {"2": ["5", "(¬6)"], "9": ["5", "7", "2", "(¬8)", "(¬6)"], "b": ["7"], "8": ["c"], "6": ["a"], "(¬c)": ["7"], "(¬a)": ["7", "2"]}, {"0": ["1", "2"], "2": ["0", "1"]}, {"0": ["1"]}], "predicted_steps": [false, false, "Contradiction in the premises", true, true]}
{"text": "Symphony No. 9 is a music piece. Composers write music pieces. Beethoven wrote Symphony No. 9. Vienna Music Society premiered Symphony No. 9. Vienna Music Society is an orchestra. Beethoven leads the Vienna Music Society. Orchestras are led by conductors.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Beethoven is not a conductor?", "id": "38", "ground_truth": "False", "reasoning": " Here is my reasoning:\n\nPremise 1.1: Composers write music pieces.\nPremise 1.2: Beethoven wrote Symphony No. 9.\nConclusion 1: Beethoven is a composer.\n\nPremise 2.1: Vienna Music Society premiered Symphony No. 9.\nPremise 2.2: Vienna Music Society is an orchestra.\nConclusion 2: Symphony No. 9 was premiered by an orchestra.\n\nPremise 3.1: Beethoven leads the Vienna Music Society.\nPremise 3.2: Orchestras are led by conductors.\nConclusion 3: Beethoven is a conductor.\n\nPremise 4.1: Beethoven is a conductor.\nConclusion 4: Beethoven is not a conductor (this conclusion contradicts our previous conclusion).\n\nTherefore, the answer is B. No. It is not true that Beethoven is not a conductor.", "logic_premises": "[[((5→6)∪(7→8)), ((9→a)∪(b→c))], [((4→5)∪(6→7)), 2], [0, 1], [0]]", "logic_conclusion": "[4, 3, 2, 1]", "correspondance": [{"0": "X is a Composer .", "1": "X writes music pieces .", "2": "X is a Symphony . 9 .", "3": "Beethoven did not write X .", "4": "Beethoven is a composer .", "5": "Beethoven is a Composer .", "6": "Beethoven writes music pieces .", "7": "Symphony No. 9 is a Composer .", "8": "Symphony No. 9 writes music pieces .", "9": "Beethoven is a Symphony . 9 .", "a": "Beethoven did not write Beethoven .", "b": "Symphony No. 9 is a Symphony . 9 .", "c": "Beethoven did not write Symphony No. 9 ."}, {"0": "X is a Symphony . 9 .", "1": "Vienna Music Society did not premiere X .", "2": "Vienna Music Society is an orchestra .", "3": "Symphony No . 9 was premiered by an orchestra .", "4": "Vienna Music Society is a Symphony . 9 .", "5": "Vienna Music Society did not premiere Vienna Music Society .", "6": "Symphony No. 9 is a Symphony . 9 .", "7": "Vienna Music Society did not premiere Symphony No. 9 ."}, {"0": "Beethoven leads the Vienna Music Society .", "1": "Orchestras are led by conductors .", "2": "Beethoven is a conductor ."}, {"0": "Beethoven is a conductor .", "1": "Beethoven is not a conductor ."}], "errors": [[]], "entailments_dict": [{"6": ["b", "4", "(¬c)", "(¬a)"], "8": ["b", "4", "(¬c)", "(¬a)"], "4": ["5", "b", "(¬a)"], "c": ["(¬8)"], "(¬7)": ["b"]}, {"2": ["4", "3", "(¬5)"], "3": ["6", "(¬7)", "(¬5)"]}, {"0": ["1", "2"], "2": ["0", "1"]}, {"1": ["(¬0)"], "(¬1)": ["0"]}], "predicted_steps": [false, true, true, false]}
{"text": "All of Zaha Hadid's design styles are timeless. No mass product design is timeless. Either Zaha Hadid's design style or Kelly Wearstler's design style. All of Kelly Wearstler's design styles are evocative. All of Kelly Wearstler's design styles are dreamy. If a design by Max is timeless, then a design by Max is a mass product design and evocative.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that A design by Max is a mass product design?", "id": "39", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All of Zaha Hadid's design styles are timeless.\nPremise 1.2: No mass product design is timeless.\nConclusion 1: Zaha Hadid's design style is not a mass product design.\n\nPremise 2.1: Either Zaha Hadid's design style or Kelly Wearstler's design style.\nPremise 2.2: All of Kelly Wearstler's design styles are evocative.\nConclusion 2: Kelly Wearstler's design style is evocative.\n\nPremise 3.1: All of Kelly Wearstler's design styles are dreamy.\nConclusion 3: Kelly Wearstler's design style is dreamy.\n\nPremise 4.1: If a design by Max is timeless, then a design by Max is a mass product design and evocative.\nPremise 4.2: A design by Max is timeless.\nConclusion 4: A design by Max is a mass product design and evocative.\n\nPremise 5.1: A design by Max is a mass product design.\nConclusion 5: B. No, it is not true that a design by Max is a mass product design.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((5→6)∪(7→8)), ((9→a)∪(b→c))], [0, ((4→5)∪(6→7))], [((3→4)∪(5→6))], [((5∧6)→7), 3], [(0→1)]]", "logic_conclusion": "[4, 3, 2, 4, (2→3)]", "correspondance": [{"0": "X is of a Zaha Hadid 's 's design styles .", "1": "X is timeless .", "2": "X is a mass product design .", "3": "X is not timeless .", "4": "Zaha Hadid 's 's design style is not a mass product design .", "5": "Zaha Hadids design style is of a Zaha Hadid 's 's design styles .", "6": "Zaha Hadids design style is timeless .", "7": "Zaha Hadids design styles is of a Zaha Hadid 's 's design styles .", "8": "Zaha Hadids design styles is timeless .", "9": "Zaha Hadids design style is a mass product design .", "a": "Zaha Hadids design style is not timeless .", "b": "Zaha Hadids design styles is a mass product design .", "c": "Zaha Hadids design styles is not timeless ."}, {"0": "Either Zaha Hadid 's design style or Kelly Wearstler 's 's design style .", "1": "X is of a Kelly Wearstler 's 's design styles .", "2": "X is evocative .", "3": "Kelly Wearstler 's 's design style is evocative .", "4": "Kelly Wearstlers design style is of a Kelly Wearstler 's 's design styles .", "5": "Kelly Wearstlers design style is evocative .", "6": "Kelly Wearstlers design styles is of a Kelly Wearstler 's 's design styles .", "7": "Kelly Wearstlers design styles is evocative ."}, {"0": "X is of a Kelly Wearstler 's 's design styles .", "1": "X is dreamy .", "2": "Kelly Wearstler 's 's design style is dreamy .", "3": "Kelly Wearstlers design style is of a Kelly Wearstler 's 's design styles .", "4": "Kelly Wearstlers design style is dreamy .", "5": "Kelly Wearstlers design styles is of a Kelly Wearstler 's 's design styles .", "6": "Kelly Wearstlers design styles is dreamy ."}, {"0": "X is a design by Max", "1": "X is timeless .", "2": "X is a mass product design and evocative .", "3": "A design by Max is timeless .", "4": "A design by Max is a mass product design and evocative .", "5": "Max is a design by Max", "6": "Max is timeless .", "7": "Max is a mass product design and evocative ."}, {"0": "X is A design by Max", "1": "X is a mass product design .", "2": "B. No , it is not true that X is a design by Max", "3": "B. No , it is not true that X is a mass product design ."}], "errors": [[]], "entailments_dict": [{"8": ["(¬c)", "(¬a)"], "c": ["(¬6)", "(¬8)"], "a": ["(¬6)", "(¬8)"], "6": ["(¬c)", "(¬a)"], "(¬4)": ["5", "9", "b"]}, {"3": ["4", "6"], "7": ["3"], "5": ["3"], "0": ["4", "6"]}, {"2": ["3", "5"], "4": ["2"], "6": ["2"]}, {"3": ["5"], "7": ["4"]}, {}], "predicted_steps": [true, true, false, false, false]}
{"text": "All of Zaha Hadid's design styles are timeless. No mass product design is timeless. Either Zaha Hadid's design style or Kelly Wearstler's design style. All of Kelly Wearstler's design styles are evocative. All of Kelly Wearstler's design styles are dreamy. If a design by Max is timeless, then a design by Max is a mass product design and evocative.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that A design by Max is evocative and dreamy?", "id": "40", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All of Zaha Hadid's design styles are timeless.\nPremise 1.2: No mass product design is timeless.\nConclusion 1: Zaha Hadid's design style is not a mass product design.\n\nPremise 2.1: Either Zaha Hadid's design style or Kelly Wearstler's design style.\nPremise 2.2: All of Kelly Wearstler's design styles are evocative.\nConclusion 2: Kelly Wearstler's design style is evocative.\n\nPremise 3.1: All of Kelly Wearstler's design styles are dreamy.\nConclusion 3: Kelly Wearstler's design style is dreamy.\n\nPremise 4.1: If a design by Max is timeless, then a design by Max is a mass product design and evocative.\nPremise 4.2: A design by Max is timeless.\nConclusion 4: A design by Max is a mass product design and evocative.\n\nPremise 5.1: A design by Max is evocative.\nPremise 5.2: A design by Max is dreamy.\nConclusion 5: A design by Max is evocative and dreamy.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((5→6)∪(7→8)), ((9→a)∪(b→c))], [0, ((4→5)∪(6→7))], [((3→4)∪(5→6))], [((5∧6)→7), 3], [0, 1]]", "logic_conclusion": "[4, 3, 2, 4, (2∧3)]", "correspondance": [{"0": "X is of a Zaha Hadid 's 's design styles .", "1": "X is timeless .", "2": "X is a mass product design .", "3": "X is not timeless .", "4": "Zaha Hadid 's 's design style is not a mass product design .", "5": "Zaha Hadids design style is of a Zaha Hadid 's 's design styles .", "6": "Zaha Hadids design style is timeless .", "7": "Zaha Hadids design styles is of a Zaha Hadid 's 's design styles .", "8": "Zaha Hadids design styles is timeless .", "9": "Zaha Hadids design style is a mass product design .", "a": "Zaha Hadids design style is not timeless .", "b": "Zaha Hadids design styles is a mass product design .", "c": "Zaha Hadids design styles is not timeless ."}, {"0": "Either Zaha Hadid 's design style or Kelly Wearstler 's 's design style .", "1": "X is of a Kelly Wearstler 's 's design styles .", "2": "X is evocative .", "3": "Kelly Wearstler 's 's design style is evocative .", "4": "Kelly Wearstlers design style is of a Kelly Wearstler 's 's design styles .", "5": "Kelly Wearstlers design style is evocative .", "6": "Kelly Wearstlers design styles is of a Kelly Wearstler 's 's design styles .", "7": "Kelly Wearstlers design styles is evocative ."}, {"0": "X is of a Kelly Wearstler 's 's design styles .", "1": "X is dreamy .", "2": "Kelly Wearstler 's 's design style is dreamy .", "3": "Kelly Wearstlers design style is of a Kelly Wearstler 's 's design styles .", "4": "Kelly Wearstlers design style is dreamy .", "5": "Kelly Wearstlers design styles is of a Kelly Wearstler 's 's design styles .", "6": "Kelly Wearstlers design styles is dreamy ."}, {"0": "X is a design by Max", "1": "X is timeless .", "2": "X is a mass product design and evocative .", "3": "A design by Max is timeless .", "4": "A design by Max is a mass product design and evocative .", "5": "Max is a design by Max", "6": "Max is timeless .", "7": "Max is a mass product design and evocative ."}, {"0": "A design by Max is evocative .", "1": "A design by Max is dreamy .", "2": "A design by Max is evocative .", "3": "A design by Max is dreamy ."}], "errors": [[]], "entailments_dict": [{"8": ["(¬c)", "(¬a)"], "c": ["(¬6)", "(¬8)"], "a": ["(¬6)", "(¬8)"], "6": ["(¬c)", "(¬a)"], "(¬4)": ["5", "9", "b"]}, {"0": ["4", "6"], "3": ["4", "6"], "7": ["3"], "5": ["3"]}, {"2": ["3", "5"], "4": ["2"], "6": ["2"]}, {"3": ["5"], "7": ["4"]}, {"1": ["0", "3", "2"], "3": ["0", "1"], "2": ["0"], "0": ["2"]}], "predicted_steps": [true, true, false, false, true]}
{"text": "All of Zaha Hadid's design styles are timeless. No mass product design is timeless. Either Zaha Hadid's design style or Kelly Wearstler's design style. All of Kelly Wearstler's design styles are evocative. All of Kelly Wearstler's design styles are dreamy. If a design by Max is timeless, then a design by Max is a mass product design and evocative.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that A design by Max is either evocative or dreamy?", "id": "41", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All of Zaha Hadid's design styles are timeless.\nPremise 1.2: No mass product design is timeless.\nConclusion 1: Zaha Hadid's design style is not a mass product design.\n\nPremise 2.1: Either Zaha Hadid's design style or Kelly Wearstler's design style.\nPremise 2.2: All of Kelly Wearstler's design styles are evocative.\nConclusion 2: Kelly Wearstler's design style is evocative.\n\nPremise 3.1: All of Kelly Wearstler's design styles are dreamy.\nConclusion 3: Kelly Wearstler's design style is dreamy.\n\nPremise 4.1: If a design by Max is timeless, then a design by Max is a mass product design and evocative.\nPremise 4.2: A design by Max is timeless.\nConclusion 4: A design by Max is a mass product design and evocative.\n\nPremise 5.1: A design by Max is evocative.\nConclusion 5: A design by Max is either evocative or dreamy.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((5→6)∪(7→8)), ((9→a)∪(b→c))], [0, ((4→5)∪(6→7))], [((3→4)∪(5→6))], [((5∧6)→7), 3], [0]]", "logic_conclusion": "[4, 3, 2, 4, (1∨2)]", "correspondance": [{"0": "X is of a Zaha Hadid 's 's design styles .", "1": "X is timeless .", "2": "X is a mass product design .", "3": "X is not timeless .", "4": "Zaha Hadid 's 's design style is not a mass product design .", "5": "Zaha Hadids design style is of a Zaha Hadid 's 's design styles .", "6": "Zaha Hadids design style is timeless .", "7": "Zaha Hadids design styles is of a Zaha Hadid 's 's design styles .", "8": "Zaha Hadids design styles is timeless .", "9": "Zaha Hadids design style is a mass product design .", "a": "Zaha Hadids design style is not timeless .", "b": "Zaha Hadids design styles is a mass product design .", "c": "Zaha Hadids design styles is not timeless ."}, {"0": "Either Zaha Hadid 's design style or Kelly Wearstler 's 's design style .", "1": "X is of a Kelly Wearstler 's 's design styles .", "2": "X is evocative .", "3": "Kelly Wearstler 's 's design style is evocative .", "4": "Kelly Wearstlers design style is of a Kelly Wearstler 's 's design styles .", "5": "Kelly Wearstlers design style is evocative .", "6": "Kelly Wearstlers design styles is of a Kelly Wearstler 's 's design styles .", "7": "Kelly Wearstlers design styles is evocative ."}, {"0": "X is of a Kelly Wearstler 's 's design styles .", "1": "X is dreamy .", "2": "Kelly Wearstler 's 's design style is dreamy .", "3": "Kelly Wearstlers design style is of a Kelly Wearstler 's 's design styles .", "4": "Kelly Wearstlers design style is dreamy .", "5": "Kelly Wearstlers design styles is of a Kelly Wearstler 's 's design styles .", "6": "Kelly Wearstlers design styles is dreamy ."}, {"0": "X is a design by Max", "1": "X is timeless .", "2": "X is a mass product design and evocative .", "3": "A design by Max is timeless .", "4": "A design by Max is a mass product design and evocative .", "5": "Max is a design by Max", "6": "Max is timeless .", "7": "Max is a mass product design and evocative ."}, {"0": "A design by Max is evocative .", "1": "A design by Max is either evocative .", "2": "A design by Max is either dreamy ."}], "errors": [[]], "entailments_dict": [{"8": ["(¬c)", "(¬a)"], "c": ["(¬6)", "(¬8)"], "a": ["(¬6)", "(¬8)"], "6": ["(¬c)", "(¬a)"], "(¬4)": ["5", "9", "b"]}, {"0": ["4", "6"], "3": ["4", "6"], "7": ["3"], "5": ["3"]}, {"2": ["3", "5"], "4": ["2"], "6": ["2"]}, {"3": ["5"], "7": ["4"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [true, true, false, false, true]}
{"text": "If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis. Everyone who lost to Iga Świątek is ranked highly by the Women's Tennis Association. All female tennis players at Roland Garros 2022 lost to Iga Świątek. Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022. All male tennis players at Roland Garros 2022 lost to Rafael Nadal. If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Coco Gauff is among the most active players in major tennis?", "id": "42", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis.\nPremise 1.2: Everyone who lost to Iga Świątek is ranked highly by the Women's Tennis Association.\nPremise 2.1: All female tennis players at Roland Garros 2022 lost to Iga Świątek.\nPremise 2.2: Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022.\nConclusion 2: All male tennis players at Roland Garros 2022 lost to Rafael Nadal.\nPremise 3.1: If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.\nPremise 3.2: Coco Gauff is a player who is ranked highly by the Women's Tennis Association.\nConclusion 3: Coco Gauff is not a male tennis player at Roland Garros 2022.\nConclusion 4: Coco Gauff is among the most active players in major tennis.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(((a∧b)→c)∪(((d∧e)→f)∪(((g∧h)→i)∪(((j∧k)→l)∪((m∧n)→o))))), ((p→q)∪((r→s)∪((t→u)∪((v→w)∪(x→y))))), ((z→A)∪((B→C)∪((D→E)∪((F→G)∪(H→I))))), 7], [((0∨1)→2), 3]]", "logic_conclusion": "[((J→K)∪((L→M)∪((N→O)∪((P→Q)∪(R→S))))), 4]", "correspondance": [{"0": "X is a player", "1": "X is ranked highly by the Women 's Tennis Association .", "2": "X are among the most active players in major tennis .", "3": "X is a person who lost to Iga Świątek .", "4": "X is ranked highly by the Women 's Tennis Association .", "5": "X is a female tennis player at Roland Garros 2022 .", "6": "X lost to Iga Świątek .", "7": "Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022 .", "8": "X is a male tennis player at Roland Garros 2022 .", "9": "X lost to Rafael Nadal .", "a": "Iga Świątek is a player", "b": "Iga Świątek is ranked highly by the Women 's Tennis Association .", "c": "Iga Świątek are among the most active players in major tennis .", "d": "the most active players in major tennis is a player", "e": "the most active players in major tennis is ranked highly by the Women 's Tennis Association .", "f": "the most active players in major tennis are among the most active players in major tennis .", "g": "Roland Garros 2022 is a player", "h": "Roland Garros 2022 is ranked highly by the Women 's Tennis Association .", "i": "Roland Garros 2022 are among the most active players in major tennis .", "j": "Rafael Nadal is a player", "k": "Rafael Nadal is ranked highly by the Women 's Tennis Association .", "l": "Rafael Nadal are among the most active players in major tennis .", "m": "the Womens Tennis Association is a player", "n": "the Womens Tennis Association is ranked highly by the Women 's Tennis Association .", "o": "the Womens Tennis Association are among the most active players in major tennis .", "p": "Iga Świątek is a person who lost to Iga Świątek .", "q": "Iga Świątek is ranked highly by the Women 's Tennis Association .", "r": "the most active players in major tennis is a person who lost to Iga Świątek .", "s": "the most active players in major tennis is ranked highly by the Women 's Tennis Association .", "t": "Roland Garros 2022 is a person who lost to Iga Świątek .", "u": "Roland Garros 2022 is ranked highly by the Women 's Tennis Association .", "v": "Rafael Nadal is a person who lost to Iga Świątek .", "w": "Rafael Nadal is ranked highly by the Women 's Tennis Association .", "x": "the Womens Tennis Association is a person who lost to Iga Świątek .", "y": "the Womens Tennis Association is ranked highly by the Women 's Tennis Association .", "z": "Iga Świątek is a female tennis player at Roland Garros 2022 .", "A": "Iga Świątek lost to Iga Świątek .", "B": "the most active players in major tennis is a female tennis player at Roland Garros 2022 .", "C": "the most active players in major tennis lost to Iga Świątek .", "D": "Roland Garros 2022 is a female tennis player at Roland Garros 2022 .", "E": "Roland Garros 2022 lost to Iga Świątek .", "F": "Rafael Nadal is a female tennis player at Roland Garros 2022 .", "G": "Rafael Nadal lost to Iga Świątek .", "H": "the Womens Tennis Association is a female tennis player at Roland Garros 2022 .", "I": "the Womens Tennis Association lost to Iga Świątek .", "J": "Iga Świątek is a male tennis player at Roland Garros 2022 .", "K": "Iga Świątek lost to Rafael Nadal .", "L": "the most active players in major tennis is a male tennis player at Roland Garros 2022 .", "M": "the most active players in major tennis lost to Rafael Nadal .", "N": "Roland Garros 2022 is a male tennis player at Roland Garros 2022 .", "O": "Roland Garros 2022 lost to Rafael Nadal .", "P": "Rafael Nadal is a male tennis player at Roland Garros 2022 .", "Q": "Rafael Nadal lost to Rafael Nadal .", "R": "the Womens Tennis Association is a male tennis player at Roland Garros 2022 .", "S": "the Womens Tennis Association lost to Rafael Nadal ."}, {"0": "Coco Gauff is a player who is ranked highly by the Women 's Tennis Association .", "1": "Coco Gauff is a player who lost to Rafael Nadal .", "2": "Coco Gauff is not a male tennis player at Roland Garros 2022 .", "3": "Coco Gauff is a player who is ranked highly by the Women 's Tennis Association .", "4": "Coco Gauff is not a male tennis player at Roland Garros 2022 ."}], "errors": [[]], "entailments_dict": [{"C": ["a", "r", "p", "(¬c)"], "q": ["a", "b", "z", "(¬A)"], "7": ["b", "a", "j", "z", "(¬w)", "(¬A)"], "I": ["a", "p"], "s": ["e", "(¬o)", "(¬l)", "(¬A)"], "E": ["b", "a", "7"], "G": ["p", "v", "a", "j", "7"], "y": ["n", "(¬A)"], "u": ["h", "(¬A)"], "A": ["p", "a", "(¬7)"], "i": ["7"], "c": ["z", "(¬w)", "(¬A)"], "w": ["k"], "N": ["g", "j", "t", "7", "(¬A)"], "P": ["j", "7", "(¬A)"], "R": ["7", "(¬u)", "(¬w)", "(¬o)", "(¬C)", "(¬G)", "(¬A)", "(¬E)", "(¬I)"], "L": ["j", "7", "(¬c)", "(¬A)"], "J": ["v", "7", "(¬w)", "(¬C)", "(¬A)", "(¬E)", "(¬I)"], "f": ["(¬A)"], "o": ["(¬w)", "(¬A)"], "(¬p)": ["D", "a", "z"], "(¬t)": ["z", "a"], "(¬F)": ["j", "7"], "(¬H)": ["7"], "(¬z)": ["7"], "(¬D)": ["7"]}, {"3": ["0", "4"], "2": ["3", "4"], "4": ["0", "3"]}], "predicted_steps": ["Contradiction in the premises", true]}
{"text": "If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis. Everyone who lost to Iga Świątek is ranked highly by the Women's Tennis Association. All female tennis players at Roland Garros 2022 lost to Iga Świątek. Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022. All male tennis players at Roland Garros 2022 lost to Rafael Nadal. If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Coco Gauff has lost to Rafael Nadal?", "id": "43", "ground_truth": "Uncertain", "reasoning": " Here is my reasoning:\n\nPremise 1.1: If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis.\nPremise 1.2: Everyone who lost to Iga Świątek is ranked highly by the Women's Tennis Association.\nConclusion 1: All players who lost to Iga Świątek are among the most active players in major tennis.\n\nPremise 2.1: All female tennis players at Roland Garros 2022 lost to Iga Świątek.\nPremise 2.2: Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022.\nConclusion 2: All players at Roland Garros 2022 lost to Iga Świątek or Rafael Nadal.\n\nPremise 3.1: All male tennis players at Roland Garros 2022 lost to Rafael Nadal.\nConclusion 3: Rafael Nadal won all matches against male players at Roland Garros 2022.\n\nPremise 4.1: If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.\nPremise 4.2: Coco Gauff is a player who is ranked highly by the Women's Tennis Association.\nConclusion 4: Coco Gauff is not a male tennis player at Roland Garros 2022.\n\nPremise 5.1: Coco Gauff is not a male tennis player at Roland Garros 2022.\nConclusion 5: Coco Gauff has not lost to Rafael Nadal.\n\nTherefore, the answer is B. No. It is not true that Coco Gauff has lost to Rafael Nadal.", "logic_premises": "[[((0∧1)→2), (3→4)], [((6→7)∪((8→9)∪(a→b))), 2], [(0→1)], [((0∨1)→2), 3], [0]]", "logic_conclusion": "[(5→6), ((c→(d∨e))∪((f→(g∨h))∪(i→(j∨k)))), (2→3), 4, 1]", "correspondance": [{"0": "X is a player", "1": "X is ranked highly by the Women 's Tennis Association .", "2": "X are among the most active players in major tennis .", "3": "X is a person who lost to Iga Świątek .", "4": "X is ranked highly by the Women 's Tennis Association .", "5": "X is a player who lost to Iga Świątek .", "6": "X is among the most active players in major tennis ."}, {"0": "X is a female tennis player at Roland Garros 2022 .", "1": "X lost to Iga Świątek .", "2": "Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022 .", "3": "X is a player at Roland Garros 2022 .", "4": "X lost to Iga Świątek .", "5": "X lost to Rafael Nadal .", "6": "Iga Świątek is a female tennis player at Roland Garros 2022 .", "7": "Iga Świątek lost to Iga Świątek .", "8": "Roland Garros 2022 is a female tennis player at Roland Garros 2022 .", "9": "Roland Garros 2022 lost to Iga Świątek .", "a": "Iga Świątek or Rafael Nadal is a female tennis player at Roland Garros 2022 .", "b": "Iga Świątek or Rafael Nadal lost to Iga Świątek .", "c": "Iga Świątek is a player at Roland Garros 2022 .", "d": "Iga Świątek lost to Iga Świątek .", "e": "Iga Świątek lost to Rafael Nadal .", "f": "Roland Garros 2022 is a player at Roland Garros 2022 .", "g": "Roland Garros 2022 lost to Iga Świątek .", "h": "Roland Garros 2022 lost to Rafael Nadal .", "i": "Iga Świątek or Rafael Nadal is a player at Roland Garros 2022 .", "j": "Iga Świątek or Rafael Nadal lost to Iga Świątek .", "k": "Iga Świątek or Rafael Nadal lost to Rafael Nadal ."}, {"0": "X is a male tennis player at Roland Garros 2022 .", "1": "X lost to Rafael Nadal .", "2": "X is a match against male players .", "3": "Rafael Nadal won X at Roland Garros 2022 ."}, {"0": "Coco Gauff is a player who is ranked highly by the Women 's Tennis Association .", "1": "Coco Gauff is a player who lost to Rafael Nadal .", "2": "Coco Gauff is not a male tennis player at Roland Garros 2022 .", "3": "Coco Gauff is a player who is ranked highly by the Women 's Tennis Association .", "4": "Coco Gauff is not a male tennis player at Roland Garros 2022 ."}, {"0": "Coco Gauff is not a male tennis player at Roland Garros 2022 .", "1": "Coco Gauff has not lost to Rafael Nadal ."}], "errors": [[]], "entailments_dict": [{"4": ["1"], "5": ["0", "3"], "2": ["6"]}, {"2": ["6", "a", "j", "(¬7)"], "9": ["2", "g", "j"], "7": ["d", "j", "(¬2)"], "b": ["j", "2", "d", "e", "g"], "f": ["6", "2", "(¬7)"], "c": ["6", "2", "(¬7)"], "i": ["6", "a", "2", "(¬7)"], "(¬6)": ["2"], "(¬8)": ["2"], "(¬g)": ["6"], "(¬j)": ["6"], "(¬a)": ["2"]}, {"1": ["3"]}, {"3": ["0", "4"], "2": ["3", "4"], "4": ["0", "3"]}, {"(¬1)": ["0"]}], "predicted_steps": [true, "Contradiction in the premises", false, true, false]}
{"text": "If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis. Everyone who lost to Iga Świątek is ranked highly by the Women's Tennis Association. All female tennis players at Roland Garros 2022 lost to Iga Świątek. Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022. All male tennis players at Roland Garros 2022 lost to Rafael Nadal. If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Coco Gauff is not a player who lost to Iga Świątek or one of the most active players in major tennis?", "id": "44", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a player is ranked highly by the Women's Tennis Association, then they are among the most active players in major tennis.\nPremise 1.2: Everyone who lost to Iga Świątek is ranked highly by the Women's Tennis Association.\nConclusion 1: All players who lost to Iga Świątek are among the most active players in major tennis.\n\nPremise 2.1: All female tennis players at Roland Garros 2022 lost to Iga Świątek.\nPremise 2.2: Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022.\nConclusion 2: All players at Roland Garros 2022 who lost to Iga Świątek are female.\n\nPremise 3.1: All male tennis players at Roland Garros 2022 lost to Rafael Nadal.\nConclusion 3: No male tennis player at Roland Garros 2022 lost to Iga Świątek.\n\nPremise 4.1: If Coco Gauff is a player who is ranked highly by the Women's Tennis Association or a player who lost to Rafael Nadal, then Coco Gauff is not a male tennis player at Roland Garros 2022.\nPremise 4.2: Coco Gauff is a player who is ranked highly by the Women's Tennis Association.\nConclusion 4: Coco Gauff is not a male tennis player at Roland Garros 2022.\n\nPremise 5.1: Coco Gauff is not a male tennis player at Roland Garros 2022.\nConclusion 5: Coco Gauff is not a player who lost to Iga Świątek.\n\nTherefore, the answer is A. Yes. It is true that Coco Gauff is not a player who lost to Iga Świątek or one of the most active players in major tennis.", "logic_premises": "[[((0∧1)→2), (3→4)], [((5→6)∪(7→8)), 2], [(0→1)], [((0∨1)→2), 3], [0]]", "logic_conclusion": "[(5→6), ((9→a)∪(b→c)), (2→3), 4, 1]", "correspondance": [{"0": "X is a player", "1": "X is ranked highly by the Women 's Tennis Association .", "2": "X are among the most active players in major tennis .", "3": "X is a person who lost to Iga Świątek .", "4": "X is ranked highly by the Women 's Tennis Association .", "5": "X is a player who lost to Iga Świątek .", "6": "X is among the most active players in major tennis ."}, {"0": "X is a female tennis player at Roland Garros 2022 .", "1": "X lost to Iga Świątek .", "2": "Either female tennis players at Roland Garros 2022 or male tennis players at Roland Garros 2022 .", "3": "X is a player at Roland Garros 2022 who lost to Iga Świątek .", "4": "X is female .", "5": "Roland Garros 2022 is a female tennis player at Roland Garros 2022 .", "6": "Roland Garros 2022 lost to Iga Świątek .", "7": "Iga Świątek is a female tennis player at Roland Garros 2022 .", "8": "Iga Świątek lost to Iga Świątek .", "9": "Roland Garros 2022 is a player at Roland Garros 2022 who lost to Iga Świątek .", "a": "Roland Garros 2022 is female .", "b": "Iga Świątek is a player at Roland Garros 2022 who lost to Iga Świątek .", "c": "Iga Świątek is female ."}, {"0": "X is a male tennis player at Roland Garros 2022 .", "1": "X lost to Rafael Nadal .", "2": "X is a male tennis player at Roland Garros 2022 .", "3": "X did not lose to Iga Świątek ."}, {"0": "Coco Gauff is a player who is ranked highly by the Women 's Tennis Association .", "1": "Coco Gauff is a player who lost to Rafael Nadal .", "2": "Coco Gauff is not a male tennis player at Roland Garros 2022 .", "3": "Coco Gauff is a player who is ranked highly by the Women 's Tennis Association .", "4": "Coco Gauff is not a male tennis player at Roland Garros 2022 ."}, {"0": "Coco Gauff is not a male tennis player at Roland Garros 2022 .", "1": "Coco Gauff is not a player who lost to Iga Świątek ."}], "errors": [[]], "entailments_dict": [{"4": ["1"], "5": ["0", "3"], "2": ["6"]}, {"6": ["2", "c"], "2": ["7", "c", "(¬8)"], "9": ["7", "5", "2", "(¬8)"], "b": ["7", "2", "(¬8)", "(¬6)"], "8": ["(¬2)"], "(¬7)": ["2"], "(¬5)": ["2"], "(¬a)": ["7", "2"]}, {"2": ["0"]}, {"3": ["0", "4"], "2": ["3", "4"], "4": ["0", "3"]}, {"0": ["1"]}], "predicted_steps": [true, "Contradiction in the premises", false, true, true]}
{"text": "All cats are mammals. Some pets are not mammals.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that No pets are cats?", "id": "45", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All cats are mammals.\nPremise 1.2: Some pets are not mammals.\nConclusion 1: Some pets are not cats.\n\nPremise 2.1: Some pets are not cats.\nConclusion 2: Not all pets are cats.\n\nPremise 3.1: Not all pets are cats.\nConclusion 3: It is uncertain whether no pets are cats.\n\nTherefore, the answer is C. Uncertain.", "logic_premises": "[[(0→1), 2], [0], [0]]", "logic_conclusion": "[3, 1, (1→2)]", "correspondance": [{"0": "X is a cat .", "1": "X is a mammal .", "2": "Some pets are not mammals .", "3": "Some pets are not cats ."}, {"0": "Some pets are not cats .", "1": "Not all pets are cats ."}, {"0": "Not all pets are cats .", "1": "X is a pet .", "2": "It is not uncertain that X is a cat ."}], "errors": [[]], "entailments_dict": [{}, {"1": ["0"], "0": ["1"], "(¬1)": ["0"]}, {}], "predicted_steps": [false, true, false]}
{"text": "[BG] There are four seasons in a year: Spring, Summer, Fall, and Winter. All students who want to have a long vacation love summer the most. Emma's favorite season is summer. Mia's favorite season is not the same as Emma's. James wants to have a long vacation.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that James's favorite season is summer?", "id": "46", "ground_truth": "True", "reasoning": " Premise 1: All students who want to have a long vacation love summer the most.\nPremise 2: James wants to have a long vacation.\nConclusion 1: James loves summer the most.\nPremise 3: Mia's favorite season is not the same as Emma's.\nPremise 4: Emma's favorite season is summer.\nConclusion 2: Mia's favorite season is not summer.\nPremise 5: James's favorite season is not the same as Mia's.\nConclusion 3: James's favorite season is summer.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(4→5), 2], [0, 1], [0]]", "logic_conclusion": "[3, 2, 1]", "correspondance": [{"0": "X is a student who wants to has a long vacation .", "1": "X loves summer the most .", "2": "James wants to have a long vacation .", "3": "James loves summer the most .", "4": "James is a student who wants to has a long vacation .", "5": "James loves summer the most ."}, {"0": "Mia 's 's favorite season is not the same as Emma 's 's .", "1": "Emma 's 's favorite season is summer .", "2": "Mia 's 's favorite season is not summer ."}, {"0": "James 's 's favorite season is not the same as Mia 's .", "1": "James 's 's favorite season is summer ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"(¬1)": ["0"]}, {}], "predicted_steps": [true, false, false]}
{"text": "[BG] There are four seasons in a year: Spring, Summer, Fall, and Winter. All students who want to have a long vacation love summer the most. Emma's favorite season is summer. Mia's favorite season is not the same as Emma's. James wants to have a long vacation.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that James's favorite season is fall?", "id": "47", "ground_truth": "False", "reasoning": " Premise 1: All students who want to have a long vacation love summer the most.\nPremise 2: Emma's favorite season is summer.\nPremise 3: Mia's favorite season is not the same as Emma's.\nPremise 4: James wants to have a long vacation.\nConclusion 1: James's favorite season is not summer.\nPremise 5: Mia's favorite season is fall.\nConclusion 2: James's favorite season is fall.\n\nTherefore, the answer is (A) Yes. It is true that James's favorite season is fall.", "logic_premises": "[[((6→7)∪((8→9)∪((a→b)∪((c→d)∪(e→f))))), 2, 3, 4], [0]]", "logic_conclusion": "[5, 1]", "correspondance": [{"0": "X is a student who wants to has a long vacation .", "1": "X loves summer the most .", "2": "Emma 's 's favorite season is summer .", "3": "Mia 's favorite season is not the same as Emma 's 's .", "4": "James wants to have a long vacation .", "5": "James 's favorite season is not summer .", "6": "James is a student who wants to has a long vacation .", "7": "James loves summer the most .", "8": "Mias favorite season is a student who wants to has a long vacation .", "9": "Mias favorite season loves summer the most .", "a": "Jamess favorite season is a student who wants to has a long vacation .", "b": "Jamess favorite season loves summer the most .", "c": "Emmas favorite season is a student who wants to has a long vacation .", "d": "Emmas favorite season loves summer the most .", "e": "Emmas is a student who wants to has a long vacation .", "f": "Emmas loves summer the most ."}, {"0": "Mia 's favorite season is fall .", "1": "James 's favorite season is fall ."}], "errors": [[]], "entailments_dict": [{"2": ["3"], "4": ["6"], "f": ["3", "2"], "d": ["2"], "5": ["(¬7)", "(¬b)"], "(¬2)": ["3"]}, {}], "predicted_steps": [false, false]}
{"text": "[BG] There are four seasons in a year: Spring, Summer, Fall, and Winter. All students who want to have a long vacation love summer the most. Emma's favorite season is summer. Mia's favorite season is not the same as Emma's. James wants to have a long vacation.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Mia's favorite season is spring?", "id": "48", "ground_truth": "Uncertain", "reasoning": " Premise 1: All students who want to have a long vacation love summer the most.\nPremise 2: Emma's favorite season is summer.\nPremise 3: Mia's favorite season is not the same as Emma's.\nConclusion 1: Mia's favorite season is not summer.\nPremise 4: James wants to have a long vacation.\nConclusion 2: James' favorite season is summer.\nPremise 5: Mia's favorite season is spring.\nConclusion 3: Mia's favorite season is not summer.\n\nTherefore, the answer is B. No. It is not true that Mia's favorite season is spring.", "logic_premises": "[[((5→6)∪((7→8)∪(9→a))), 2, 3], [0], [0]]", "logic_conclusion": "[4, 1, 1]", "correspondance": [{"0": "X is a student who wants to has a long vacation .", "1": "X loves summer the most .", "2": "Emma 's 's favorite season is summer .", "3": "Mia 's 's favorite season is not the same as Emma 's 's .", "4": "Mia 's 's favorite season is not summer .", "5": "Emmas favorite season is a student who wants to has a long vacation .", "6": "Emmas favorite season loves summer the most .", "7": "Mias favorite season is a student who wants to has a long vacation .", "8": "Mias favorite season loves summer the most .", "9": "Emmas is a student who wants to has a long vacation .", "a": "Emmas loves summer the most ."}, {"0": "James wants to have a long vacation .", "1": "James 's favorite season is summer ."}, {"0": "Mia 's 's favorite season is spring .", "1": "Mia 's 's favorite season is not summer ."}], "errors": [[]], "entailments_dict": [{"6": ["2"], "a": ["2"], "4": ["(¬8)"], "(¬5)": ["3"], "(¬2)": ["3"]}, {}, {"0": ["1"]}], "predicted_steps": [false, false, true]}
{"text": "No digital media are analog. Every printed text is analog. All streaming services are digital. If an object is a hardcover book then it is printed text. If 1984 is a streaming service, then 1984 is a hardcover book.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that 1984 is printed text?", "id": "49", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: No digital media are analog.\nPremise 1.2: Every printed text is analog.\nConclusion 1: All printed texts are not digital.\n\nPremise 2.1: All streaming services are digital.\nPremise 2.2: If an object is a hardcover book, then it is printed text.\nConclusion 2: If an object is a hardcover book, then it is not a streaming service.\n\nPremise 3.1: If 1984 is a streaming service, then 1984 is a hardcover book.\nConclusion 3: 1984 is not a streaming service.\n\nPremise 4.1: 1984 is not a streaming service.\nConclusion 4: 1984 is printed text.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→1), ((2∧3)→4)], [(0→1)], [0]]", "logic_conclusion": "[(4→5), ((5∧6)→7), 2, 1]", "correspondance": [{"0": "X is a digital medium .", "1": "X is not analog .", "2": "X is a printed text .", "3": "X is analog .", "4": "X is printed a text .", "5": "X is not digital ."}, {"0": "X is streaming a service .", "1": "X is digital .", "2": "X is an object", "3": "X is a hardcover book .", "4": "X is printed text .", "5": "X is an object", "6": "X is a hardcover book .", "7": "X is not a streaming service ."}, {"0": "1984 is a streaming service .", "1": "1984 is a hardcover book .", "2": "1984 is not a streaming service ."}, {"0": "1984 is not a streaming service .", "1": "1984 is printed text ."}], "errors": [[]], "entailments_dict": [{"4": ["2"], "1": ["5", "(¬3)"], "3": ["(¬1)"], "(¬5)": ["0"], "(¬0)": ["2"]}, {"6": ["3", "2", "(¬1)"], "5": ["2"], "1": ["(¬4)"], "(¬7)": ["0"]}, {"1": ["2"], "(¬2)": ["0"]}, {"1": ["0"]}], "predicted_steps": [true, true, false, false]}
{"text": "No digital media are analog. Every printed text is analog. All streaming services are digital. If an object is a hardcover book then it is printed text. If 1984 is a streaming service, then 1984 is a hardcover book.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that 1984 is a streaming service?", "id": "50", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: No digital media are analog.\nPremise 1.2: Every printed text is analog.\nConclusion 1: If an object is a hardcover book, then it is printed text.\n\nPremise 2.1: All streaming services are digital.\nPremise 2.2: If 1984 is a streaming service, then 1984 is a hardcover book.\nConclusion 2: If 1984 is a streaming service, then it is not digital.\n\nPremise 3.1: If 1984 is not digital, then it is analog.\nConclusion 3: 1984 is analog.\n\nTherefore, the answer is B. No, it is not true that 1984 is a streaming service.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [(0→1)]]", "logic_conclusion": "[((4∧5)→6), (4→5), 2]", "correspondance": [{"0": "X is a digital medium .", "1": "X is not analog .", "2": "X is a printed text .", "3": "X is analog .", "4": "X is an object", "5": "X is a hardcover book .", "6": "X is printed text ."}, {"0": "X is streaming a service .", "1": "X is digital .", "2": "1984 is a streaming service .", "3": "1984 is a hardcover book .", "4": "1984 is a streaming service .", "5": "it is not digital ."}, {"0": "1984 is not digital .", "1": "it is analog .", "2": "1984 is analog ."}], "errors": [[]], "entailments_dict": [{"5": ["2"], "1": ["(¬3)"], "3": ["(¬1)"], "(¬0)": ["2"]}, {"4": ["2", "(¬3)"], "3": ["5"]}, {"1": ["2"], "(¬2)": ["0"]}], "predicted_steps": [false, "Contradiction in the premises", false]}
{"text": "No digital media are analog. Every printed text is analog. All streaming services are digital. If an object is a hardcover book then it is printed text. If 1984 is a streaming service, then 1984 is a hardcover book.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that 1984 is not a streaming service?", "id": "51", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: No digital media are analog.\nPremise 1.2: Every printed text is analog.\nConclusion 1: If an object is a hardcover book, then it is printed text.\n\nPremise 2.1: All streaming services are digital.\nPremise 2.2: If 1984 is a streaming service, then 1984 is a hardcover book.\nConclusion 2: If 1984 is a hardcover book, then it is not a streaming service.\n\nPremise 3.1: 1984 is a hardcover book.\nConclusion 3: 1984 is not a streaming service.\n\nTherefore, the answer is A. Yes, it is true that 1984 is not a streaming service.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [0]]", "logic_conclusion": "[((4∧5)→6), (4→5), 1]", "correspondance": [{"0": "X is a digital medium .", "1": "X is not analog .", "2": "X is a printed text .", "3": "X is analog .", "4": "X is an object", "5": "X is a hardcover book .", "6": "X is printed text ."}, {"0": "X is streaming a service .", "1": "X is digital .", "2": "1984 is a streaming service .", "3": "1984 is a hardcover book .", "4": "1984 is a hardcover book .", "5": "it is not a streaming service ."}, {"0": "1984 is a hardcover book .", "1": "1984 is not a streaming service ."}], "errors": [[]], "entailments_dict": [{"5": ["2"], "1": ["(¬3)"], "3": ["(¬1)"], "(¬0)": ["2"]}, {"3": ["5"], "(¬5)": ["0"]}, {"0": ["1"]}], "predicted_steps": [false, false, true]}
{"text": "All Romance languages are Indo-European languages. The Romance languages are a language family. All languages within a language family are related to each other. French and Spanish are both Romance languages. German is related to Spanish. Basque is not related to any other language.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Basque is a Romance language?", "id": "52", "ground_truth": "False", "reasoning": " Premise 1.1: All Romance languages are Indo-European languages.\nPremise 1.2: The Romance languages are a language family.\nPremise 1.3: All languages within a language family are related to each other.\nPremise 2.1: French and Spanish are both Romance languages.\nPremise 2.2: German is related to Spanish.\nPremise 3.1: Basque is not related to any other language.\nConclusion 1: Basque is not a Romance language.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((c→(d∧e))∪((f→(g∧h))∪((i→(j∧k))∪((l→(m∧n))∪((o→(p∧q))∪((r→(s∧t))∪(u→(v∧w)))))))), 3, ((x→y)∪((z→A)∪((B→C)∪((D→E)∪((F→G)∪((H→I)∪(J→K))))))), (6∧7), 8, ((L→M)∪((N→O)∪((P→Q)∪((R→S)∪((T→U)∪((V→W)∪(X→Y)))))))]]", "logic_conclusion": "[b]", "correspondance": [{"0": "X is Romance a language .", "1": "X is Indo a language .", "2": "X is European a language .", "3": "The Romance languages are a language family .", "4": "X is a language within a language family .", "5": "X is related to each other .", "6": "French are both Romance languages .", "7": "Spanish are both Romance languages .", "8": "German is related to Spanish .", "9": "X is an other language .", "a": "Basque is not related to X .", "b": "Basque is not a Romance language .", "c": "German is Romance a language .", "d": "German is Indo a language .", "e": "German is European a language .", "f": "Romance languages is Romance a language .", "g": "Romance languages is Indo a language .", "h": "Romance languages is European a language .", "i": "Spanish is Romance a language .", "j": "Spanish is Indo a language .", "k": "Spanish is European a language .", "l": "The Romance languages is Romance a language .", "m": "The Romance languages is Indo a language .", "n": "The Romance languages is European a language .", "o": "French and Spanish is Romance a language .", "p": "French and Spanish is Indo a language .", "q": "French and Spanish is European a language .", "r": "Basque is Romance a language .", "s": "Basque is Indo a language .", "t": "Basque is European a language .", "u": "All Romance languages is Romance a language .", "v": "All Romance languages is Indo a language .", "w": "All Romance languages is European a language .", "x": "German is a language within a language family .", "y": "German is related to each other .", "z": "Romance languages is a language within a language family .", "A": "Romance languages is related to each other .", "B": "Spanish is a language within a language family .", "C": "Spanish is related to each other .", "D": "The Romance languages is a language within a language family .", "E": "The Romance languages is related to each other .", "F": "French and Spanish is a language within a language family .", "G": "French and Spanish is related to each other .", "H": "Basque is a language within a language family .", "I": "Basque is related to each other .", "J": "All Romance languages is a language within a language family .", "K": "All Romance languages is related to each other .", "L": "German is an other language .", "M": "Basque is not related to German .", "N": "Romance languages is an other language .", "O": "Basque is not related to Romance languages .", "P": "Spanish is an other language .", "Q": "Basque is not related to Spanish .", "R": "The Romance languages is an other language .", "S": "Basque is not related to The Romance languages .", "T": "French and Spanish is an other language .", "U": "Basque is not related to French and Spanish .", "V": "Basque is an other language .", "W": "Basque is not related to Basque .", "X": "All Romance languages is an other language .", "Y": "Basque is not related to All Romance languages ."}], "errors": [[]], "entailments_dict": [{"w": ["z", "7", "J", "3", "D", "8", "6", "F", "B", "(¬Y)", "(¬O)", "(¬S)"], "6": ["3", "D", "o", "x", "F", "B", "i", "z", "J"], "n": ["J", "3", "D", "7", "F", "8", "6", "B", "z", "(¬O)", "(¬S)"], "h": ["7", "J", "3", "D", "8", "6", "F", "B", "z", "(¬S)"], "K": ["6", "i", "3", "7", "o", "8", "(¬W)", "(¬Y)", "(¬Q)", "(¬O)", "(¬S)", "(¬U)"], "G": ["i", "f", "3", "7", "l", "u", "o", "6"], "8": ["7", "J", "3", "D", "x", "i", "F", "B", "z"], "m": ["6", "B", "z", "J", "3", "D", "7", "x", "F", "8", "(¬Y)", "(¬O)", "(¬S)"], "A": ["7", "6", "i", "3", "o", "(¬Y)", "(¬O)", "(¬S)"], "j": ["7", "J", "3", "D", "6", "F", "B", "z"], "s": ["D", "7", "J", "H", "B", "z", "b"], "p": ["B", "z", "J", "3", "D", "7", "F", "6"], "7": ["o", "x", "B", "i", "z", "F", "3", "D", "J"], "q": ["B", "z", "7", "J", "3", "D", "6", "F"], "k": ["z", "J", "3", "D", "7", "6", "F", "B"], "g": ["8", "6", "x", "B", "z", "F", "3", "D", "7", "J", "(¬Y)", "(¬O)", "(¬S)"], "E": ["i", "7", "3", "o", "6", "(¬Y)", "(¬O)", "(¬S)"], "C": ["3", "7", "6", "i", "(¬S)", "(¬W)", "(¬Q)"], "v": ["F", "6", "B", "z", "J", "3", "D", "8", "7", "(¬W)", "(¬Y)", "(¬Q)", "(¬O)", "(¬S)", "(¬U)"], "t": ["D", "H", "z"], "3": ["B", "z", "F", "D", "J", "(¬Y)", "(¬O)", "(¬S)"], "d": ["x", "z"], "e": ["x"], "b": ["V"], "O": ["b", "(¬I)"], "U": ["b", "(¬I)"], "S": ["b"], "Q": ["b"], "W": ["b", "(¬I)"], "Y": ["b"], "I": ["(¬W)", "(¬Y)", "(¬O)", "(¬S)", "(¬U)"], "y": ["(¬M)"], "(¬b)": ["u", "f", "o", "i", "l", "r", "3", "H", "z", "F", "B", "J", "D", "7", "6"]}], "predicted_steps": [false]}
{"text": "All Romance languages are Indo-European languages. The Romance languages are a language family. All languages within a language family are related to each other. French and Spanish are both Romance languages. German is related to Spanish. Basque is not related to any other language.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that German is a Romance language?", "id": "53", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All Romance languages are Indo-European languages.\nPremise 1.2: The Romance languages are a language family.\nPremise 1.3: All languages within a language family are related to each other.\n\nConclusion 1: French and Spanish are related to each other.\n\nPremise 2.1: French and Spanish are both Romance languages.\nPremise 2.2: German is related to Spanish.\n\nConclusion 2: German is related to French.\n\nPremise 3.1: All Romance languages are related to each other.\nPremise 3.2: German is related to French.\n\nConclusion 3: German is a Romance language.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((9→(a∧b))∪((c→(d∧e))∪(f→(g∧h)))), 3, ((i→j)∪((k→l)∪(m→n)))], [(0∧1), 2], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[((o→(p∧q))∪((r→(s∧t))∪(u→(v∧w)))), 3, 3]", "correspondance": [{"0": "X is Romance a language .", "1": "X is Indo a language .", "2": "X is European a language .", "3": "The Romance languages are a language family .", "4": "X is a language within a language family .", "5": "X is related to each other .", "6": "X is an other .", "7": "French is related to X .", "8": "Spanish is related to X .", "9": "French and Spanish is Romance a language .", "a": "French and Spanish is Indo a language .", "b": "French and Spanish is European a language .", "c": "All Romance languages is Romance a language .", "d": "All Romance languages is Indo a language .", "e": "All Romance languages is European a language .", "f": "The Romance languages is Romance a language .", "g": "The Romance languages is Indo a language .", "h": "The Romance languages is European a language .", "i": "French and Spanish is a language within a language family .", "j": "French and Spanish is related to each other .", "k": "All Romance languages is a language within a language family .", "l": "All Romance languages is related to each other .", "m": "The Romance languages is a language within a language family .", "n": "The Romance languages is related to each other .", "o": "French and Spanish is an other .", "p": "French is related to French and Spanish .", "q": "Spanish is related to French and Spanish .", "r": "All Romance languages is an other .", "s": "French is related to All Romance languages .", "t": "Spanish is related to All Romance languages .", "u": "The Romance languages is an other .", "v": "French is related to The Romance languages .", "w": "Spanish is related to The Romance languages ."}, {"0": "French are both Romance languages .", "1": "Spanish are both Romance languages .", "2": "German is related to Spanish .", "3": "German is related to French ."}, {"0": "X is Romance a language .", "1": "X is related to each other .", "2": "German is related to French .", "3": "German is a Romance language .", "4": "French is Romance a language .", "5": "French is related to each other .", "6": "German is Romance a language .", "7": "German is related to each other ."}], "errors": [[]], "entailments_dict": [{"b": ["m", "3", "i", "k", "s", "p", "w", "v", "t"], "h": ["k", "i", "m", "3", "s", "w", "q", "v", "t"], "g": ["m", "3", "i", "k", "s", "p", "w", "q", "v", "t"], "n": ["3", "9", "s", "p", "w", "q", "v", "t"], "j": ["3", "c", "f", "9", "p", "q", "s", "w", "v", "t"], "e": ["i", "k", "m", "3", "s", "w", "q", "v", "t"], "d": ["k", "i", "m", "3", "s", "w", "q", "v", "t"], "a": ["k", "i", "m", "3", "s", "p", "w", "v", "t"], "l": ["9", "3", "s", "p", "w", "q", "v", "t"], "3": ["i", "k", "m", "w", "v", "s", "q", "t"], "u": ["3", "f", "c", "k", "m", "i"], "o": ["i", "3", "k", "m"], "r": ["9", "f", "c", "3", "k", "m"]}, {"2": ["1"], "3": ["0"], "0": ["3"]}, {"3": ["6", "2"]}], "predicted_steps": [false, true, false]}
{"text": "All Romance languages are Indo-European languages. The Romance languages are a language family. All languages within a language family are related to each other. French and Spanish are both Romance languages. German is related to Spanish. Basque is not related to any other language.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that French is an Indo-European language?", "id": "54", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All Romance languages are Indo-European languages.\nPremise 1.2: French is a Romance language.\nConclusion 1: French is an Indo-European language.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((6→(7∧8))∪(9→(a∧b))), 3]]", "logic_conclusion": "[(4∧5)]", "correspondance": [{"0": "X is Romance a language .", "1": "X is Indo a language .", "2": "X is European a language .", "3": "French is a Romance language .", "4": "French is an Indo language .", "5": "French is an European language .", "6": "French is Romance a language .", "7": "French is Indo a language .", "8": "French is European a language .", "9": "All Romance languages is Romance a language .", "a": "All Romance languages is Indo a language .", "b": "All Romance languages is European a language ."}], "errors": [[]], "entailments_dict": [{"8": ["3", "5"], "a": ["3", "4"], "3": ["6", "5"], "7": ["3", "4", "5"], "b": ["3", "5"], "4": ["6", "3"], "5": ["6", "3"]}], "predicted_steps": [true]}
{"text": "Robert Lewandowski is a striker. [BG] Strikers are soccer players. Robert Lewandowski left Bayern Munchen. [BG] If a player left a team they no longer play for that team.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Robert Lewandowski is a soccer player?", "id": "55", "ground_truth": "True", "reasoning": " Sure! Here's my reasoning:\n\nPremise 1.1: Robert Lewandowski is a striker.\nPremise 1.2: Strikers are soccer players.\nConclusion 1: Robert Lewandowski is a soccer player.\n\nSince the premises are both true, the conclusion logically follows, and the answer is A. Yes.", "logic_premises": "[[0, (4→5)]]", "logic_conclusion": "[3]", "correspondance": [{"0": "Robert Lewandowski is a striker .", "1": "X is a Striker .", "2": "X is soccer a player .", "3": "Robert Lewandowski is a soccer player .", "4": "Robert Lewandowski is a Striker .", "5": "Robert Lewandowski is soccer a player ."}], "errors": [[]], "entailments_dict": [{"0": ["4", "3"], "5": ["0", "3"], "3": ["0", "4"]}], "predicted_steps": [true]}
{"text": "Robert Lewandowski is a striker. [BG] Strikers are soccer players. Robert Lewandowski left Bayern Munchen. [BG] If a player left a team they no longer play for that team.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Robert Lewandowski plays for Bayern Munchen?", "id": "56", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Robert Lewandowski is a striker.\nPremise 1.2: Strikers are soccer players.\nConclusion 1: Robert Lewandowski is a soccer player.\n\nPremise 2.1: Robert Lewandowski left Bayern Munchen.\nPremise 2.2: If a player left a team, they no longer play for that team.\nConclusion 2: Robert Lewandowski no longer plays for Bayern Munchen.\n\nConclusion 3: Robert Lewandowski does not play for Bayern Munchen.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, (4→5)], [0, (((5∧6)→7)∪((8∧9)→a))]]", "logic_conclusion": "[3, 4]", "correspondance": [{"0": "Robert Lewandowski is a striker .", "1": "X is a Striker .", "2": "X is soccer a player .", "3": "Robert Lewandowski is a soccer player .", "4": "Robert Lewandowski is a Striker .", "5": "Robert Lewandowski is soccer a player ."}, {"0": "Robert Lewandowski left Bayern Munchen .", "1": "X is a player", "2": "X left a team .", "3": "X no longer play for a team .", "4": "Robert Lewandowski no longer plays for Bayern Munchen .", "5": "Bayern Munchen is a player", "6": "Bayern Munchen left a team .", "7": "Bayern Munchen no longer play for a team .", "8": "Robert Lewandowski is a player", "9": "Robert Lewandowski left a team .", "a": "Robert Lewandowski no longer play for a team ."}], "errors": [[]], "entailments_dict": [{"0": ["4", "3"], "5": ["0", "3"], "3": ["0", "4"]}, {"0": ["8", "9", "4"], "4": ["0", "9"], "7": ["4"], "a": ["4"]}], "predicted_steps": [true, true]}
{"text": "Robert Lewandowski is a striker. [BG] Strikers are soccer players. Robert Lewandowski left Bayern Munchen. [BG] If a player left a team they no longer play for that team.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Robert Lewandowski is a star?", "id": "57", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Robert Lewandowski is a striker.\nPremise 1.2: Strikers are soccer players.\nConclusion 1: Robert Lewandowski is a soccer player.\n\nPremise 2.1: Robert Lewandowski left Bayern Munchen.\nPremise 2.2: If a player left a team, they no longer play for that team.\nConclusion 2: Robert Lewandowski no longer plays for Bayern Munchen.\n\nPremise 3.1: Robert Lewandowski is a soccer player.\nPremise 3.2: Soccer players can be stars.\nConclusion 3: Robert Lewandowski can be a star.\n\nConclusion 4: Therefore, the answer is (A) Yes, it is true that Robert Lewandowski is a star.", "logic_premises": "[[0, (4→5)], [0, (((5∧6)→7)∪((8∧9)→a))], [0, (4→5)]]", "logic_conclusion": "[3, 4, 3]", "correspondance": [{"0": "Robert Lewandowski is a striker .", "1": "X is a Striker .", "2": "X is soccer a player .", "3": "Robert Lewandowski is a soccer player .", "4": "Robert Lewandowski is a Striker .", "5": "Robert Lewandowski is soccer a player ."}, {"0": "Robert Lewandowski left Bayern Munchen .", "1": "X is a player", "2": "X left a team .", "3": "X no longer play for a team .", "4": "Robert Lewandowski no longer plays for Bayern Munchen .", "5": "Bayern Munchen is a player", "6": "Bayern Munchen left a team .", "7": "Bayern Munchen no longer play for a team .", "8": "Robert Lewandowski is a player", "9": "Robert Lewandowski left a team .", "a": "Robert Lewandowski no longer play for a team ."}, {"0": "Robert Lewandowski is a soccer player .", "1": "X is Soccer a player .", "2": "X can is a star .", "3": "Robert Lewandowski can be a star .", "4": "Robert Lewandowski is Soccer a player .", "5": "Robert Lewandowski can is a star ."}], "errors": [[]], "entailments_dict": [{"0": ["4", "3"], "5": ["0", "3"], "3": ["0", "4"]}, {"0": ["8", "9", "4"], "4": ["0", "9"], "7": ["4"], "a": ["4"]}, {"0": ["4", "3"], "5": ["0", "3"], "3": ["0", "4"]}], "predicted_steps": [true, true, true]}
{"text": "Billings is a city in Montana. Montana includes the cities of Butte, Helena, and Missoula. White Sulphur Springs and Butte are cities in the same state. The city of Pierre is not in Montana. Any city in Butte is not in Pierre.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Butte and Pierre are in the same state?", "id": "58", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Billings is a city in Montana.\nPremise 1.2: Montana includes the cities of Butte, Helena, and Missoula.\nConclusion 1: Butte is a city in Montana.\n\nPremise 2.1: White Sulphur Springs and Butte are cities in the same state.\nConclusion 2: White Sulphur Springs is a city in Montana.\n\nPremise 3.1: The city of Pierre is not in Montana.\nConclusion 3: Pierre is not a city in Montana.\n\nPremise 4.1: Any city in Butte is not in Pierre.\nConclusion 4: Butte is not in Pierre.\n\nPremise 5.1: Butte is a city in Montana.\nPremise 5.2: Pierre is not a city in Montana.\nConclusion 5: Butte and Pierre are not in the same state.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, (1∧(2∧3))], [(0∧1)], [0], [((3→4)∪(5→6))], [0, 1]]", "logic_conclusion": "[4, 2, 1, 2, (2∧3)]", "correspondance": [{"0": "Billings is a city in Montana .", "1": "Montana includes the cities of Butte .", "2": "Montana includes the cities of Helena .", "3": "Montana includes the cities of Missoula .", "4": "Butte is a city in Montana ."}, {"0": "White Sulphur Springs are cities in the same state .", "1": "Butte are cities in the same state .", "2": "White Sulphur Springs is a city in the same state ."}, {"0": "the city of Pierre is not in Montana .", "1": "the city of Pierre is not a city in Montana ."}, {"0": "X is a city in Butte .", "1": "X is not in Pierre .", "2": "Butte is not in Pierre .", "3": "Pierre is a city in Butte .", "4": "Pierre is not in Pierre .", "5": "Butte is a city in Butte .", "6": "Butte is not in Pierre ."}, {"0": "Butte is a city in Montana .", "1": "Pierre is not a city in Montana .", "2": "Butte are not in the same state .", "3": "Pierre are not in the same state ."}], "errors": [[]], "entailments_dict": [{"0": ["2", "1"], "2": ["0", "4"], "4": ["1", "2"], "1": ["4"], "3": ["4"]}, {"2": ["0"], "0": ["2"]}, {"1": ["0"], "0": ["1"]}, {"4": ["2"], "6": ["2"]}, {"2": ["1"], "(¬2)": ["0"]}], "predicted_steps": [true, true, true, false, false]}
{"text": "Billings is a city in Montana. Montana includes the cities of Butte, Helena, and Missoula. White Sulphur Springs and Butte are cities in the same state. The city of Pierre is not in Montana. Any city in Butte is not in Pierre.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Pierre and Bismarck are in the same state?", "id": "59", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Billings is a city in Montana.\nPremise 1.2: Montana includes the cities of Butte, Helena, and Missoula.\nConclusion 1: Butte, Helena, and Missoula are cities in Montana.\n\nPremise 2.1: White Sulphur Springs and Butte are cities in the same state.\nPremise 2.2: Butte is a city in Montana.\nConclusion 2: White Sulphur Springs is a city in Montana.\n\nPremise 3.1: The city of Pierre is not in Montana.\nConclusion 3: Pierre is not a city in Montana.\n\nPremise 4.1: Any city in Butte is not in Pierre.\nPremise 4.2: Butte is a city in Montana.\nConclusion 4: Any city in Montana is not in Pierre.\n\nPremise 5.1: Pierre and Bismarck are cities in the same state.\nConclusion 5: It is uncertain whether Pierre and Bismarck are in the same state.\n\nTherefore, the answer is C. Uncertain.", "logic_premises": "[[0, (1∧(2∧3))], [(0∧1), 2], [0], [((5→6)∪((7→8)∪(9→a))), 2], [(0∧1)]]", "logic_conclusion": "[(4∧(5∧6)), 3, 1, ((b→c)∪((d→e)∪(f→g))), (2∧3)]", "correspondance": [{"0": "Billings is a city in Montana .", "1": "Montana includes the cities of Butte .", "2": "Montana includes the cities of Helena .", "3": "Montana includes the cities of Missoula .", "4": "Butte are cities in Montana .", "5": "Helena are cities in Montana .", "6": "Missoula are cities in Montana ."}, {"0": "White Sulphur Springs are cities in the same state .", "1": "Butte are cities in the same state .", "2": "Butte is a city in the same state .", "3": "White Sulphur Springs is a city in the same state ."}, {"0": "the city of Pierre is not in Montana .", "1": "the city of Pierre is not a city in Montana ."}, {"0": "X is a city in Butte .", "1": "X is not in Pierre .", "2": "Butte is a city in Montana .", "3": "X is a city in Montana .", "4": "X is not in Pierre .", "5": "Pierre is a city in Butte .", "6": "Pierre is not in Pierre .", "7": "Butte is a city in Butte .", "8": "Butte is not in Pierre .", "9": "Montana is a city in Butte .", "a": "Montana is not in Pierre .", "b": "Pierre is a city in Montana .", "c": "Pierre is not in Pierre .", "d": "Butte is a city in Montana .", "e": "Butte is not in Pierre .", "f": "Montana is a city in Montana .", "g": "Montana is not in Pierre ."}, {"0": "Pierre are cities in the same state .", "1": "Bismarck are cities in the same state .", "2": "It is uncertain that Pierre are in the same state .", "3": "It is uncertain that Bismarck are in the same state ."}], "errors": [[]], "entailments_dict": [{"0": ["2", "1"], "2": ["0", "4", "6", "5"], "4": ["1"], "6": ["3"], "5": ["2"], "1": ["4", "5"], "3": ["4", "6", "5"]}, {"1": ["2"], "2": ["1"], "3": ["0"], "0": ["3"]}, {"1": ["0"], "0": ["1"]}, {"d": ["2"], "8": ["e"], "6": ["c", "e"], "a": ["g"], "f": ["2"], "2": ["e"], "b": ["(¬6)", "(¬a)"], "(¬c)": ["7", "2"], "(¬e)": ["2"]}, {}], "predicted_steps": [true, true, true, false, false]}
{"text": "Billings is a city in Montana. Montana includes the cities of Butte, Helena, and Missoula. White Sulphur Springs and Butte are cities in the same state. The city of Pierre is not in Montana. Any city in Butte is not in Pierre.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Montana is home to the city of Missoula?", "id": "60", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Montana includes the cities of Butte, Helena, and Missoula.\nPremise 1.2: Butte is a city in Montana.\nConclusion 1: Butte is a city in Montana that is included in the list of cities in Montana.\n\nPremise 2.1: White Sulphur Springs and Butte are cities in the same state.\nPremise 2.2: The city of Pierre is not in Montana.\nConclusion 2: White Sulphur Springs is not in Pierre.\n\nPremise 3.1: Any city in Butte is not in Pierre.\nPremise 3.2: Butte is a city in Montana.\nConclusion 3: Any city in Montana is not in Pierre.\n\nPremise 4.1: Missoula is a city in Montana.\nConclusion 4: Missoula is a city in Montana that is not in Pierre.\n\nTherefore, the answer is A. Yes, Montana is home to the city of Missoula.", "logic_premises": "[[(0∧(1∧2)), 3], [(0∧1), 2], [((5→6)∪((7→8)∪(9→a))), 2], [0]]", "logic_conclusion": "[4, 3, ((b→c)∪((d→e)∪(f→g))), 1]", "correspondance": [{"0": "Montana includes the cities of Butte .", "1": "Montana includes the cities of Helena .", "2": "Montana includes the cities of Missoula .", "3": "Butte is a city in Montana .", "4": "Butte is a city in Montana that is included in the list of cities in Montana ."}, {"0": "White Sulphur Springs are cities in the same state .", "1": "Butte are cities in the same state .", "2": "The city of Pierre is not in the same state .", "3": "White Sulphur Springs is not in The city of Pierre ."}, {"0": "X is a city in Butte .", "1": "X is not in Pierre .", "2": "Butte is a city in Montana .", "3": "X is a city in Montana .", "4": "X is not in Pierre .", "5": "Pierre is a city in Butte .", "6": "Pierre is not in Pierre .", "7": "Butte is a city in Butte .", "8": "Butte is not in Pierre .", "9": "Montana is a city in Butte .", "a": "Montana is not in Pierre .", "b": "Pierre is a city in Montana .", "c": "Pierre is not in Pierre .", "d": "Butte is a city in Montana .", "e": "Butte is not in Pierre .", "f": "Montana is a city in Montana .", "g": "Montana is not in Pierre ."}, {"0": "Missoula is a city in Montana .", "1": "Missoula is a city in Montana that is not in Pierre ."}], "errors": [[]], "entailments_dict": [{"2": ["3", "4"], "1": ["3", "4"], "3": ["1", "0", "4"], "0": ["3", "4"], "4": ["1", "0", "3"]}, {"1": ["(¬2)"], "(¬3)": ["0"]}, {"d": ["2"], "f": ["2"], "8": ["e"], "6": ["c", "e"], "a": ["g"], "2": ["e"], "b": ["(¬6)", "(¬a)"], "(¬c)": ["7", "2"], "(¬e)": ["2"]}, {"1": ["0"], "0": ["1"], "(¬1)": ["0"]}], "predicted_steps": [true, "Contradiction in the premises", false, true]}
{"text": "International students in US have either an F1 visa or a J1 visa. An international student in US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US. Mike is an international student. Mike needs to apply for CPT if he wants to work in the US.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Mike has an F1 visa?", "id": "61", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: International students in the US have either an F1 visa or a J1 visa.\nPremise 1.2: An international student in the US with an F1 visa needs to apply for CPT or OPT if they want to work in the US.\nPremise 2.1: Mike is an international student.\nPremise 2.2: Mike needs to apply for CPT if he wants to work in the US.\nConclusion 1: Mike has an F1 visa.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((7→(8⊻9))∪((a→(b⊻c))∪((d→(e⊻f))∪(g→(h⊻i))))), 3, 4, 5]]", "logic_conclusion": "[6]", "correspondance": [{"0": "X is an International student in the US .", "1": "X has an F1 visa .", "2": "X has a J1 visa .", "3": "An international student in the US with an F1 visa needs to apply for CPT . An international student in the US with an F1 visa needs to apply for OPT that An international student in the US with an F1 visa want to work in the US .", "4": "Mike is an international student .", "5": "Mike needs to apply for CPT that Mike wants to work in the US .", "6": "Mike has an F1 visa .", "7": "the US is an International student in the US .", "8": "the US has an F1 visa .", "9": "the US has a J1 visa .", "a": "Mike is an International student in the US .", "b": "Mike has an F1 visa .", "c": "Mike has a J1 visa .", "d": "CPT or OPT is an International student in the US .", "e": "CPT or OPT has an F1 visa .", "f": "CPT or OPT has a J1 visa .", "g": "CPT is an International student in the US .", "h": "CPT has an F1 visa .", "i": "CPT has a J1 visa ."}], "errors": [[]], "entailments_dict": [{"4": ["3"], "3": ["5"], "b": ["3", "6"], "5": ["4", "3", "d"], "h": ["3"], "6": ["3"], "8": ["3"], "e": ["3"]}], "predicted_steps": [false]}
{"text": "International students in US have either an F1 visa or a J1 visa. An international student in US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US. Mike is an international student. Mike needs to apply for CPT if he wants to work in the US.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Mike has a J1 visa?", "id": "62", "ground_truth": "Uncertain", "reasoning": " Premise 1: International students in US have either an F1 visa or a J1 visa.\nPremise 2: An international student in US with an F1 visa needs to apply for CPT or OPT if the student wants to work in the US.\nPremise 3: Mike is an international student.\nPremise 4: Mike needs to apply for CPT if he wants to work in the US.\nConclusion 1: Mike has an F1 visa.\n\nTherefore, the answer is B. No. It is not true that Mike has a J1 visa.", "logic_premises": "[[((7→(8⊻9))∪((a→(b⊻c))∪((d→(e⊻f))∪((g→(h⊻i))∪((j→(k⊻l))∪(m→(n⊻o))))))), 3, 4, 5]]", "logic_conclusion": "[6]", "correspondance": [{"0": "X is an International student in US .", "1": "X has an F1 visa .", "2": "X has a J1 visa .", "3": "An international student in US with an F1 visa needs to apply for CPT . An international student in US with an F1 visa needs to apply for OPT that An international student in US with an F1 visa wants to work in US .", "4": "Mike is an international student .", "5": "Mike needs to apply for CPT that Mike wants to work in US .", "6": "Mike has an F1 visa .", "7": "the student is an International student in US .", "8": "the student has an F1 visa .", "9": "the student has a J1 visa .", "a": "the US is an International student in US .", "b": "the US has an F1 visa .", "c": "the US has a J1 visa .", "d": "Mike is an International student in US .", "e": "Mike has an F1 visa .", "f": "Mike has a J1 visa .", "g": "CPT or OPT is an International student in US .", "h": "CPT or OPT has an F1 visa .", "i": "CPT or OPT has a J1 visa .", "j": "US is an International student in US .", "k": "US has an F1 visa .", "l": "US has a J1 visa .", "m": "CPT is an International student in US .", "n": "CPT has an F1 visa .", "o": "CPT has a J1 visa ."}], "errors": [[]], "entailments_dict": [{"4": ["3"], "n": ["3"], "5": ["7", "3"], "3": ["5", "7", "6"], "b": ["3"], "h": ["3"], "k": ["3"], "8": ["3"], "e": ["3", "6"], "6": ["7", "3"]}], "predicted_steps": [true]}
{"text": "All cows are bovines. Some pets are cows. If something is a bovine, then it is domesticated. No domesticated animals are alligators. Ted is an aligator.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Ted is a pet?", "id": "63", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All cows are bovines.\nPremise 1.2: Some pets are cows.\nConclusion 1: Some pets are bovines.\n\nPremise 2.1: If something is a bovine, then it is domesticated.\nPremise 2.2: No domesticated animals are alligators.\nConclusion 2: No bovines are alligators.\n\nPremise 3.1: Ted is an alligator.\nConclusion 3: Ted is not a bovine.\n\nPremise 4.1: Ted is not a bovine.\nConclusion 4: Ted is not a pet.\n\nTherefore, the answer is B. No.", "logic_premises": "[[(0→1), 2], [(0→1), (2→3)], [0], [0]]", "logic_conclusion": "[3, (4→5), 1, 1]", "correspondance": [{"0": "X is a cow .", "1": "X is a bovine .", "2": "Some pets are cows .", "3": "Some pets are bovines ."}, {"0": "X is a bovine .", "1": "X is domesticated .", "2": "X is a domesticated animal .", "3": "X is not an alligator .", "4": "X is a bovine .", "5": "X is not an alligator ."}, {"0": "Ted is an alligator .", "1": "Ted is not a bovine ."}, {"0": "Ted is not a bovine .", "1": "Ted is not a pet ."}], "errors": [[]], "entailments_dict": [{"3": ["2"], "2": ["3"]}, {"1": ["2"], "4": ["0", "2"], "3": ["5"]}, {"0": ["1"]}, {"(¬1)": ["0"]}], "predicted_steps": [true, true, true, false]}
{"text": "All cows are bovines. Some pets are cows. If something is a bovine, then it is domesticated. No domesticated animals are alligators. Ted is an aligator.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Ted is a pet and a cow?", "id": "64", "ground_truth": "False", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: All cows are bovines.\nPremise 1.2: Some pets are cows.\nConclusion 1: Some pets are bovines.\n\nPremise 2.1: If something is a bovine, then it is domesticated.\nConclusion 2: All bovines are domesticated.\n\nPremise 3.1: No domesticated animals are alligators.\nPremise 3.2: Ted is an alligator.\nConclusion 3: Ted is not domesticated.\n\nPremise 4.1: Ted is not domesticated.\nConclusion 4: Ted is not a pet.\n\nConclusion 5: B. No, it is not true that Ted is a pet and a cow.\n\nTherefore, the answer is B. No.", "logic_premises": "[[(0→1), 2], [(0→1)], [(4→5), 2], [0]]", "logic_conclusion": "[3, (2→3), 3, 1]", "correspondance": [{"0": "X is a cow .", "1": "X is a bovine .", "2": "Some pets are cows .", "3": "Some pets are bovines ."}, {"0": "X is a bovine .", "1": "X is domesticated .", "2": "X is a bovine .", "3": "X is domesticated ."}, {"0": "X is a domesticated animal .", "1": "X is not an alligator .", "2": "Ted is an alligator .", "3": "Ted is not domesticated .", "4": "Ted is a domesticated animal .", "5": "Ted is not an alligator ."}, {"0": "Ted is not domesticated .", "1": "Ted is not a pet ."}], "errors": [[]], "entailments_dict": [{"3": ["2"], "2": ["3"]}, {"2": ["0"], "1": ["3"]}, {"3": ["2"], "2": ["3", "(¬5)"], "5": ["(¬2)"], "(¬3)": ["4"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [true, true, true, true]}
{"text": "All cows are bovines. Some pets are cows. If something is a bovine, then it is domesticated. No domesticated animals are alligators. Ted is an aligator.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Ted is a cow, then Ted is not a pet?", "id": "65", "ground_truth": "True", "reasoning": " Here is my reasoning:\n\nPremise 1.1: All cows are bovines.\nPremise 1.2: Some pets are cows.\nConclusion 1: Some pets are bovines.\n\nPremise 2.1: If something is a bovine, then it is domesticated.\nPremise 2.2: No domesticated animals are alligators.\nConclusion 2: No bovines are alligators.\n\nPremise 3.1: Ted is an alligator.\nConclusion 3: Ted is not a bovine.\n\nPremise 4.1: If Ted is a cow, then Ted is a bovine.\nPremise 4.2: Ted is not a bovine.\nConclusion 4: Ted is not a cow.\n\nTherefore, the answer is B. No. It is not true that if Ted is a cow, then Ted is not a pet.", "logic_premises": "[[(0→1), 2], [(0→1), (2→3)], [0], [(0→1), 2]]", "logic_conclusion": "[3, (4→5), 1, 3]", "correspondance": [{"0": "X is a cow .", "1": "X is a bovine .", "2": "Some pets are cows .", "3": "Some pets are bovines ."}, {"0": "X is a bovine .", "1": "X is domesticated .", "2": "X is a domesticated animal .", "3": "X is not an alligator .", "4": "X is a bovine .", "5": "X is not an alligator ."}, {"0": "Ted is an alligator .", "1": "Ted is not a bovine ."}, {"0": "Ted is a cow .", "1": "Ted is a bovine .", "2": "Ted is not a bovine .", "3": "Ted is not a cow ."}], "errors": [[]], "entailments_dict": [{"3": ["2"], "2": ["3"]}, {"1": ["2"], "4": ["0", "2"], "3": ["5"]}, {"0": ["1"]}, {"3": ["2", "(¬1)"], "2": ["3", "(¬1)"], "1": ["(¬2)"], "(¬3)": ["0"], "(¬0)": ["2"], "(¬2)": ["0"]}], "predicted_steps": [true, true, true, true]}
{"text": "Yale University is a private Ivy League research university. Yale University moved to New Haven in 1716. Yale university's endowment was valued at $42.3 billion. Yale University has been organized into 27 constituent colleges and schools: the residential colleges, the Yale Graduate School of Arts and Sciences, and twelve professional schools. A list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that A private Ivy League research university moved to New Haven?", "id": "66", "ground_truth": "True", "reasoning": " Premise 1: Yale University is a private Ivy League research university.\nPremise 2: Yale University moved to New Haven in 1716.\nConclusion 1: Yale University, a private Ivy League research university, moved to New Haven.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, 1]]", "logic_conclusion": "[2]", "correspondance": [{"0": "Yale University is a private Ivy League research university .", "1": "Yale University moved to New Haven in 1716 .", "2": "Yale University , moved to New Haven ."}], "errors": [[]], "entailments_dict": [{"1": ["0", "2"], "2": ["0"]}], "predicted_steps": [true]}
{"text": "Yale University is a private Ivy League research university. Yale University moved to New Haven in 1716. Yale university's endowment was valued at $42.3 billion. Yale University has been organized into 27 constituent colleges and schools: the residential colleges, the Yale Graduate School of Arts and Sciences, and twelve professional schools. A list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Yale University has the largest university endowment of any educational institution?", "id": "67", "ground_truth": "Uncertain", "reasoning": " Premise 1: Yale University's endowment was valued at $42.3 billion.\nConclusion 1: Yale University has a large endowment.\n\nPremise 2: Yale University's endowment is the largest among all educational institutions.\nConclusion 2: Yale University has the largest university endowment of any educational institution.\n\nHowever, we cannot conclude that Yale University has the largest university endowment of any educational institution without further information. The passage only states that Yale University's endowment is large, but it does not provide information about the endowments of other educational institutions. Therefore, the answer is C. Uncertain.", "logic_premises": "[[0], [(0→1)]]", "logic_conclusion": "[1, (2→3)]", "correspondance": [{"0": "Yale University 's 's endowment was valued at $ 42.3 billion .", "1": "Yale University 's has a large endowment ."}, {"0": "X is a the largest among an educational institution .", "1": "Yale University 's 's endowment is X .", "2": "X is a the largest university endowment of educational institution .", "3": "Yale University 's has X ."}], "errors": [[]], "entailments_dict": [{"1": ["0"], "0": ["1"]}, {"2": ["0"], "1": ["3"]}], "predicted_steps": [true, true]}
{"text": "Yale University is a private Ivy League research university. Yale University moved to New Haven in 1716. Yale university's endowment was valued at $42.3 billion. Yale University has been organized into 27 constituent colleges and schools: the residential colleges, the Yale Graduate School of Arts and Sciences, and twelve professional schools. A list of residential colleges at Yale: Benjamin Franklin College, Berkeley College, Branford College, Davenport College, Ezra Stiles College, Grace Hopper College, Jonathan Edwards College, Morse College, Pauli Murray College, Pierson College, Saybrook College, Silliman College, Timothy Dwight College, and Trumbull College.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Pierson College is a residential college at Yale?", "id": "68", "ground_truth": "True", "reasoning": " Premise 1: Yale University has 27 constituent colleges and schools, including the residential colleges.\nPremise 2: A list of residential colleges at Yale includes Pierson College.\nConclusion 1: Pierson College is a residential college at Yale.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0∧1), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "Yale University has 27 constituent colleges , including the residential colleges .", "1": "Yale University has 27 constituent schools , including the residential colleges .", "2": "A list of residential colleges at Yale University includes Pierson College .", "3": "Pierson College is a residential college at Yale University ."}], "errors": [[]], "entailments_dict": [{"0": ["2", "3"], "1": ["2", "3"], "2": ["0", "3"], "3": ["1", "0", "2"]}], "predicted_steps": [true]}
{"text": "Badults is a British Sitcom series, starring members of Pappy's. Badults piloted in July 2013 on BBC Three. The Working title \"The Secret Dude Society\" was used for Badults. Andrew Collins was the script editor for Badults", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society\"?", "id": "69", "ground_truth": "True", "reasoning": " Premise 1: The working title \"The Secret Dude Society\" was used for Badults.\nPremise 2: Andrew Collins was the script editor for Badults.\nConclusion 1: Andrew Collins was the script editor for a series with the working title \"The Secret Dude Society.\"\nAnswer: A. Yes", "logic_premises": "[[0, 1]]", "logic_conclusion": "[2]", "correspondance": [{"0": "the working title \" The Secret Dude Society \" was used for Badults .", "1": "Andrew Collins was the script editor for Badults .", "2": "Andrew Collins was the script editor for a series with the working title \" The Secret Dude Society \" . \""}], "errors": [[]], "entailments_dict": [{"2": ["0", "1"], "0": ["2"], "1": ["2"], "(¬2)": ["0"]}], "predicted_steps": [true]}
{"text": "Badults is a British Sitcom series, starring members of Pappy's. Badults piloted in July 2013 on BBC Three. The Working title \"The Secret Dude Society\" was used for Badults. Andrew Collins was the script editor for Badults", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that No members of Pappy's have starred for a show piloting on BBC Two or BBC Three?", "id": "70", "ground_truth": "False", "reasoning": " Premise 1.1: The members of Pappy's starred in Badults, a British Sitcom series.\nPremise 1.2: Badults piloted on BBC Three in July 2013.\nConclusion 1: At least some members of Pappy's have starred in a show that piloted on BBC Three.\nPremise 2.1: No members of Pappy's have starred in a show that piloted on BBC Two.\nConclusion 2: If a show piloted on BBC Two, then no members of Pappy's starred in it.\nPremise 3.1: Badults piloted on BBC Three.\nConclusion 3: Badults is a show that piloted on BBC Three.\nPremise 4.1: The Working title \"The Secret Dude Society\" was used for Badults.\nConclusion 4: The working title for Badults was \"The Secret Dude Society\".\nPremise 5.1: Andrew Collins was the script editor for Badults.\nConclusion 5: Andrew Collins was involved in the production of Badults.\n\nNow, let's evaluate the options:\n\nA. Yes: This option states that no members of Pappy's have starred in a show that piloted on BBC Two or BBC Three. However, we have concluded that at least some members of Pappy's have starred in a show that piloted on BBC Three (Conclusion 1). Therefore, this option is false.\n\nB. No: This option states that some members of Pappy's have starred in a show that piloted on BBC Two or BBC Three. We have concluded that at least some members of Pappy's have starred in a show that piloted on BBC Three (Conclusion 1). Therefore, this option is true.\n\nC. Uncertain: This option states that it is uncertain whether any members of Pappy's have starred in a show that piloted on BBC Two or BBC Three. However, we have concluded that at least some members of Pappy's have starred in a show that piloted on BBC Three (Conclusion 1). Therefore, this option is false.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, 1], [(0→1)], [0], [0], [0]]", "logic_conclusion": "[2, ((2∧3)→4), 1, 1, 1]", "correspondance": [{"0": "The members of Pappy 's 's starred in Badults .", "1": "Badults piloted on BBC Three in July 2013 .", "2": "At least some members of Pappy 's 's have starred in a show that piloted on BBC Three ."}, {"0": "X is a member of Pappy 's 's .", "1": "X has not starred in a show that piloted on BBC Two .", "2": "X is a show", "3": "X piloted on BBC Two .", "4": "no members of Pappy 's 's starred in X ."}, {"0": "Badults piloted on BBC Three .", "1": "Badults is a show that piloted on BBC Three ."}, {"0": "The Working title \" The Secret Dude Society \" was used for Badults .", "1": "The working title for Badults was \" The Secret Dude Society \" ."}, {"0": "Andrew Collins was the script editor for Badults .", "1": "Andrew Collins was involved in the production of Badults ."}], "errors": [[]], "entailments_dict": [{"2": ["1", "0"], "1": ["2", "0"], "0": ["1", "2"], "(¬2)": ["0"], "(¬1)": ["0"]}, {"3": ["(¬1)"]}, {"1": ["0"], "0": ["1"]}, {"1": ["0"], "0": ["1"]}, {"0": ["1"]}], "predicted_steps": [true, false, true, true, true]}
{"text": "All growth companies’ stocks are volatile. If the stock price is volatile, then it is not suitable for a retirement fund. Some companies’ stocks are growth companies’ stocks. All mature companies’ stocks are suitable for a retirement fund. KO is a mature company’s stock.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that KO is a company stock?", "id": "71", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All growth companies' stocks are volatile.\nPremise 1.2: If the stock price is volatile, then it is not suitable for a retirement fund.\nConclusion 1: Growth companies' stocks are not suitable for a retirement fund.\n\nPremise 2.1: Some companies' stocks are growth companies' stocks.\nConclusion 2: Some companies' stocks are not suitable for a retirement fund.\n\nPremise 3.1: All mature companies' stocks are suitable for a retirement fund.\nPremise 3.2: KO is a mature company's stock.\nConclusion 3: KO is suitable for a retirement fund.\n\nPremise 4.1: KO is a company stock.\nConclusion 4: KO is a company stock.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(6→7), (2→3)], [0], [(4→5), 2], [0]]", "logic_conclusion": "[(8→9), 1, 3, 1]", "correspondance": [{"0": "X is growth a company ' stocks .", "1": "X is volatile .", "2": "the stock price is volatile .", "3": "the stock price is not suitable for a retirement fund .", "4": "X is a Growth company ' a stock .", "5": "X is not suitable for a retirement fund .", "6": "the stock price is growth a company ' stocks .", "7": "the stock price is volatile .", "8": "the stock price is a Growth company ' a stock .", "9": "the stock price is not suitable for a retirement fund ."}, {"0": "Some companies ' stocks are growth companies ' stocks .", "1": "Some companies ' stocks are not suitable for a retirement fund ."}, {"0": "X is a mature company ' stocks .", "1": "X is suitable for a retirement fund .", "2": "KO is a mature company 's stock .", "3": "KO is suitable for a retirement fund .", "4": "KO is a mature company ' stocks .", "5": "KO is suitable for a retirement fund ."}, {"0": "KO is a company stock .", "1": "KO is a company stock ."}], "errors": [[]], "entailments_dict": [{"7": ["2"], "8": ["6"], "3": ["9"]}, {}, {"2": ["4"], "5": ["3"], "(¬4)": ["2"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [true, false, true, true]}
{"text": "All growth companies’ stocks are volatile. If the stock price is volatile, then it is not suitable for a retirement fund. Some companies’ stocks are growth companies’ stocks. All mature companies’ stocks are suitable for a retirement fund. KO is a mature company’s stock.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that KO is a company stock and a growth company’s stock?", "id": "72", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All growth companies' stocks are volatile.\nPremise 1.2: If the stock price is volatile, then it is not suitable for a retirement fund.\nConclusion 1: Growth companies' stocks are not suitable for a retirement fund.\n\nPremise 2.1: Some companies' stocks are growth companies' stocks.\nConclusion 2: Some companies' stocks are not suitable for a retirement fund.\n\nPremise 3.1: All mature companies' stocks are suitable for a retirement fund.\nPremise 3.2: KO is a mature company's stock.\nConclusion 3: KO is suitable for a retirement fund.\n\nPremise 4.1: KO is a mature company's stock.\nPremise 4.2: Mature companies' stocks are suitable for a retirement fund.\nConclusion 4: KO is suitable for a retirement fund.\n\nConclusion 5: B. No\n\nTherefore, the answer is B. No. KO is not a growth company's stock, but it is a mature company's stock, which makes it suitable for a retirement fund.", "logic_premises": "[[(6→7), (2→3)], [0], [(4→5), 2], [0, (4→5)]]", "logic_conclusion": "[(8→9), 1, 3, 3]", "correspondance": [{"0": "X is growth a company ' stocks .", "1": "X is volatile .", "2": "the stock price is volatile .", "3": "the stock price is not suitable for a retirement fund .", "4": "X is a Growth company ' a stock .", "5": "X is not suitable for a retirement fund .", "6": "the stock price is growth a company ' stocks .", "7": "the stock price is volatile .", "8": "the stock price is a Growth company ' a stock .", "9": "the stock price is not suitable for a retirement fund ."}, {"0": "Some companies ' stocks are growth companies ' stocks .", "1": "Some companies ' stocks are not suitable for a retirement fund ."}, {"0": "X is a mature company ' stocks .", "1": "X is suitable for a retirement fund .", "2": "KO is a mature company 's stock .", "3": "KO is suitable for a retirement fund .", "4": "KO is a mature company ' stocks .", "5": "KO is suitable for a retirement fund ."}, {"0": "KO is a mature company 's stock .", "1": "X is a Mature company ' a stock .", "2": "X is suitable for a retirement fund .", "3": "KO is suitable for a retirement fund .", "4": "KO is a Mature company ' a stock .", "5": "KO is suitable for a retirement fund ."}], "errors": [[]], "entailments_dict": [{"7": ["2"], "8": ["6"], "3": ["9"]}, {}, {"2": ["4"], "5": ["3"], "(¬4)": ["2"]}, {"0": ["4"], "5": ["3"]}], "predicted_steps": [true, false, true, true]}
{"text": "All growth companies’ stocks are volatile. If the stock price is volatile, then it is not suitable for a retirement fund. Some companies’ stocks are growth companies’ stocks. All mature companies’ stocks are suitable for a retirement fund. KO is a mature company’s stock.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If KO is a growth company’s stock or if its price is volatile, then KO is neither a company’s stock nor is its price volatile?", "id": "73", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All growth companies' stocks are volatile.\nPremise 1.2: If the stock price is volatile, then it is not suitable for a retirement fund.\nPremise 2.1: Some companies' stocks are growth companies' stocks.\nPremise 2.2: All mature companies' stocks are suitable for a retirement fund.\nPremise 3.1: KO is a mature company's stock.\n\nConclusion 1: KO is not a growth company's stock.\n\nPremise 4.1: If KO is a growth company's stock or if its price is volatile, then KO is neither a company's stock nor is its price volatile.\nPremise 4.2: KO is not a growth company's stock (conclusion 1).\nPremise 4.3: KO's price is not volatile (conclusion 1).\n\nConclusion 2: KO is neither a company's stock nor is its price volatile.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((9→a)∪(b→c)), (2→3), 4, ((d→e)∪(f→g)), 7], [0, 1, 2]]", "logic_conclusion": "[8, 3]", "correspondance": [{"0": "X is growth a company ' stocks .", "1": "X is volatile .", "2": "the stock price is volatile .", "3": "the stock price is not suitable for a retirement fund .", "4": "Some companies ' stocks are growth companies ' stocks .", "5": "X is a mature company ' stocks .", "6": "X is suitable for a retirement fund .", "7": "KO is a mature company 's stock .", "8": "KO is not a growth company 's stock .", "9": "KO is growth a company ' stocks .", "a": "KO is volatile .", "b": "the stock price is growth a company ' stocks .", "c": "the stock price is volatile .", "d": "KO is a mature company ' stocks .", "e": "KO is suitable for a retirement fund .", "f": "the stock price is a mature company ' stocks .", "g": "the stock price is suitable for a retirement fund ."}, {"0": "If KO is a growth company 's stock or if KO 's price is volatile , then KO is neither a company 's stock nor is KO 's price volatile .", "1": "KO is not a growth company 's stock .", "2": "KO 's price is not volatile .", "3": "KO is neither a company 's stock nor is KO 's price volatile ."}], "errors": [[]], "entailments_dict": [{"7": ["d", "f"], "c": ["2"], "a": ["(¬e)"], "g": ["(¬3)"], "e": ["(¬3)"], "3": ["(¬g)"], "(¬8)": ["4"], "(¬d)": ["7"]}, {"0": ["2", "1", "3"], "2": ["0", "3"], "3": ["0", "2"], "(¬3)": ["0", "2"], "(¬0)": ["1"]}], "predicted_steps": [false, true]}
{"text": "All vehicle registration plates in Istanbul begin with the number 34. Plates that do not begin with the number 34 are not from Istanbul. Joe's vehicle registration plate is from Istanbul. Tom's license plate begins with the number 35. [BG] If a license plate begins with the number 35, then it does not begin with the number 34.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Joe's license plate begins with the number 34?", "id": "74", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All vehicle registration plates in Istanbul begin with the number 34.\nPremise 1.2: Plates that do not begin with the number 34 are not from Istanbul.\nConclusion 1: Joe's vehicle registration plate begins with the number 34.\nPremise 2.1: If a license plate begins with the number 35, then it does not begin with the number 34.\nPremise 2.2: Tom's license plate begins with the number 35.\nConclusion 2: Tom's license plate does not begin with the number 34.\nPremise 3.1: Joe's vehicle registration plate is from Istanbul.\nConclusion 3: Joe's license plate begins with the number 34.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((5→6)∪((7→8)∪(9→a))), ((b→c)∪((d→e)∪(f→g)))], [(((5∧6)→7)∪(((8∧9)→a)∪((b∧c)→d))), 3], [0]]", "logic_conclusion": "[4, 4, 1]", "correspondance": [{"0": "X is a vehicle registration a plate in Istanbul .", "1": "X begins with the number 34 .", "2": "X is a Plate that do not begin with the number 34 .", "3": "X is not from Istanbul .", "4": "Joe 's vehicle registration plate begins with the number 34 .", "5": "Joes vehicle registration plate is a vehicle registration a plate in Istanbul .", "6": "Joes vehicle registration plate begins with the number 34 .", "7": "Istanbul is a vehicle registration a plate in Istanbul .", "8": "Istanbul begins with the number 34 .", "9": "the number 34 is a vehicle registration a plate in Istanbul .", "a": "the number 34 begins with the number 34 .", "b": "Joes vehicle registration plate is a Plate that do not begin with the number 34 .", "c": "Joes vehicle registration plate is not from Istanbul .", "d": "Istanbul is a Plate that do not begin with the number 34 .", "e": "Istanbul is not from Istanbul .", "f": "the number 34 is a Plate that do not begin with the number 34 .", "g": "the number 34 is not from Istanbul ."}, {"0": "X is a license plate", "1": "X begins with the number 35 .", "2": "X does not begin with the number 34 .", "3": "Tom 's 's license plate begins with the number 35 .", "4": "Tom 's 's license plate does not begin with the number 34 .", "5": "the number 35 is a license plate", "6": "the number 35 begins with the number 35 .", "7": "the number 35 does not begin with the number 34 .", "8": "Toms license plate is a license plate", "9": "Toms license plate begins with the number 35 .", "a": "Toms license plate does not begin with the number 34 .", "b": "the number 34 is a license plate", "c": "the number 34 begins with the number 35 .", "d": "the number 34 does not begin with the number 34 ."}, {"0": "Joe 's 's vehicle registration plate is from Istanbul .", "1": "Joe 's 's license plate begins with the number 34 ."}], "errors": [[]], "entailments_dict": [{"6": ["4"], "8": ["(¬g)"], "g": ["(¬8)"], "(¬9)": ["b"], "(¬d)": ["7"], "(¬4)": ["b"]}, {"3": ["9", "8", "6"], "a": ["4"], "4": ["(¬d)"], "(¬4)": ["8"]}, {}], "predicted_steps": [false, true, false]}
{"text": "All vehicle registration plates in Istanbul begin with the number 34. Plates that do not begin with the number 34 are not from Istanbul. Joe's vehicle registration plate is from Istanbul. Tom's license plate begins with the number 35. [BG] If a license plate begins with the number 35, then it does not begin with the number 34.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Tom's license plate is from Istanbul?", "id": "75", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All vehicle registration plates in Istanbul begin with the number 34.\nPremise 1.2: Plates that do not begin with the number 34 are not from Istanbul.\nConclusion 1: If a license plate begins with the number 34, then it is from Istanbul.\n\nPremise 2.1: Joe's vehicle registration plate is from Istanbul.\nPremise 2.2: Joe's license plate begins with the number 34.\nConclusion 2: Joe's license plate is from Istanbul.\n\nPremise 3.1: Tom's license plate begins with the number 35.\nPremise 3.2: If a license plate begins with the number 35, then it does not begin with the number 34.\nConclusion 3: Tom's license plate does not begin with the number 34.\n\nPremise 4.1: Tom's license plate does not begin with the number 34.\nConclusion 4: Tom's license plate is not from Istanbul.\n\nTherefore, the answer is B. No. It is not true that Tom's license plate is from Istanbul.", "logic_premises": "[[(0→1), (2→3)], [0, 1], [0, (((5∧6)→7)∪(((8∧9)→a)∪((b∧c)→d)))], [0]]", "logic_conclusion": "[((4∧5)→6), 2, 4, 1]", "correspondance": [{"0": "X is a vehicle registration a plate in Istanbul .", "1": "X begins with the number 34 .", "2": "X is a Plate that do not begin with the number 34 .", "3": "X is not from Istanbul .", "4": "X is a license plate", "5": "X begins with the number 34 .", "6": "X is from Istanbul ."}, {"0": "Joe 's 's vehicle registration plate is from Istanbul .", "1": "Joe 's 's license plate begins with the number 34 .", "2": "Joe 's 's license plate is from Istanbul ."}, {"0": "Tom 's 's license plate begins with the number 35 .", "1": "X is a license plate", "2": "X begins with the number 35 .", "3": "X does not begin with the number 34 .", "4": "Tom 's 's license plate does not begin with the number 34 .", "5": "the number 35 is a license plate", "6": "the number 35 begins with the number 35 .", "7": "the number 35 does not begin with the number 34 .", "8": "Toms license plate is a license plate", "9": "Toms license plate begins with the number 35 .", "a": "Toms license plate does not begin with the number 34 .", "b": "the number 34 is a license plate", "c": "the number 34 begins with the number 35 .", "d": "the number 34 does not begin with the number 34 ."}, {"0": "Tom 's 's license plate does not begin with the number 34 .", "1": "Tom 's 's license plate is not from Istanbul ."}], "errors": [[]], "entailments_dict": [{}, {"2": ["0"], "0": ["2"]}, {"0": ["8", "6", "9"], "a": ["4"], "4": ["(¬d)"], "(¬4)": ["8"]}, {}], "predicted_steps": [false, true, true, false]}
{"text": "If people work in student jobs on campus, then they need to earn money to help pay for their college tuition. If people order takeout frequently in college, then they work in student jobs on campus. People either order takeout frequently in college or enjoy the dining hall meals and recipes. If people enjoy the dining hall meals and recipes, then they are not picky eaters. If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls. If Mary works in student jobs on campus and needs to earn money to help pay for her college tuition, then Mary is neither picky nor needs to earn money to help pay for her college tuition.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Mary needs to earn money to help pay for her college tuition?", "id": "76", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If people work in student jobs on campus, then they need to earn money to help pay for their college tuition.\nPremise 1.2: If people order takeout frequently in college, then they work in student jobs on campus.\nConclusion 1: People who order takeout frequently in college work in student jobs on campus.\n\nPremise 2.1: People either order takeout frequently in college or enjoy the dining hall meals and recipes.\nPremise 2.2: If people enjoy the dining hall meals and recipes, then they are not picky eaters.\nConclusion 2: People who enjoy the dining hall meals and recipes are not picky eaters.\n\nPremise 3.1: If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.\nConclusion 3: People who spend a lot of their time eating and catching up with friends in the campus dining halls enjoy the dining hall meals and recipes.\n\nPremise 4.1: Mary works in student jobs on campus and needs to earn money to help pay for her college tuition.\nPremise 4.2: Mary is neither picky nor needs to earn money to help pay for her college tuition.\nConclusion 4: Mary does not need to earn money to help pay for her college tuition.\n\nConclusion 5: The answer is B. No. It is not true that Mary needs to earn money to help pay for her college tuition.", "logic_premises": "[[(0→1), (2→3)], [(0→(1⊻(2∧(3∧4)))), ((5∧(6∧7))→8)], [((0∧(1∧2))→3)], [(0∧1), (2∧3)]]", "logic_conclusion": "[(4→5), ((9∧(a∧b))→c), (4→(5∧(6∧7))), 4]", "correspondance": [{"0": "X work in student jobs on campus .", "1": "X need to earn money to help pay for X 's college tuition .", "2": "X order takeout frequently in college .", "3": "X work in student jobs on campus .", "4": "X is a person who orders takeout frequently in college .", "5": "X works in student jobs on campus ."}, {"0": "X is a person .", "1": "X orders takeout frequently in college .", "2": "X enjoys the dining hall .", "3": "X enjoys the meals .", "4": "X enjoys the recipes .", "5": "X enjoy the dining hall .", "6": "X enjoy the meals .", "7": "X enjoy the recipes .", "8": "X are not picky eaters .", "9": "X is a person who enjoys the dining hall .", "a": "X is a person who enjoys the meals .", "b": "X is a person who enjoys the recipes .", "c": "X is not picky an eater ."}, {"0": "X enjoy the dining hall .", "1": "X enjoy the meals .", "2": "X enjoy the recipes .", "3": "X spend a lot of X 's time eating and catching up with friends in the campus dining halls .", "4": "X is a person who spends a lot of their time eating and catching up with friends in the campus dining halls .", "5": "X enjoys the dining hall .", "6": "X enjoys the meals .", "7": "X enjoys the recipes ."}, {"0": "Mary works in student jobs on campus .", "1": "Mary needs to earn money to help pay for Mary 's college tuition .", "2": "Mary VP .", "3": "Mary does not need to earn money to help pay for Mary 's college tuition .", "4": "Mary does not need to earn money to help pay for Mary 's college tuition ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["2"], "1": ["5"]}, {"4": ["7", "6"], "2": ["5", "6"], "3": ["7", "6"], "9": ["0", "6", "5"], "b": ["0", "7", "6"], "a": ["0", "7", "6", "5"], "8": ["c"], "(¬c)": ["0"]}, {"4": ["1", "0"]}, {"4": ["3", "(¬1)"], "3": ["4", "(¬1)"], "1": ["(¬3)"], "(¬4)": ["1", "0"], "(¬1)": ["3"], "(¬3)": ["1", "0"]}], "predicted_steps": [true, true, false, "Contradiction in the premises"]}
{"text": "If people work in student jobs on campus, then they need to earn money to help pay for their college tuition. If people order takeout frequently in college, then they work in student jobs on campus. People either order takeout frequently in college or enjoy the dining hall meals and recipes. If people enjoy the dining hall meals and recipes, then they are not picky eaters. If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls. If Mary works in student jobs on campus and needs to earn money to help pay for her college tuition, then Mary is neither picky nor needs to earn money to help pay for her college tuition.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Mary is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls?", "id": "77", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If people work in student jobs on campus, then they need to earn money to help pay for their college tuition.\nPremise 1.2: If people order takeout frequently in college, then they work in student jobs on campus.\nConclusion 1: People who order takeout frequently in college work in student jobs on campus.\n\nPremise 2.1: People either order takeout frequently in college or enjoy the dining hall meals and recipes.\nPremise 2.2: If people enjoy the dining hall meals and recipes, then they are not picky eaters.\nConclusion 2: People who enjoy the dining hall meals and recipes are not picky eaters.\n\nPremise 3.1: If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.\nConclusion 3: People who enjoy the dining hall meals and recipes spend a lot of their time eating and catching up with friends in the campus dining halls.\n\nPremise 4.1: Mary works in student jobs on campus and needs to earn money to help pay for her college tuition.\nPremise 4.2: Mary is not picky and needs to earn money to help pay for her college tuition.\nConclusion 4: Mary is not a picky eater and spends a lot of her time eating and catching up with friends in the campus dining halls.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→(1⊻(2∧(3∧4)))), ((5∧(6∧7))→8)], [((0∧(1∧2))→3)], [(0∧1), (2∧3)]]", "logic_conclusion": "[(4→5), ((9∧(a∧b))→c), ((4∧(5∧6))→7), (4∧5)]", "correspondance": [{"0": "X work in student jobs on campus .", "1": "X need to earn money to help pay for X 's college tuition .", "2": "X order takeout frequently in college .", "3": "X work in student jobs on campus .", "4": "X is a person who orders takeout frequently in college .", "5": "X works in student jobs on campus ."}, {"0": "X is a person .", "1": "X orders takeout frequently in college .", "2": "X enjoys the dining hall .", "3": "X enjoys the meals .", "4": "X enjoys the recipes .", "5": "X enjoy the dining hall .", "6": "X enjoy the meals .", "7": "X enjoy the recipes .", "8": "X are not picky eaters .", "9": "X is a person who enjoys the dining hall .", "a": "X is a person who enjoys the meals .", "b": "X is a person who enjoys the recipes .", "c": "X is not picky an eater ."}, {"0": "X enjoy the dining hall .", "1": "X enjoy the meals .", "2": "X enjoy the recipes .", "3": "X spend a lot of X 's time eating and catching up with friends in the campus dining halls .", "4": "X is a person who enjoys the dining hall .", "5": "X is a person who enjoys the meals .", "6": "X is a person who enjoys the recipes .", "7": "X spends a lot of their time eating and catching up with friends in the campus dining halls ."}, {"0": "Mary works in student jobs on campus .", "1": "Mary needs to earn money to help pay for Mary 's college tuition .", "2": "Mary is not picky .", "3": "Mary needs to earn money to help pay for Mary 's college tuition .", "4": "Mary is not a picky eater .", "5": "Mary spends a lot of Mary 's time eating and catching up with friends in the campus dining halls ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["2"], "1": ["5"]}, {"4": ["7", "6"], "2": ["5", "6"], "3": ["7", "6"], "9": ["0", "6", "5"], "b": ["0", "7", "6"], "a": ["0", "7", "6", "5"], "8": ["c"], "(¬c)": ["0"]}, {"4": ["1", "0"], "6": ["1", "2"], "5": ["1", "0", "2"], "3": ["7"]}, {"1": ["3"], "3": ["1", "0"], "0": ["3"], "4": ["2"], "2": ["4"]}], "predicted_steps": [true, true, true, false]}
{"text": "If people work in student jobs on campus, then they need to earn money to help pay for their college tuition. If people order takeout frequently in college, then they work in student jobs on campus. People either order takeout frequently in college or enjoy the dining hall meals and recipes. If people enjoy the dining hall meals and recipes, then they are not picky eaters. If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls. If Mary works in student jobs on campus and needs to earn money to help pay for her college tuition, then Mary is neither picky nor needs to earn money to help pay for her college tuition.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Mary either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls?", "id": "78", "ground_truth": "False", "reasoning": " Here is my reasoning:\n\nPremise 1.1: If people work in student jobs on campus, then they need to earn money to help pay for their college tuition.\nPremise 1.2: If people order takeout frequently in college, then they work in student jobs on campus.\nConclusion 1: People who work in student jobs on campus order takeout frequently in college.\n\nPremise 2.1: People either order takeout frequently in college or enjoy the dining hall meals and recipes.\nPremise 2.2: If people enjoy the dining hall meals and recipes, then they are not picky eaters.\nConclusion 2: People who are not picky eaters enjoy the dining hall meals and recipes.\n\nPremise 3.1: If people enjoy the dining hall meals and recipes, then they spend a lot of their time eating and catching up with friends in the campus dining halls.\nConclusion 3: People who are not picky eaters spend a lot of their time eating and catching up with friends in the campus dining halls.\n\nPremise 4.1: Mary works in student jobs on campus and needs to earn money to help pay for her college tuition.\nPremise 4.2: Mary is neither picky nor needs to earn money to help pay for her college tuition.\nConclusion 4: Mary is not picky.\n\nConclusion 5: Mary spends a lot of her time eating and catching up with friends in the campus dining halls.\n\nTherefore, the answer is A. Yes. It is true that Mary either is not a picky eater or, if she is, then she spends a lot of her time eating and catching up with friends in the campus dining halls.", "logic_premises": "[[(0→1), (2→3)], [(0→(1⊻(2∧(3∧4)))), ((5∧(6∧7))→8)], [((0∧(1∧2))→3)], [(0∧1), (2∧3)]]", "logic_conclusion": "[(4→5), (9→(a∧(b∧c))), (4→5), 4]", "correspondance": [{"0": "X work in student jobs on campus .", "1": "X need to earn money to help pay for X 's college tuition .", "2": "X order takeout frequently in college .", "3": "X work in student jobs on campus .", "4": "X is a person who works in student jobs on campus .", "5": "X orders takeout frequently in college ."}, {"0": "X is a person .", "1": "X orders takeout frequently in college .", "2": "X enjoys the dining hall .", "3": "X enjoys the meals .", "4": "X enjoys the recipes .", "5": "X enjoy the dining hall .", "6": "X enjoy the meals .", "7": "X enjoy the recipes .", "8": "X are not picky eaters .", "9": "X is a person who is not picky an eater .", "a": "X enjoys the dining hall .", "b": "X enjoys the meals .", "c": "X enjoys the recipes ."}, {"0": "X enjoy the dining hall .", "1": "X enjoy the meals .", "2": "X enjoy the recipes .", "3": "X spend a lot of X 's time eating and catching up with friends in the campus dining halls .", "4": "X is a person who is not picky an eater .", "5": "X spends a lot of their time eating and catching up with friends in the campus dining halls ."}, {"0": "Mary works in student jobs on campus .", "1": "Mary needs to earn money to help pay for Mary 's college tuition .", "2": "Mary VP .", "3": "Mary does not need to earn money to help pay for Mary 's college tuition .", "4": "Mary is not picky ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["0"]}, {"4": ["7", "6", "b", "c"], "2": ["5", "6", "a", "b"], "3": ["7", "6", "b"], "9": ["0"]}, {"3": ["5"]}, {"1": ["(¬3)"], "3": ["(¬1)"], "(¬1)": ["3"], "(¬3)": ["1", "0"]}], "predicted_steps": [false, false, false, "Contradiction in the premises"]}
{"text": "No bakery is spicy. All cupcakes are bakeries. All hotpots are spicy. All products of Baked by Melissa are cupcakes. If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Dried Thai chilies are a product of Baked by Melissa?", "id": "79", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: No bakery is spicy.\nPremise 1.2: All cupcakes are bakeries.\nConclusion 1: No cupcake is spicy.\n\nPremise 2.1: All hotpots are spicy.\nPremise 2.2: All products of Baked by Melissa are cupcakes.\nConclusion 2: No product of Baked by Melissa is a hotpot.\n\nPremise 3.1: If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy.\nPremise 3.2: Dried Thai chilies are not a bakery.\nConclusion 3: Dried Thai chilies are spicy.\n\nPremise 4.1: No product of Baked by Melissa is a hotpot.\nPremise 4.2: Dried Thai chilies are spicy.\nConclusion 4: Dried Thai chilies are not a product of Baked by Melissa.\n\nConclusion 5: The answer is B. No, Dried Thai chilies are not a product of Baked by Melissa.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [(0→(1∨2)), (3→4)], [(0→1), (2→3)]]", "logic_conclusion": "[(4→5), (4→5), (5→6), (4→5)]", "correspondance": [{"0": "X is a bakery .", "1": "X is not spicy .", "2": "X is a cupcake .", "3": "X is a bakery .", "4": "X is a cupcake .", "5": "X is not spicy ."}, {"0": "X is a hotpot .", "1": "X is spicy .", "2": "X is a product of Baked by Melissa .", "3": "X is a cupcake .", "4": "X is a product of Baked by Melissa .", "5": "X is not a hotpot ."}, {"0": "dried Thai chilies are spicy or a bakery .", "1": "dried Thai chilies are a hotpot .", "2": "dried Thai chilies are spicy .", "3": "X is Dried a Thai chile .", "4": "X is not a bakery .", "5": "X is Dried a Thai chile .", "6": "X is spicy ."}, {"0": "X is a product of Baked by Melissa .", "1": "X is not a hotpot .", "2": "X is Dried a Thai chile .", "3": "X is spicy .", "4": "X is Dried a Thai chile .", "5": "X is not a product of Baked by Melissa ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"], "1": ["5"]}, {"4": ["2"], "3": ["5"], "(¬5)": ["0"]}, {"5": ["3"]}, {"4": ["2"], "(¬5)": ["0"]}], "predicted_steps": [true, true, false, false]}
{"text": "No bakery is spicy. All cupcakes are bakeries. All hotpots are spicy. All products of Baked by Melissa are cupcakes. If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Dried Thai chilies are not a product of Baked by Melissa?", "id": "80", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: No bakery is spicy.\nPremise 1.2: All cupcakes are bakeries.\nConclusion 1: No cupcake is spicy.\n\nPremise 2.1: All hotpots are spicy.\nPremise 2.2: All products of Baked by Melissa are cupcakes.\nConclusion 2: No product of Baked by Melissa is a hotpot.\n\nPremise 3.1: If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy.\nPremise 3.2: Dried Thai chilies are not a hotpot.\nConclusion 3: Dried Thai chilies are not spicy.\n\nPremise 4.1: Dried Thai chilies are not spicy.\nConclusion 4: Dried Thai chilies are not a product of Baked by Melissa.\n\nTherefore, the answer is A. Yes, it is true that Dried Thai chilies are not a product of Baked by Melissa.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [(0→(1∨2)), (3→4)], [(0→1)]]", "logic_conclusion": "[(4→5), (4→5), (5→6), (2→3)]", "correspondance": [{"0": "X is a bakery .", "1": "X is not spicy .", "2": "X is a cupcake .", "3": "X is a bakery .", "4": "X is a cupcake .", "5": "X is not spicy ."}, {"0": "X is a hotpot .", "1": "X is spicy .", "2": "X is a product of Baked by Melissa .", "3": "X is a cupcake .", "4": "X is a product of Baked by Melissa .", "5": "X is not a hotpot ."}, {"0": "dried Thai chilies are spicy or a bakery .", "1": "dried Thai chilies are a hotpot .", "2": "dried Thai chilies are spicy .", "3": "X is Dried a Thai chile .", "4": "X is not a hotpot .", "5": "X is a Dried Thai chile .", "6": "X is not spicy ."}, {"0": "X is a Dried Thai chile .", "1": "X is not spicy .", "2": "X is Dried a Thai chile .", "3": "X is not a product of Baked by Melissa ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"], "1": ["5"]}, {"4": ["2"], "3": ["5"], "(¬5)": ["0"]}, {"5": ["3", "(¬4)"]}, {"2": ["0"]}], "predicted_steps": [true, true, "Contradiction in the premises", false]}
{"text": "No bakery is spicy. All cupcakes are bakeries. All hotpots are spicy. All products of Baked by Melissa are cupcakes. If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Dried Thai chilies are a hotpot?", "id": "81", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: No bakery is spicy.\nPremise 1.2: All cupcakes are bakeries.\nConclusion 1: No cupcake is spicy.\n\nPremise 2.1: All hotpots are spicy.\nPremise 2.2: All products of Baked by Melissa are cupcakes.\nConclusion 2: No product of Baked by Melissa is a hotpot.\n\nPremise 3.1: If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy.\nPremise 3.2: Dried Thai chilies are not a bakery.\nConclusion 3: Dried Thai chilies are spicy.\n\nPremise 4.1: Dried Thai chilies are spicy.\nConclusion 4: Dried Thai chilies are not a hotpot.\n\nTherefore, the answer is B. No. Dried Thai chilies are not a hotpot.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [(0→(1∨2)), (3→4)], [(0→1)]]", "logic_conclusion": "[(4→5), (4→5), (5→6), (2→3)]", "correspondance": [{"0": "X is a bakery .", "1": "X is not spicy .", "2": "X is a cupcake .", "3": "X is a bakery .", "4": "X is a cupcake .", "5": "X is not spicy ."}, {"0": "X is a hotpot .", "1": "X is spicy .", "2": "X is a product of Baked by Melissa .", "3": "X is a cupcake .", "4": "X is a product of Baked by Melissa .", "5": "X is not a hotpot ."}, {"0": "dried Thai chilies are spicy or a bakery .", "1": "dried Thai chilies are a hotpot .", "2": "dried Thai chilies are spicy .", "3": "X is Dried a Thai chile .", "4": "X is not a bakery .", "5": "X is Dried a Thai chile .", "6": "X is spicy ."}, {"0": "X is Dried a Thai chile .", "1": "X is spicy .", "2": "X is Dried a Thai chile .", "3": "X is not a hotpot ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"], "1": ["5"]}, {"4": ["2"], "3": ["5"], "(¬5)": ["0"]}, {"5": ["3"]}, {"2": ["0"]}], "predicted_steps": [true, true, false, false]}
{"text": "No bakery is spicy. All cupcakes are bakeries. All hotpots are spicy. All products of Baked by Melissa are cupcakes. If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Dried Thai chilies are neither a product of Baked by Melissa nor a bakery?", "id": "82", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: No bakery is spicy.\nPremise 1.2: All cupcakes are bakeries.\nConclusion 1: No cupcake is spicy.\n\nPremise 2.1: All hotpots are spicy.\nPremise 2.2: All products of Baked by Melissa are cupcakes.\nConclusion 2: No product of Baked by Melissa is a hotpot.\n\nPremise 3.1: If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy.\nPremise 3.2: Dried Thai chilies are not a bakery.\nConclusion 3: Dried Thai chilies are spicy.\n\nPremise 4.1: No cupcake is spicy.\nPremise 4.2: Dried Thai chilies are spicy.\nConclusion 4: Dried Thai chilies are not a cupcake.\n\nPremise 5.1: Dried Thai chilies are not a cupcake.\nConclusion 5: Dried Thai chilies are neither a product of Baked by Melissa nor a bakery.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [(0→(1∨2)), (3→4)], [(0→1), (2→3)], [(0→1)]]", "logic_conclusion": "[(4→5), (4→5), (5→6), (4→5), (2→(3∧4))]", "correspondance": [{"0": "X is a bakery .", "1": "X is not spicy .", "2": "X is a cupcake .", "3": "X is a bakery .", "4": "X is a cupcake .", "5": "X is not spicy ."}, {"0": "X is a hotpot .", "1": "X is spicy .", "2": "X is a product of Baked by Melissa .", "3": "X is a cupcake .", "4": "X is a product of Baked by Melissa .", "5": "X is not a hotpot ."}, {"0": "dried Thai chilies are spicy or a bakery .", "1": "dried Thai chilies are a hotpot .", "2": "dried Thai chilies are spicy .", "3": "X is Dried a Thai chile .", "4": "X is not a bakery .", "5": "X is Dried a Thai chile .", "6": "X is spicy ."}, {"0": "X is a cupcake .", "1": "X is not spicy .", "2": "X is Dried a Thai chile .", "3": "X is spicy .", "4": "X is Dried a Thai chile .", "5": "X is not a cupcake ."}, {"0": "X is Dried a Thai chile .", "1": "X is not a cupcake .", "2": "X is Dried a Thai chile .", "3": "X is not a product of Baked by Melissa .", "4": "X is not a bakery ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"], "1": ["5"]}, {"4": ["2"], "3": ["5"], "(¬5)": ["0"]}, {"5": ["3"]}, {"4": ["2"], "1": ["(¬3)"], "3": ["(¬1)"], "(¬5)": ["0"]}, {"2": ["0"]}], "predicted_steps": [true, true, false, true, false]}
{"text": "No bakery is spicy. All cupcakes are bakeries. All hotpots are spicy. All products of Baked by Melissa are cupcakes. If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Dried Thai chilies are cupcakes and a product of Baked by Melissa?", "id": "83", "ground_truth": "False", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: No bakery is spicy.\nPremise 1.2: All cupcakes are bakeries.\nConclusion 1: No cupcake is spicy.\n\nPremise 2.1: All hotpots are spicy.\nPremise 2.2: If dried Thai chilies are spicy or a bakery, then dried Thai chilies are a hotpot or are spicy.\nConclusion 2: If dried Thai chilies are spicy, then they are not a bakery.\n\nPremise 3.1: All products of Baked by Melissa are cupcakes.\nPremise 3.2: Dried Thai chilies are not a cupcake.\nConclusion 3: Dried Thai chilies are not a product of Baked by Melissa.\n\nConclusion 4: Therefore, the statement \"Dried Thai chilies are cupcakes and a product of Baked by Melissa\" is false.\n\nAnswer: B. No", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→(3∨4))], [(0→1), (2→3)]]", "logic_conclusion": "[(4→5), (5→6), (4→5)]", "correspondance": [{"0": "X is a bakery .", "1": "X is not spicy .", "2": "X is a cupcake .", "3": "X is a bakery .", "4": "X is a cupcake .", "5": "X is not spicy ."}, {"0": "X is a hotpot .", "1": "X is spicy .", "2": "dried Thai chilies are spicy or a bakery .", "3": "dried Thai chilies are a hotpot .", "4": "dried Thai chilies are spicy .", "5": "dried Thai chilies are spicy .", "6": "dried Thai chilies are not a bakery ."}, {"0": "X is a product of Baked by Melissa .", "1": "X is a cupcake .", "2": "X is Dried a Thai chile .", "3": "X is not a cupcake .", "4": "X is Dried a Thai chile .", "5": "X is not a product of Baked by Melissa ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"], "1": ["5"]}, {"5": ["2"], "3": ["6"]}, {"4": ["2", "(¬1)"], "1": ["(¬3)"], "3": ["(¬1)"], "(¬5)": ["0"]}], "predicted_steps": [true, false, true]}
{"text": "If the restaurant is listed in Yelp’s recommendations, then the restaurant does not receive many negative reviews. All restaurants with a rating greater than 9 are listed in Yelp’s recommendations. Some restaurants that do not provide take-out service receive many negative reviews. All restaurants that are popular among local residents have ratings greater than 9. Subway has a rating greater than 9 or is popular among local residents.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Subway provides take-out service and receives many negative reviews, then its rating is greater than 9 and it does not provide take-out service?", "id": "84", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a restaurant is listed in Yelp’s recommendations, then it does not receive many negative reviews.\nPremise 1.2: All restaurants with a rating greater than 9 are listed in Yelp’s recommendations.\nConclusion 1: Restaurants with a rating greater than 9 do not receive many negative reviews.\n\nPremise 2.1: Some restaurants that do not provide take-out service receive many negative reviews.\nPremise 2.2: All restaurants that are popular among local residents have ratings greater than 9.\nConclusion 2: Restaurants that are popular among local residents and do not provide take-out service have ratings greater than 9.\n\nPremise 3.1: Subway has a rating greater than 9 or is popular among local residents.\nConclusion 3: Subway has a rating greater than 9 or does not provide take-out service.\n\nPremise 4.1: If Subway provides take-out service and receives many negative reviews, then its rating is greater than 9 and it does not provide take-out service.\nConclusion 4: It is not true that If Subway provides take-out service and receives many negative reviews, then its rating is greater than 9 and it does not provide take-out service.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((0∧1)→2), (3→4)], [0, (1→2)], [(0∨1)], [((0∧1)→(2∧5))]]", "logic_conclusion": "[(5→6), (3→4), (2∨3), ((6∧7)→(8∧b))]", "correspondance": [{"0": "X is a restaurant", "1": "X is listed in Yelp ’s 's recommendations .", "2": "X does not receive many negative reviews .", "3": "X is a restaurant with a rating greater than 9 .", "4": "X is listed in Yelp ’s 's recommendations .", "5": "X is a Restaurant with a rating greater than 9 .", "6": "X does not receives many negative reviews ."}, {"0": "Some restaurants that do not provide take - out service receive many negative reviews .", "1": "X is a restaurant that is popular among local a resident .", "2": "X has ratings greater than 9 .", "3": "X is a Restaurant that are popular among local residents and do not provide take - out service .", "4": "X has ratings greater than 9 ."}, {"0": "Subway has a rating greater than 9 .", "1": "Subway is popular among local residents .", "2": "Subway has a rating greater than 9 .", "3": "Subway does not provide take - out service ."}, {"0": "Subway provides take - out service .", "1": "Subway receives many negative reviews .", "2": "Subway 's rating is greater than 9 .", "3": "Subway provides take - out service .", "4": "Subway receives many negative reviews .", "5": "Subway does not provide take - out service .", "6": "It is not true that Subway provides take - out service .", "7": "It is not true that Subway receives many negative reviews .", "8": "It is not true that Subway 's rating is greater than 9 .", "9": "It is not true that Subway provides take - out service .", "a": "It is not true that Subway receives many negative reviews .", "b": "It is not true that Subway does not provide take - out service ."}], "errors": [[]], "entailments_dict": [{"4": ["1"], "5": ["3"], "2": ["6"]}, {"2": ["4"]}, {"2": ["0"], "0": ["2"]}, {"(¬b)": ["0"]}], "predicted_steps": [false, false, false, false]}
{"text": "If the restaurant is listed in Yelp’s recommendations, then the restaurant does not receive many negative reviews. All restaurants with a rating greater than 9 are listed in Yelp’s recommendations. Some restaurants that do not provide take-out service receive many negative reviews. All restaurants that are popular among local residents have ratings greater than 9. Subway has a rating greater than 9 or is popular among local residents.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Subway provides take-out service and does not receive many negative reviews?", "id": "85", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a restaurant is listed in Yelp’s recommendations, then it does not receive many negative reviews.\nPremise 1.2: All restaurants with a rating greater than 9 are listed in Yelp’s recommendations.\nConclusion 1: Restaurants with a rating greater than 9 do not receive many negative reviews.\n\nPremise 2.1: Some restaurants that do not provide take-out service receive many negative reviews.\nPremise 2.2: All restaurants that are popular among local residents have ratings greater than 9.\nConclusion 2: Restaurants that are popular among local residents and do not provide take-out service receive many negative reviews.\n\nPremise 3.1: Subway has a rating greater than 9 or is popular among local residents.\nConclusion 3: Subway does not receive many negative reviews.\n\nPremise 4.1: Subway does not receive many negative reviews.\nPremise 4.2: Subway has a rating greater than 9 or is popular among local residents.\nConclusion 4: Subway provides take-out service.\n\nConclusion 5: Therefore, the answer is A. Yes, Subway provides take-out service and does not receive many negative reviews.", "logic_premises": "[[((0∧1)→2), (3→4)], [0, (1→2)], [(0∨1)], [0, (1∨2)]]", "logic_conclusion": "[(5→6), (3→4), 2, 3]", "correspondance": [{"0": "X is a restaurant", "1": "X is listed in Yelp ’s 's recommendations .", "2": "X does not receive many negative reviews .", "3": "X is a restaurant with a rating greater than 9 .", "4": "X is listed in Yelp ’s 's recommendations .", "5": "X is a Restaurant with a rating greater than 9 .", "6": "X does not receives many negative reviews ."}, {"0": "Some restaurants that do not provide take - out service receive many negative reviews .", "1": "X is a restaurant that is popular among local a resident .", "2": "X has ratings greater than 9 .", "3": "X is a Restaurant that are popular among local residents and do not provide take - out service .", "4": "X receives many negative reviews ."}, {"0": "Subway has a rating greater than 9 .", "1": "Subway is popular among local residents .", "2": "Subway does not receive many negative reviews ."}, {"0": "Subway does not receive many negative reviews .", "1": "Subway has a rating greater than 9 .", "2": "Subway is popular among local residents .", "3": "Subway provides take - out service ."}], "errors": [[]], "entailments_dict": [{"4": ["1"], "5": ["3"], "2": ["6"]}, {}, {}, {}], "predicted_steps": [false, false, false, false]}
{"text": "If the restaurant is listed in Yelp’s recommendations, then the restaurant does not receive many negative reviews. All restaurants with a rating greater than 9 are listed in Yelp’s recommendations. Some restaurants that do not provide take-out service receive many negative reviews. All restaurants that are popular among local residents have ratings greater than 9. Subway has a rating greater than 9 or is popular among local residents.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Subway does not provide take-out service?", "id": "86", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a restaurant is listed in Yelp’s recommendations, then it does not receive many negative reviews.\nPremise 1.2: All restaurants with a rating greater than 9 are listed in Yelp’s recommendations.\nConclusion 1: Restaurants with a rating greater than 9 do not receive many negative reviews.\n\nPremise 2.1: Some restaurants that do not provide take-out service receive many negative reviews.\nConclusion 2: Restaurants that do not provide take-out service may receive many negative reviews.\n\nPremise 3.1: All restaurants that are popular among local residents have ratings greater than 9.\nPremise 3.2: Subway has a rating greater than 9 or is popular among local residents.\nConclusion 3: Subway has a rating greater than 9 or is popular among local residents.\n\nPremise 4.1: If Subway has a rating greater than 9, then it does not receive many negative reviews.\nPremise 4.2: Subway has a rating greater than 9 or is popular among local residents.\nConclusion 4: Subway does not receive many negative reviews.\n\nPremise 5.1: Subway does not receive many negative reviews.\nConclusion 5: B. No, it is not true that Subway does not provide take-out service.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((0∧1)→2), (3→4)], [0], [(6→7), (2∨3)], [(0→1), (2∨3)], [0]]", "logic_conclusion": "[(5→6), (1→2), (4∨5), 4, 1]", "correspondance": [{"0": "X is a restaurant", "1": "X is listed in Yelp ’s 's recommendations .", "2": "X does not receive many negative reviews .", "3": "X is a restaurant with a rating greater than 9 .", "4": "X is listed in Yelp ’s 's recommendations .", "5": "X is a Restaurant with a rating greater than 9 .", "6": "X does not receives many negative reviews ."}, {"0": "Some restaurants that do not provide take - out service receive many negative reviews .", "1": "X is a Restaurant that do not provide take - out service .", "2": "X may receive many negative reviews ."}, {"0": "X is a restaurant that is popular among local a resident .", "1": "X has ratings greater than 9 .", "2": "Subway has a rating greater than 9 .", "3": "Subway is popular among local residents .", "4": "Subway has a rating greater than 9 .", "5": "Subway is popular among local residents .", "6": "Subway is a restaurant that is popular among local a resident .", "7": "Subway has ratings greater than 9 ."}, {"0": "Subway has a rating greater than 9 .", "1": "Subway does not receive many negative reviews .", "2": "Subway has a rating greater than 9 .", "3": "Subway is popular among local residents .", "4": "Subway does not receive many negative reviews ."}, {"0": "Subway does not receive many negative reviews .", "1": "B. No , it is not true that Subway does not provide take - out service ."}], "errors": [[]], "entailments_dict": [{"4": ["1"], "5": ["3"], "2": ["6"]}, {}, {"7": ["2", "4"], "3": ["6", "5"], "4": ["2"], "5": ["6", "3"], "2": ["4"]}, {"2": ["0"], "1": ["4"]}, {}], "predicted_steps": [false, false, true, false, false]}
{"text": "In superhero movies, the good guys always win. The Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie. Good guys fight bad guys and vice versa. Sir Digby fights his nemesis. If a superhero movie is named after a character, that character is a good guy. The Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby. If somebody wins a fight, the person they are fighting loses. If a superhero movie is named after a character, that character appears in the movie.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Sir Digby’s nemesis loses?", "id": "87", "ground_truth": "True", "reasoning": " Here is my reasoning:\n\nPremise 1.1: In superhero movies, the good guys always win.\nPremise 1.2: The Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie.\nConclusion 1: The good guys win in The Surprising Adventures of Sir Digby Chicken Caesar.\n\nPremise 2.1: Good guys fight bad guys and vice versa.\nPremise 2.2: Sir Digby fights his nemesis.\nConclusion 2: Sir Digby's nemesis is a bad guy.\n\nPremise 3.1: If a superhero movie is named after a character, that character is a good guy.\nPremise 3.2: The Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby.\nConclusion 3: Sir Digby is a good guy.\n\nPremise 4.1: If somebody wins a fight, the person they are fighting loses.\nPremise 4.2: Sir Digby wins a fight against his nemesis.\nConclusion 4: Sir Digby's nemesis loses.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, 1], [0, 1], [(((5∧6)→2)∪((7∧8)→2)), 3], [((4→5)∪((6→7)∪(8→9))), 2]]", "logic_conclusion": "[2, 2, 4, 3]", "correspondance": [{"0": "In superhero movies , the good guys always win .", "1": "The Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie .", "2": "The good guys win in The Surprising Adventures of Sir Digby Chicken Caesar ."}, {"0": "Good guys fight bad guys and vice versa .", "1": "Sir Digby fights Sir Digby 's nemesis .", "2": "Sir Digby 's nemesis is a bad guy ."}, {"0": "X is a superhero movie", "1": "X is named after a character .", "2": "a character is a good guy .", "3": "The Surprising Adventures of Sir Digby Chicken Caesar is named after Sir Digby .", "4": "Sir Digby is a good guy .", "5": "Sir Digby is a superhero movie", "6": "Sir Digby is named after a character .", "7": "The Surprising Adventures of Sir Digby Chicken Caesar is a superhero movie", "8": "The Surprising Adventures of Sir Digby Chicken Caesar is named after a character ."}, {"0": "X wins a fight .", "1": "the person X are fighting loses .", "2": "Sir Digby wins a fight against Sir Digby 's nemesis .", "3": "Sir Digby 's nemesis loses .", "4": "Sir Digby wins a fight .", "5": "the person Sir Digby are fighting loses .", "6": "the person they are fighting wins a fight .", "7": "the person the person they are fighting are fighting loses .", "8": "Sir Digbys nemesis wins a fight .", "9": "the person Sir Digbys nemesis are fighting loses ."}], "errors": [[]], "entailments_dict": [{"0": ["2"]}, {"1": ["0"], "0": ["1", "2"], "2": ["0", "1"]}, {"3": ["8"], "4": ["8", "3"]}, {"3": ["6", "2"], "9": ["3", "2"], "5": ["3", "(¬2)"], "2": ["3", "4", "6"], "(¬2)": ["8"]}], "predicted_steps": [true, true, false, "Contradiction in the premises"]}
{"text": "[BG] Books contain tons of knowledge. [BG] When a person reads a book, that person gains knowledge. [BG] If a person gains knowledge, they become smarter. Harry read the book “Walden” by Henry Thoreau.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Walden contains knowledge?", "id": "88", "ground_truth": "True", "reasoning": " Sure, I can help you with that! Here's my step-by-step reasoning:\n\nPremise 1: Books contain tons of knowledge.\nConclusion 1: The book \"Walden\" by Henry Thoreau contains knowledge.\n\nPremise 2: When a person reads a book, they gain knowledge.\nConclusion 2: Harry gained knowledge by reading \"Walden\".\n\nPremise 3: If a person gains knowledge, they become smarter.\nConclusion 3: Harry became smarter after reading \"Walden\".\n\nPremise 4: The book \"Walden\" contains knowledge.\nConclusion 4: The book \"Walden\" contains knowledge.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(3→4)], [(0→1)], [(((4∧5)→6)∪((7∧8)→9))], [0]]", "logic_conclusion": "[2, 2, 3, 1]", "correspondance": [{"0": "X is a Book .", "1": "X contains tons of knowledge .", "2": "The book \" Walden \" by Henry Thoreau contains knowledge .", "3": "The book \"Walden\" by Henry Thoreau is a Book .", "4": "The book \"Walden\" by Henry Thoreau contains tons of knowledge ."}, {"0": "a person reads a book .", "1": "a person gain knowledge .", "2": "Harry gained knowledge by reading \" Walden \" ."}, {"0": "X is a person", "1": "X gains knowledge .", "2": "X become smarter .", "3": "Harry became smarter after reading \" Walden \" .", "4": "Walden is a person", "5": "Walden gains knowledge .", "6": "Walden become smarter .", "7": "Harry is a person", "8": "Harry gains knowledge .", "9": "Harry become smarter ."}, {"0": "the book \" Walden \" contains knowledge .", "1": "the book \" Walden \" contains knowledge ."}], "errors": [[]], "entailments_dict": [{"2": ["3"], "4": ["2"]}, {"2": ["0"]}, {"3": ["8"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [false, false, false, true]}
{"text": "[BG] Books contain tons of knowledge. [BG] When a person reads a book, that person gains knowledge. [BG] If a person gains knowledge, they become smarter. Harry read the book “Walden” by Henry Thoreau.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is smarter than before?", "id": "89", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Books contain tons of knowledge.\nPremise 1.2: When a person reads a book, that person gains knowledge.\nConclusion 1: Reading books can make a person gain knowledge.\nPremise 2.1: If a person gains knowledge, they become smarter.\nConclusion 2: Gaining knowledge can make a person become smarter.\nPremise 3.1: Harry read the book “Walden” by Henry Thoreau.\nConclusion 3: Harry gained knowledge from reading the book.\nPremise 4.1: Gaining knowledge can make a person become smarter.\nConclusion 4: Harry became smarter after reading the book.\nPremise 5.1: Harry became smarter after reading the book.\nConclusion 5: A. Yes, it is true that Harry is smarter than before.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [((0∧1)→2)], [0], [0], [0]]", "logic_conclusion": "[4, 3, 1, 1, 1]", "correspondance": [{"0": "X is a Book .", "1": "X contains tons of knowledge .", "2": "a person reads a book .", "3": "a person gains knowledge .", "4": "Reading books can make a person gain knowledge ."}, {"0": "X is a person", "1": "X gains knowledge .", "2": "X become smarter .", "3": "Gaining knowledge can make a person become smarter ."}, {"0": "Harry read the book “ Walden ” by Henry Thoreau .", "1": "Harry gained knowledge from reading the book “ Walden ” by Henry Thoreau ."}, {"0": "Gaining knowledge can make a person become smarter .", "1": "Harry became smarter after reading the book ."}, {"0": "Harry became smarter after reading the book .", "1": "A. Yes , it is true that Harry is smarter than before ."}], "errors": [[]], "entailments_dict": [{"3": ["4"]}, {"2": ["3"]}, {"1": ["0"], "0": ["1"]}, {"1": ["0"], "0": ["1"]}, {"0": ["1"]}], "predicted_steps": [false, false, true, true, true]}
{"text": "[BG] Books contain tons of knowledge. [BG] When a person reads a book, that person gains knowledge. [BG] If a person gains knowledge, they become smarter. Harry read the book “Walden” by Henry Thoreau.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that A person who is smarter has gained knowledge?", "id": "90", "ground_truth": "Uncertain", "reasoning": " Sure, I can help you with that! Here's my step-by-step reasoning:\n\nPremise 1.1: Books contain tons of knowledge.\nPremise 1.2: When a person reads a book, that person gains knowledge.\nConclusion 1: Reading books can make a person gain knowledge.\nPremise 2.1: If a person gains knowledge, they become smarter.\nConclusion 2: Gaining knowledge can make a person become smarter.\nPremise 3.1: Harry read the book “Walden” by Henry Thoreau.\nConclusion 3: Harry gained knowledge from reading the book.\nPremise 4.1: Gaining knowledge can make a person become smarter.\nPremise 4.2: Harry gained knowledge from reading the book.\nConclusion 4: Harry became smarter after reading the book.\nPremise 5.1: A person who is smarter has gained knowledge.\nConclusion 5: The statement is true.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [((0∧1)→2)], [0], [0, 1], [0]]", "logic_conclusion": "[4, 3, 1, 2, 1]", "correspondance": [{"0": "X is a Book .", "1": "X contains tons of knowledge .", "2": "a person reads a book .", "3": "a person gains knowledge .", "4": "Reading books can make a person gain knowledge ."}, {"0": "X is a person", "1": "X gains knowledge .", "2": "X become smarter .", "3": "Gaining knowledge can make a person become smarter ."}, {"0": "Harry read the book “ Walden ” by Henry Thoreau .", "1": "Harry gained knowledge from reading the book “ Walden ” by Henry Thoreau ."}, {"0": "Gaining knowledge can make a person become smarter .", "1": "Harry gained knowledge from reading the book .", "2": "Harry became smarter after reading the book ."}, {"0": "A person who is smarter has gained knowledge .", "1": "The statement is true ."}], "errors": [[]], "entailments_dict": [{"3": ["4"]}, {"2": ["3"]}, {"1": ["0"], "0": ["1"]}, {"1": ["0", "2"], "2": ["0", "1"], "0": ["2"]}, {}], "predicted_steps": [false, false, true, true, false]}
{"text": "Natural language processing tasks can be categorized as either language generation task or language understanding task. If the output of a natural language processing task is a text sequence, then it is a language generation task. Machine translation is a natural language processing task. The output of machine translation is a text sequence.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Machine translation is a language generation task?", "id": "91", "ground_truth": "True", "reasoning": " Sure, I can help you with that! Here's my step-by-step reasoning:\n\nPremise 1.1: Natural language processing tasks can be categorized as either language generation tasks or language understanding tasks.\nPremise 1.2: If the output of a natural language processing task is a text sequence, then it is a language generation task.\nPremise 2.1: Machine translation is a natural language processing task.\nPremise 2.2: The output of machine translation is a text sequence.\nConclusion 1: Machine translation is a language generation task.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0⊻1), (((8∧9)→a)∪((b∧c)→d)), 5, 6]]", "logic_conclusion": "[7]", "correspondance": [{"0": "Natural language processing tasks can be categorized as language generation tasks .", "1": "Natural language processing tasks can be categorized as language understanding tasks .", "2": "X is a natural language processing task", "3": "the output of X is a text sequence .", "4": "X is a language generation task .", "5": "Machine translation is a natural language processing task .", "6": "The output of machine translation is a text sequence .", "7": "Machine translation is a language generation task .", "8": "The output of machine translation is a natural language processing task", "9": "the output of The output of machine translation is a text sequence .", "a": "The output of machine translation is a language generation task .", "b": "the output of a natural language processing task is a natural language processing task", "c": "the output of the output of a natural language processing task is a text sequence .", "d": "the output of a natural language processing task is a language generation task ."}], "errors": [[]], "entailments_dict": [{"d": ["6", "5", "7", "0"], "a": ["6", "0", "5", "7"], "6": ["5", "c", "0", "9", "7"], "5": ["1", "9", "b", "6", "c", "8"], "0": ["5", "6", "7", "9", "c", "8"], "1": ["5", "8"], "7": ["0", "9", "8", "c", "5", "6"]}], "predicted_steps": ["Contradiction in the premises"]}
{"text": "Natural language processing tasks can be categorized as either language generation task or language understanding task. If the output of a natural language processing task is a text sequence, then it is a language generation task. Machine translation is a natural language processing task. The output of machine translation is a text sequence.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Machine translation is a language understanding task?", "id": "92", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Natural language processing tasks can be categorized as either language generation tasks or language understanding tasks.\nPremise 1.2: If the output of a natural language processing task is a text sequence, then it is a language generation task.\nPremise 2.1: Machine translation is a natural language processing task.\nPremise 2.2: The output of machine translation is a text sequence.\nConclusion 1: Machine translation is a language generation task.\n\nTherefore, the answer is B. No. Machine translation is not a language understanding task, but rather a language generation task.", "logic_premises": "[[(0⊻1), (((8∧9)→a)∪((b∧c)→d)), 5, 6]]", "logic_conclusion": "[7]", "correspondance": [{"0": "Natural language processing tasks can be categorized as language generation tasks .", "1": "Natural language processing tasks can be categorized as language understanding tasks .", "2": "X is a natural language processing task", "3": "the output of X is a text sequence .", "4": "X is a language generation task .", "5": "Machine translation is a natural language processing task .", "6": "The output of machine translation is a text sequence .", "7": "Machine translation is a language generation task .", "8": "The output of machine translation is a natural language processing task", "9": "the output of The output of machine translation is a text sequence .", "a": "The output of machine translation is a language generation task .", "b": "the output of a natural language processing task is a natural language processing task", "c": "the output of the output of a natural language processing task is a text sequence .", "d": "the output of a natural language processing task is a language generation task ."}], "errors": [[]], "entailments_dict": [{"d": ["6", "0", "5", "7"], "a": ["6", "0", "5", "7"], "0": ["9", "5", "6", "c", "8", "7"], "1": ["8", "5"], "6": ["5", "c", "0", "9", "7"], "5": ["1", "9", "b", "6", "c", "8"], "7": ["0", "9", "8", "c", "5", "6"]}], "predicted_steps": ["Contradiction in the premises"]}
{"text": "Pets are allowed in some managed buildings. [BG] A deposit is required to rent an apartment in a managed building. The security deposit can be either equal to one month's rent or more. Fluffy is Tom's cat. Cats are pets. The Olive Garden is a managed building. The monthly rent at the Olive Garden is $2000. Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500. 2000$ is more than $1500.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Tom will rent an apartment in The Olive Garden?", "id": "93", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Pets are allowed in some managed buildings.\nPremise 1.2: The Olive Garden is a managed building.\nConclusion 1: Pets are allowed in The Olive Garden.\n\nPremise 2.1: A deposit is required to rent an apartment in a managed building.\nPremise 2.2: The security deposit can be either equal to one month's rent or more.\nConclusion 2: The security deposit for an apartment in The Olive Garden is either $2000 or more.\n\nPremise 3.1: Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.\nPremise 3.2: Fluffy is Tom's cat.\nPremise 3.3: Cats are pets.\nConclusion 3: Tom will rent an apartment in The Olive Garden if the security deposit is no more than $1500.\n\nPremise 4.1: The monthly rent at The Olive Garden is $2000.\nPremise 4.2: 2000$ is more than $1500.\nConclusion 4: The security deposit for an apartment in The Olive Garden is more than $1500.\n\nConclusion 5: Tom will not rent an apartment in The Olive Garden.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, 1], [0, (1∨2)], [((8→(1∨9))∪((a→(1∨b))∪((c→(1∨d))∪((e→(1∨f))∪(g→(1∨h)))))), 3, ((i→j)∪((k→l)∪((m→n)∪((o→p)∪(q→r)))))], [0, 1]]", "logic_conclusion": "[2, 3, ((s→t)∪((u→v)∪((w→x)∪((y→z)∪(A→B))))), 2]", "correspondance": [{"0": "Pets are allowed in some managed buildings .", "1": "The Olive Garden is a managed building .", "2": "Pets are allowed in The Olive Garden ."}, {"0": "a deposit is required to rent an apartment in a managed building .", "1": "a deposit can be either equal to one month 's rent .", "2": "a deposit can be either equal to more .", "3": "The security deposit for an apartment in The Olive Garden is either $ 2000 or more ."}, {"0": "X is a more than $ 1500 .", "1": "Tom will not rent an apartment in a managed building that Tom is allowed to move in with Fluffy .", "2": "Tom will not rent an apartment in a managed building that the security deposit is X .", "3": "Fluffy is Tom 's cat .", "4": "X is a Cat .", "5": "X is a pet .", "6": "X is a more than $ 1500 .", "7": "Tom will not rent an apartment in The Olive Garden that the security deposit is X .", "8": "Tom is a more than $ 1500 .", "9": "Tom will not rent an apartment in a managed building that the security deposit is Tom .", "a": "Toms cat is a more than $ 1500 .", "b": "Tom will not rent an apartment in a managed building that the security deposit is Toms cat .", "c": "the security deposit is a more than $ 1500 .", "d": "Tom will not rent an apartment in a managed building that the security deposit is the security deposit .", "e": "Fluffy is a more than $ 1500 .", "f": "Tom will not rent an apartment in a managed building that the security deposit is Fluffy .", "g": "The Olive Garden is a more than $ 1500 .", "h": "Tom will not rent an apartment in a managed building that the security deposit is The Olive Garden .", "i": "Tom is a Cat .", "j": "Tom is a pet .", "k": "Toms cat is a Cat .", "l": "Toms cat is a pet .", "m": "the security deposit is a Cat .", "n": "the security deposit is a pet .", "o": "Fluffy is a Cat .", "p": "Fluffy is a pet .", "q": "The Olive Garden is a Cat .", "r": "The Olive Garden is a pet .", "s": "Tom is a more than $ 1500 .", "t": "Tom will not rent an apartment in The Olive Garden that the security deposit is Tom .", "u": "Toms cat is a more than $ 1500 .", "v": "Tom will not rent an apartment in The Olive Garden that the security deposit is Toms cat .", "w": "the security deposit is a more than $ 1500 .", "x": "Tom will not rent an apartment in The Olive Garden that the security deposit is the security deposit .", "y": "Fluffy is a more than $ 1500 .", "z": "Tom will not rent an apartment in The Olive Garden that the security deposit is Fluffy .", "A": "The Olive Garden is a more than $ 1500 .", "B": "Tom will not rent an apartment in The Olive Garden that the security deposit is The Olive Garden ."}, {"0": "The monthly rent at The Olive Garden is 2000$.", "1": "2000 $ is more than $ 1500 .", "2": "The security deposit for an apartment in The Olive Garden is more than $ 1500 ."}], "errors": [[]], "entailments_dict": [{"2": ["0"]}, {"3": ["0", "2"]}, {"3": ["k", "o"], "1": ["3"], "l": ["3"], "s": ["8"], "u": ["a"], "y": ["e"], "w": ["c", "(¬b)", "(¬n)"], "A": ["g", "(¬r)"], "b": ["m", "v"], "h": ["B"], "9": ["B"], "n": ["(¬9)", "(¬d)"], "(¬v)": ["3", "m", "k"]}, {"2": ["1"], "0": ["1"]}], "predicted_steps": [false, false, false, false]}
{"text": "Pets are allowed in some managed buildings. [BG] A deposit is required to rent an apartment in a managed building. The security deposit can be either equal to one month's rent or more. Fluffy is Tom's cat. Cats are pets. The Olive Garden is a managed building. The monthly rent at the Olive Garden is $2000. Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500. 2000$ is more than $1500.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Tom is allowed to move in an apartment in The Olive Garden with Fluffy?", "id": "94", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Pets are allowed in some managed buildings.\nPremise 1.2: The Olive Garden is a managed building.\nConclusion 1: Pets are allowed in The Olive Garden.\n\nPremise 2.1: A deposit is required to rent an apartment in a managed building.\nPremise 2.2: The security deposit can be either equal to one month's rent or more.\nConclusion 2: The security deposit for an apartment in The Olive Garden is either $2000 or more.\n\nPremise 3.1: Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.\nPremise 3.2: The security deposit for an apartment in The Olive Garden is $2000, which is more than $1500.\nConclusion 3: Tom is not allowed to move in an apartment in The Olive Garden with Fluffy.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, 1], [0, (1∨2)], [((6→(1∨7))∪((8→(1∨9))∪((a→(1∨b))∪((c→(1∨d))∪(e→(1∨f)))))), (3∧4)]]", "logic_conclusion": "[2, 3, 5]", "correspondance": [{"0": "Pets are allowed in some managed buildings .", "1": "The Olive Garden is a managed building .", "2": "Pets are allowed in The Olive Garden ."}, {"0": "a deposit is required to rent an apartment in a managed building .", "1": "a deposit can be either equal to one month 's rent .", "2": "a deposit can be either equal to more .", "3": "The security deposit for an apartment in The Olive Garden is either $ 2000 or more ."}, {"0": "X is a more than $ 1500 .", "1": "Tom will not rent an apartment in a managed building that Tom is allowed to move in with Fluffy .", "2": "Tom will not rent an apartment in a managed building that the security deposit is X .", "3": "The security deposit for an apartment in The Olive Garden is $ 2000 .", "4": "$ 2000 is more than $ 1500 .", "5": "Tom is not allowed to move in an apartment in The Olive Garden with Fluffy .", "6": "Tom is a more than $ 1500 .", "7": "Tom will not rent an apartment in a managed building that the security deposit is Tom .", "8": "the security deposit is a more than $ 1500 .", "9": "Tom will not rent an apartment in a managed building that the security deposit is the security deposit .", "a": "Fluffy is a more than $ 1500 .", "b": "Tom will not rent an apartment in a managed building that the security deposit is Fluffy .", "c": "The security deposit for an apartment in The Olive Garden is a more than $ 1500 .", "d": "Tom will not rent an apartment in a managed building that the security deposit is The security deposit for an apartment in The Olive Garden .", "e": "The Olive Garden is a more than $ 1500 .", "f": "Tom will not rent an apartment in a managed building that the security deposit is The Olive Garden ."}], "errors": [[]], "entailments_dict": [{"2": ["0"]}, {"3": ["0", "2"]}, {"3": ["(¬b)"], "(¬8)": ["4"], "(¬e)": ["4"]}], "predicted_steps": [false, false, false]}
{"text": "Pets are allowed in some managed buildings. [BG] A deposit is required to rent an apartment in a managed building. The security deposit can be either equal to one month's rent or more. Fluffy is Tom's cat. Cats are pets. The Olive Garden is a managed building. The monthly rent at the Olive Garden is $2000. Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500. 2000$ is more than $1500.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The security deposit at the Olive Garden is either $2000 or more?", "id": "95", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Pets are allowed in some managed buildings.\nPremise 1.2: The Olive Garden is a managed building.\nConclusion 1: Pets are allowed in the Olive Garden.\n\nPremise 2.1: A deposit is required to rent an apartment in a managed building.\nPremise 2.2: The security deposit can be either equal to one month's rent or more.\nConclusion 2: The security deposit for an apartment in the Olive Garden is either $2000 or more.\n\nPremise 3.1: Tom will rent an apartment in a managed building if and only if he is allowed to move in with Fluffy, and the security deposit is no more than $1500.\nPremise 3.2: Fluffy is Tom's cat.\nPremise 3.3: Cats are pets.\nConclusion 3: Tom will rent an apartment in the Olive Garden if the security deposit is no more than $1500.\n\nPremise 4.1: 2000$ is more than $1500.\nConclusion 4: The security deposit at the Olive Garden is either $2000 or more.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, 1], [0, (1∨2)], [((8→(1∨9))∪((a→(1∨b))∪((c→(1∨d))∪((e→(1∨f))∪(g→(1∨h)))))), 3, ((i→j)∪((k→l)∪((m→n)∪((o→p)∪(q→r)))))], [0]]", "logic_conclusion": "[2, 3, ((s→t)∪((u→v)∪((w→x)∪((y→z)∪(A→B))))), 1]", "correspondance": [{"0": "Pets are allowed in some managed buildings .", "1": "The Olive Garden is a managed building .", "2": "Pets are allowed in The Olive Garden ."}, {"0": "a deposit is required to rent an apartment in a managed building .", "1": "a deposit can be either equal to one month 's rent .", "2": "a deposit can be either equal to more .", "3": "The security deposit for an apartment in the Olive Garden is either $ 2000 or more ."}, {"0": "X is a more than $ 1500 .", "1": "Tom will not rent an apartment in a managed building that Tom is allowed to move in with Fluffy .", "2": "Tom will not rent an apartment in a managed building that the security deposit is X .", "3": "Fluffy is Tom 's cat .", "4": "X is a Cat .", "5": "X is a pet .", "6": "X is a more than $ 1500 .", "7": "Tom will not rent an apartment in the Olive Garden that the security deposit is X .", "8": "the Olive Garden is a more than $ 1500 .", "9": "Tom will not rent an apartment in a managed building that the security deposit is the Olive Garden .", "a": "Tom is a more than $ 1500 .", "b": "Tom will not rent an apartment in a managed building that the security deposit is Tom .", "c": "Toms cat is a more than $ 1500 .", "d": "Tom will not rent an apartment in a managed building that the security deposit is Toms cat .", "e": "the security deposit is a more than $ 1500 .", "f": "Tom will not rent an apartment in a managed building that the security deposit is the security deposit .", "g": "Fluffy is a more than $ 1500 .", "h": "Tom will not rent an apartment in a managed building that the security deposit is Fluffy .", "i": "the Olive Garden is a Cat .", "j": "the Olive Garden is a pet .", "k": "Tom is a Cat .", "l": "Tom is a pet .", "m": "Toms cat is a Cat .", "n": "Toms cat is a pet .", "o": "the security deposit is a Cat .", "p": "the security deposit is a pet .", "q": "Fluffy is a Cat .", "r": "Fluffy is a pet .", "s": "the Olive Garden is a more than $ 1500 .", "t": "Tom will not rent an apartment in the Olive Garden that the security deposit is the Olive Garden .", "u": "Tom is a more than $ 1500 .", "v": "Tom will not rent an apartment in the Olive Garden that the security deposit is Tom .", "w": "Toms cat is a more than $ 1500 .", "x": "Tom will not rent an apartment in the Olive Garden that the security deposit is Toms cat .", "y": "the security deposit is a more than $ 1500 .", "z": "Tom will not rent an apartment in the Olive Garden that the security deposit is the security deposit .", "A": "Fluffy is a more than $ 1500 .", "B": "Tom will not rent an apartment in the Olive Garden that the security deposit is Fluffy ."}, {"0": "2000 $ is more than $ 1500 .", "1": "The security deposit at the Olive Garden is either $ 2000 or more ."}], "errors": [[]], "entailments_dict": [{"2": ["0"]}, {"3": ["0", "2"]}, {"n": ["3"], "1": ["3"], "3": ["q", "m"], "d": ["o", "x"], "s": ["8", "(¬j)"], "u": ["a"], "y": ["e", "(¬d)", "(¬p)"], "w": ["c"], "A": ["g"], "9": ["t"], "p": ["(¬b)", "(¬f)", "(¬9)"], "(¬x)": ["3", "m", "o"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [false, false, false, true]}
{"text": "If animals are loved by tourists, then they are Max's favorite animals. All animals from Australia are loved by tourists. All quokka are animals from Australia. All of Max's favorite animals are very fluffy. All of Max's favorite animals love to sleep. If a koala is very fluffy, then the koala is not a quokka.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Koalas love to sleep?", "id": "96", "ground_truth": "Uncertain", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: If animals are loved by tourists, then they are Max's favorite animals.\nPremise 1.2: All animals from Australia are loved by tourists.\nPremise 1.3: All quokka are animals from Australia.\nPremise 2.1: All of Max's favorite animals are very fluffy.\nPremise 2.2: All of Max's favorite animals love to sleep.\nPremise 3.1: If a koala is very fluffy, then the koala is not a quokka.\n\nConclusion 1: All quokka are very fluffy. (From Premise 1.3 and Premise 2.1)\nConclusion 2: All quokka love to sleep. (From Premise 1.3 and Premise 2.2)\nConclusion 3: If a koala is very fluffy, then it is not a quokka. (From Premise 3.1)\nConclusion 4: Koalas are not quokka. (From Conclusion 3 and Premise 1.2)\nConclusion 5: It is uncertain whether koalas love to sleep. (From Conclusion 4 and Premise 2.2)\n\nTherefore, the answer is C. Uncertain.", "logic_premises": "[[(0→1), ((f→g)∪((h→i)∪(j→k))), ((l→m)∪((n→o)∪(p→q))), ((r→s)∪((t→u)∪(v→w))), ((x→y)∪((z→A)∪(B→C))), (((D∧E)→F)∪(((G∧H)→I)∪((J∧K)→L)))]]", "logic_conclusion": "[((M→N)∪((O→P)∪(Q→R)))]", "correspondance": [{"0": "animals are loved by tourists .", "1": "animals are Max 's 's favorite animals .", "2": "X is an animal from Australia .", "3": "X is loved by tourists .", "4": "X is a quokka .", "5": "X is an animal from Australia .", "6": "X is of a Max 's 's favorite animals .", "7": "X is very fluffy .", "8": "X is of a Max 's 's favorite animals .", "9": "X loves to sleeps .", "a": "X is a koala", "b": "X is very fluffy .", "c": "X is not a quokka .", "d": "X is a quokka .", "e": "X is very fluffy . .", "f": "Maxs favorite animals is an animal from Australia .", "g": "Maxs favorite animals is loved by tourists .", "h": "the koala is an animal from Australia .", "i": "the koala is loved by tourists .", "j": "Australia is an animal from Australia .", "k": "Australia is loved by tourists .", "l": "Maxs favorite animals is a quokka .", "m": "Maxs favorite animals is an animal from Australia .", "n": "the koala is a quokka .", "o": "the koala is an animal from Australia .", "p": "Australia is a quokka .", "q": "Australia is an animal from Australia .", "r": "Maxs favorite animals is of a Max 's 's favorite animals .", "s": "Maxs favorite animals is very fluffy .", "t": "the koala is of a Max 's 's favorite animals .", "u": "the koala is very fluffy .", "v": "Australia is of a Max 's 's favorite animals .", "w": "Australia is very fluffy .", "x": "Maxs favorite animals is of a Max 's 's favorite animals .", "y": "Maxs favorite animals loves to sleeps .", "z": "the koala is of a Max 's 's favorite animals .", "A": "the koala loves to sleeps .", "B": "Australia is of a Max 's 's favorite animals .", "C": "Australia loves to sleeps .", "D": "Maxs favorite animals is a koala", "E": "Maxs favorite animals is very fluffy .", "F": "Maxs favorite animals is not a quokka .", "G": "the koala is a koala", "H": "the koala is very fluffy .", "I": "the koala is not a quokka .", "J": "Australia is a koala", "K": "Australia is very fluffy .", "L": "Australia is not a quokka .", "M": "Maxs favorite animals is a quokka .", "N": "Maxs favorite animals is very fluffy . .", "O": "the koala is a quokka .", "P": "the koala is very fluffy . .", "Q": "Australia is a quokka .", "R": "Australia is very fluffy . ."}], "errors": [[]], "entailments_dict": [{"m": ["t", "f", "D", "h", "z"], "q": ["j", "(¬L)"], "1": ["D", "z", "r", "t", "x"], "o": ["G", "h"], "u": ["H", "G", "P"], "i": ["G", "0"], "I": ["h"], "w": ["K", "R"], "s": ["E", "N"], "M": ["f", "l", "t", "r", "z", "x", "(¬F)", "(¬I)"], "O": ["h", "n", "(¬L)", "(¬I)"], "Q": ["p", "(¬k)", "(¬q)", "(¬u)", "(¬w)", "(¬A)", "(¬C)", "(¬L)", "(¬I)"]}], "predicted_steps": ["Contradiction in the premises"]}
{"text": "If animals are loved by tourists, then they are Max's favorite animals. All animals from Australia are loved by tourists. All quokka are animals from Australia. All of Max's favorite animals are very fluffy. All of Max's favorite animals love to sleep. If a koala is very fluffy, then the koala is not a quokka.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Koalas love to sleep and are quokka?", "id": "97", "ground_truth": "False", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: If animals are loved by tourists, then they are Max's favorite animals.\nPremise 1.2: All animals from Australia are loved by tourists.\nPremise 1.3: All quokka are animals from Australia.\nPremise 2.1: All of Max's favorite animals are very fluffy.\nPremise 2.2: All of Max's favorite animals love to sleep.\nPremise 3.1: If a koala is very fluffy, then the koala is not a quokka.\n\nConclusion 1: All quokka are very fluffy. (From Premise 1.3 and Premise 2.1)\nConclusion 2: All quokka love to sleep. (From Premise 1.3 and Premise 2.2)\nConclusion 3: If a koala is very fluffy, then the koala is not a quokka. (From Premise 3.1)\n\nNow, let's evaluate the options:\n\nA. Yes: This option states that koalas love to sleep and are quokka. However, we have concluded that if a koala is very fluffy, then it is not a quokka. Therefore, this option is false.\n\nB. No: This option states that koalas do not love to sleep or are not quokka. We have concluded that all quokka love to sleep and are very fluffy. Therefore, this option is true.\n\nC. Uncertain: This option states that it is uncertain whether koalas love to sleep and are quokka. However, we have concluded that all quokka love to sleep and are very fluffy, and that if a koala is very fluffy, then it is not a quokka. Therefore, this option is false.\n\nAnswer: B. No", "logic_premises": "[[(0→1), ((f→g)∪((h→i)∪(j→k))), ((l→m)∪((n→o)∪(p→q))), ((r→s)∪((t→u)∪(v→w))), ((x→y)∪((z→A)∪(B→C))), (((D∧E)→F)∪(((G∧H)→I)∪((J∧K)→L)))]]", "logic_conclusion": "[((M→N)∪((O→P)∪(Q→R)))]", "correspondance": [{"0": "animals are loved by tourists .", "1": "animals are Max 's 's favorite animals .", "2": "X is an animal from Australia .", "3": "X is loved by tourists .", "4": "X is a quokka .", "5": "X is an animal from Australia .", "6": "X is of a Max 's 's favorite animals .", "7": "X is very fluffy .", "8": "X is of a Max 's 's favorite animals .", "9": "X loves to sleeps .", "a": "X is a koala", "b": "X is very fluffy .", "c": "X is not a quokka .", "d": "X is a quokka .", "e": "X is very fluffy . .", "f": "Maxs favorite animals is an animal from Australia .", "g": "Maxs favorite animals is loved by tourists .", "h": "the koala is an animal from Australia .", "i": "the koala is loved by tourists .", "j": "Australia is an animal from Australia .", "k": "Australia is loved by tourists .", "l": "Maxs favorite animals is a quokka .", "m": "Maxs favorite animals is an animal from Australia .", "n": "the koala is a quokka .", "o": "the koala is an animal from Australia .", "p": "Australia is a quokka .", "q": "Australia is an animal from Australia .", "r": "Maxs favorite animals is of a Max 's 's favorite animals .", "s": "Maxs favorite animals is very fluffy .", "t": "the koala is of a Max 's 's favorite animals .", "u": "the koala is very fluffy .", "v": "Australia is of a Max 's 's favorite animals .", "w": "Australia is very fluffy .", "x": "Maxs favorite animals is of a Max 's 's favorite animals .", "y": "Maxs favorite animals loves to sleeps .", "z": "the koala is of a Max 's 's favorite animals .", "A": "the koala loves to sleeps .", "B": "Australia is of a Max 's 's favorite animals .", "C": "Australia loves to sleeps .", "D": "Maxs favorite animals is a koala", "E": "Maxs favorite animals is very fluffy .", "F": "Maxs favorite animals is not a quokka .", "G": "the koala is a koala", "H": "the koala is very fluffy .", "I": "the koala is not a quokka .", "J": "Australia is a koala", "K": "Australia is very fluffy .", "L": "Australia is not a quokka .", "M": "Maxs favorite animals is a quokka .", "N": "Maxs favorite animals is very fluffy . .", "O": "the koala is a quokka .", "P": "the koala is very fluffy . .", "Q": "Australia is a quokka .", "R": "Australia is very fluffy . ."}], "errors": [[]], "entailments_dict": [{"m": ["t", "f", "D", "h", "z"], "q": ["j", "(¬L)"], "1": ["D", "z", "r", "t", "x"], "o": ["G", "h"], "u": ["H", "G", "P"], "i": ["G", "0"], "I": ["h"], "w": ["K", "R"], "s": ["E", "N"], "M": ["f", "l", "t", "r", "z", "x", "(¬F)", "(¬I)"], "O": ["h", "n", "(¬L)", "(¬I)"], "Q": ["p", "(¬k)", "(¬q)", "(¬u)", "(¬w)", "(¬A)", "(¬C)", "(¬L)", "(¬I)"]}], "predicted_steps": ["Contradiction in the premises"]}
{"text": "If animals are loved by tourists, then they are Max's favorite animals. All animals from Australia are loved by tourists. All quokka are animals from Australia. All of Max's favorite animals are very fluffy. All of Max's favorite animals love to sleep. If a koala is very fluffy, then the koala is not a quokka.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If a koala is a quokka, then the koala either loves to sleep or is very fluffy?", "id": "98", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If animals are loved by tourists, then they are Max's favorite animals.\nPremise 1.2: All animals from Australia are loved by tourists.\nPremise 1.3: All quokka are animals from Australia.\nPremise 2.1: All of Max's favorite animals are very fluffy.\nPremise 2.2: All of Max's favorite animals love to sleep.\nPremise 3.1: If a koala is very fluffy, then the koala is not a quokka.\n\nConclusion 1: All quokka are very fluffy. (From Premise 1.3 and Premise 2.1)\nConclusion 2: All quokka love to sleep. (From Premise 1.3 and Premise 2.2)\nConclusion 3: If a koala is very fluffy, then the koala is not a quokka. (From Premise 3.1)\nConclusion 4: If a koala is a quokka, then the koala either loves to sleep or is very fluffy. (From Conclusion 2 and Conclusion 3)\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), ((f→g)∪((h→i)∪(j→k))), ((l→m)∪((n→o)∪(p→q))), ((r→s)∪((t→u)∪(v→w))), ((x→y)∪((z→A)∪(B→C))), (((D∧E)→F)∪(((G∧H)→I)∪((J∧K)→L)))]]", "logic_conclusion": "[((M→N)∪((O→P)∪(Q→R)))]", "correspondance": [{"0": "animals are loved by tourists .", "1": "animals are Max 's 's favorite animals .", "2": "X is an animal from Australia .", "3": "X is loved by tourists .", "4": "X is a quokka .", "5": "X is an animal from Australia .", "6": "X is of a Max 's 's favorite animals .", "7": "X is very fluffy .", "8": "X is of a Max 's 's favorite animals .", "9": "X loves to sleeps .", "a": "X is a koala", "b": "X is very fluffy .", "c": "X is not a quokka .", "d": "X is a quokka .", "e": "X is very fluffy . .", "f": "Maxs favorite animals is an animal from Australia .", "g": "Maxs favorite animals is loved by tourists .", "h": "the koala is an animal from Australia .", "i": "the koala is loved by tourists .", "j": "Australia is an animal from Australia .", "k": "Australia is loved by tourists .", "l": "Maxs favorite animals is a quokka .", "m": "Maxs favorite animals is an animal from Australia .", "n": "the koala is a quokka .", "o": "the koala is an animal from Australia .", "p": "Australia is a quokka .", "q": "Australia is an animal from Australia .", "r": "Maxs favorite animals is of a Max 's 's favorite animals .", "s": "Maxs favorite animals is very fluffy .", "t": "the koala is of a Max 's 's favorite animals .", "u": "the koala is very fluffy .", "v": "Australia is of a Max 's 's favorite animals .", "w": "Australia is very fluffy .", "x": "Maxs favorite animals is of a Max 's 's favorite animals .", "y": "Maxs favorite animals loves to sleeps .", "z": "the koala is of a Max 's 's favorite animals .", "A": "the koala loves to sleeps .", "B": "Australia is of a Max 's 's favorite animals .", "C": "Australia loves to sleeps .", "D": "Maxs favorite animals is a koala", "E": "Maxs favorite animals is very fluffy .", "F": "Maxs favorite animals is not a quokka .", "G": "the koala is a koala", "H": "the koala is very fluffy .", "I": "the koala is not a quokka .", "J": "Australia is a koala", "K": "Australia is very fluffy .", "L": "Australia is not a quokka .", "M": "Maxs favorite animals is a quokka .", "N": "Maxs favorite animals is very fluffy . .", "O": "the koala is a quokka .", "P": "the koala is very fluffy . .", "Q": "Australia is a quokka .", "R": "Australia is very fluffy . ."}], "errors": [[]], "entailments_dict": [{"m": ["t", "f", "D", "h", "z"], "q": ["j", "(¬L)"], "1": ["D", "z", "r", "t", "x"], "o": ["G", "h"], "u": ["H", "G", "P"], "i": ["G", "0"], "I": ["h"], "w": ["K", "R"], "s": ["E", "N"], "M": ["f", "l", "t", "r", "z", "x", "(¬F)", "(¬I)"], "O": ["h", "n", "(¬L)", "(¬I)"], "Q": ["p", "(¬k)", "(¬q)", "(¬u)", "(¬w)", "(¬A)", "(¬C)", "(¬L)", "(¬I)"]}], "predicted_steps": ["Contradiction in the premises"]}
{"text": "A man is either kind or evil. No ugly person is handsome. All evil people are ugly. All gentlemen are handsome. All CEOs are gentlemen. Harry is a gentleman.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is a CEO?", "id": "99", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: A man is either kind or evil.\nPremise 1.2: No ugly person is handsome.\nPremise 1.3: All evil people are ugly.\nPremise 1.4: All gentlemen are handsome.\nPremise 1.5: All CEOs are gentlemen.\nPremise 1.6: Harry is a gentleman.\n\nConclusion 1: Harry is handsome. (Follows from 1.1, 1.2, and 1.4)\n\nConclusion 2: Harry is not evil. (Follows from 1.1 and 1.3)\n\nConclusion 3: Harry is a CEO. (Follows from 1.5 and 1.6)\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0⊻1), (c→d), (e→f), (g→h), (i→j), a]]", "logic_conclusion": "[b]", "correspondance": [{"0": "A man is kind .", "1": "A man is evil .", "2": "X is an ugly person .", "3": "X is not handsome .", "4": "X is an evil person .", "5": "X is ugly .", "6": "X is a gentleman .", "7": "X is handsome .", "8": "X is a CEO .", "9": "X is a gentleman .", "a": "Harry is a gentleman .", "b": "Harry is handsome . .", "c": "Harry is an ugly person .", "d": "Harry is not handsome .", "e": "Harry is an evil person .", "f": "Harry is ugly .", "g": "Harry is a gentleman .", "h": "Harry is handsome .", "i": "Harry is a CEO .", "j": "Harry is a gentleman ."}], "errors": [[]], "entailments_dict": [{"j": ["g", "a"], "f": ["c", "(¬h)", "(¬j)", "(¬a)"], "a": ["g"], "h": ["b", "(¬d)", "(¬f)"], "d": ["(¬h)"], "b": ["(¬d)", "(¬f)"], "0": ["(¬1)"], "(¬b)": ["c"]}], "predicted_steps": [true]}
{"text": "A man is either kind or evil. No ugly person is handsome. All evil people are ugly. All gentlemen are handsome. All CEOs are gentlemen. Harry is a gentleman.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is kind or a CEO?", "id": "100", "ground_truth": "True", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: A man is either kind or evil.\nPremise 1.2: No ugly person is handsome.\nPremise 1.3: All evil people are ugly.\nPremise 1.4: All gentlemen are handsome.\nPremise 1.5: All CEOs are gentlemen.\nPremise 1.6: Harry is a gentleman.\n\nConclusion 1: Harry is handsome.\n\nPremise 2.1: All evil people are ugly.\nPremise 2.2: Harry is handsome.\nConclusion 2: Harry is not evil.\n\nPremise 3.1: A man is either kind or evil.\nPremise 3.2: Harry is not evil.\nConclusion 3: Harry is kind.\n\nPremise 4.1: All CEOs are gentlemen.\nPremise 4.2: Harry is a gentleman.\nConclusion 4: Harry is a CEO.\n\nConclusion 5: Harry is both kind and a CEO.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0⊻1), (c→d), (e→f), (g→h), (i→j), a], [(4→5), 2], [(0⊻1), 2], [(4→5), 2]]", "logic_conclusion": "[b, 3, 3, 3]", "correspondance": [{"0": "A man is kind .", "1": "A man is evil .", "2": "X is an ugly person .", "3": "X is not handsome .", "4": "X is an evil person .", "5": "X is ugly .", "6": "X is a gentleman .", "7": "X is handsome .", "8": "X is a CEO .", "9": "X is a gentleman .", "a": "Harry is a gentleman .", "b": "Harry is handsome .", "c": "Harry is an ugly person .", "d": "Harry is not handsome .", "e": "Harry is an evil person .", "f": "Harry is ugly .", "g": "Harry is a gentleman .", "h": "Harry is handsome .", "i": "Harry is a CEO .", "j": "Harry is a gentleman ."}, {"0": "X is an evil person .", "1": "X is ugly .", "2": "Harry is handsome .", "3": "Harry is not evil .", "4": "Harry is an evil person .", "5": "Harry is ugly ."}, {"0": "A man is kind .", "1": "A man is evil .", "2": "Harry is not evil .", "3": "Harry is kind ."}, {"0": "X is a CEO .", "1": "X is a gentleman .", "2": "Harry is a gentleman .", "3": "Harry is a CEO .", "4": "Harry is a CEO .", "5": "Harry is a gentleman ."}], "errors": [[]], "entailments_dict": [{"j": ["g", "a"], "f": ["c", "(¬h)", "(¬j)", "(¬a)"], "a": ["g"], "h": ["b", "(¬d)", "(¬f)"], "d": ["(¬h)"], "b": ["(¬d)", "(¬f)"], "0": ["(¬1)"], "(¬b)": ["c"]}, {"5": ["(¬2)"], "2": ["(¬5)"], "(¬3)": ["4"]}, {"3": ["2"], "2": ["3"], "1": ["(¬2)"], "0": ["(¬1)"], "(¬1)": ["2"]}, {"5": ["2"], "3": ["4"]}], "predicted_steps": [true, true, true, false]}
{"text": "A man is either kind or evil. No ugly person is handsome. All evil people are ugly. All gentlemen are handsome. All CEOs are gentlemen. Harry is a gentleman.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Harry is either both evil and ugly, or neither evil nor ugly, then Harry is neither kind nor a CEO?", "id": "101", "ground_truth": "False", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: A man is either kind or evil.\nPremise 1.2: No ugly person is handsome.\nPremise 1.3: All evil people are ugly.\nPremise 1.4: All gentlemen are handsome.\nPremise 1.5: All CEOs are gentlemen.\nPremise 1.6: Harry is a gentleman.\n\nConclusion 1: Harry is either kind or evil. (From Premise 1.1)\n\nConclusion 2: Harry is not ugly. (From Premise 1.2 and Premise 1.6)\n\nConclusion 3: Harry is not evil. (From Premise 1.3 and Conclusion 2)\n\nConclusion 4: Harry is handsome. (From Premise 1.4 and Conclusion 3)\n\nConclusion 5: Harry is a CEO. (From Premise 1.5 and Conclusion 4)\n\nConclusion 6: Harry is neither kind nor a CEO. (From Premise 1.1 and Conclusion 5)\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0⊻1), (d→e), (f→g), (h→i), (j→k), a]]", "logic_conclusion": "[(b⊻c)]", "correspondance": [{"0": "A man is kind .", "1": "A man is evil .", "2": "X is an ugly person .", "3": "X is not handsome .", "4": "X is an evil person .", "5": "X is ugly .", "6": "X is a gentleman .", "7": "X is handsome .", "8": "X is a CEO .", "9": "X is a gentleman .", "a": "Harry is a gentleman .", "b": "Harry is kind . .", "c": "Harry is evil . .", "d": "Harry is an ugly person .", "e": "Harry is not handsome .", "f": "Harry is an evil person .", "g": "Harry is ugly .", "h": "Harry is a gentleman .", "i": "Harry is handsome .", "j": "Harry is a CEO .", "k": "Harry is a gentleman ."}], "errors": [[]], "entailments_dict": [{"k": ["a", "h"], "a": ["h"], "g": ["d", "(¬a)", "(¬i)", "(¬k)"], "c": ["f", "(¬k)", "(¬a)"], "e": ["(¬i)"], "i": ["(¬e)", "(¬g)"], "0": ["(¬1)"]}], "predicted_steps": [false]}
{"text": "If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings. If people have siblings who are the same age, then they are twins or triplets. If people complain often about annoying siblings, then they have siblings who are the same age. If people do not live at home regularly, then they do not develop strong bonds with their family members. If people spend a lot of time hanging out with and playing with their siblings, then they often did not live at home regularly. Luke is either both a twin or triplet and develops strong bonds with his family members, or he neither is a twin or triplet nor develops strong bonds with his family members.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Luke spends a lot of time hanging out and playing with his siblings?", "id": "102", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings.\nPremise 1.2: If people have siblings who are the same age, then they are twins or triplets.\nConclusion 1: If Luke is a twin or triplet, then he spends a lot of time hanging out with and playing with his siblings.\n\nPremise 2.1: If people complain often about annoying siblings, then they have siblings who are the same age.\nPremise 2.2: Luke does not complain often about annoying siblings.\nConclusion 2: Luke does not have siblings who are the same age.\n\nPremise 3.1: If people do not live at home regularly, then they do not develop strong bonds with their family members.\nPremise 3.2: Luke does not live at home regularly.\nConclusion 3: Luke does not develop strong bonds with his family members.\n\nPremise 4.1: If people spend a lot of time hanging out with and playing with their siblings, then they often did not live at home regularly.\nPremise 4.2: Luke does not spend a lot of time hanging out with and playing with his siblings.\nConclusion 4: Luke does live at home regularly.\n\nConclusion 5: Since Luke does not have siblings who are the same age and does not spend a lot of time hanging out with and playing with his siblings, it is uncertain whether he spends a lot of time hanging out and playing with his siblings.\n\nTherefore, the answer is C. Uncertain.", "logic_premises": "[[(((9∨a)→b)∪((c∨d)→e)), ((f→(g∨h))∪(i→(j∨k)))], [((4→5)∪(6→7)), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[((6∨7)→8), 3, 3, 3]", "correspondance": [{"0": "X are twins .", "1": "X are triplets .", "2": "X spend a lot of time hanging out with and playing with X 's siblings .", "3": "X have siblings who are the same age .", "4": "X are twins .", "5": "X are triplets .", "6": "Luke is a twin .", "7": "Luke is a triplet .", "8": "Luke spends a lot of time hanging out with and playing with Luke 's siblings .", "9": "the same age are twins .", "a": "the same age are triplets .", "b": "the same age spend a lot of time hanging out with and playing with the same age 's siblings .", "c": "Luke are twins .", "d": "Luke are triplets .", "e": "Luke spend a lot of time hanging out with and playing with Luke 's siblings .", "f": "the same age have siblings who are the same age .", "g": "the same age are twins .", "h": "the same age are triplets .", "i": "Luke have siblings who are the same age .", "j": "Luke are twins .", "k": "Luke are triplets ."}, {"0": "X complain often about annoying siblings .", "1": "X have siblings who are the same age .", "2": "Luke does not complain often about annoying siblings .", "3": "Luke does not have siblings who are the same age .", "4": "the same age complain often about annoying siblings .", "5": "the same age have siblings who are the same age .", "6": "Luke complain often about annoying siblings .", "7": "Luke have siblings who are the same age ."}, {"0": "X do not live at home regularly .", "1": "X do not develop strong bonds with X 's family members .", "2": "Luke does not live at home regularly .", "3": "Luke does not develop strong bonds with Luke 's family members .", "4": "Luke do not live at home regularly .", "5": "Luke do not develop strong bonds with Luke 's family members ."}, {"0": "X spend a lot of time hanging out with and playing with people 's siblings .", "1": "X often did not live at home regularly .", "2": "Luke does not spend a lot of time hanging out with and playing with Luke 's siblings .", "3": "Luke does live at home regularly .", "4": "Luke spend a lot of time hanging out with and playing with people 's siblings .", "5": "Luke often did not live at home regularly ."}], "errors": [[]], "entailments_dict": [{"k": ["a", "d", "8"], "g": ["9", "c", "8"], "h": ["d", "a", "8"], "j": ["c", "9", "8"], "b": ["f", "8"], "7": ["d", "a", "f", "i", "(¬j)"], "6": ["9", "c", "f", "i", "(¬k)"], "e": ["8"]}, {"3": ["(¬7)", "(¬5)"], "(¬2)": ["6"], "(¬6)": ["2"]}, {"2": ["4"], "5": ["3"]}, {"3": ["(¬5)"], "(¬4)": ["2"]}], "predicted_steps": [true, false, true, false]}
{"text": "If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings. If people have siblings who are the same age, then they are twins or triplets. If people complain often about annoying siblings, then they have siblings who are the same age. If people do not live at home regularly, then they do not develop strong bonds with their family members. If people spend a lot of time hanging out with and playing with their siblings, then they often did not live at home regularly. Luke is either both a twin or triplet and develops strong bonds with his family members, or he neither is a twin or triplet nor develops strong bonds with his family members.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Luke complains often about annoying siblings?", "id": "103", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings.\nPremise 1.2: If people have siblings who are the same age, then they are twins or triplets.\nConclusion 1: If Luke is a twin or triplet, then he spends a lot of time hanging out with and playing with his siblings.\n\nPremise 2.1: If people complain often about annoying siblings, then they have siblings who are the same age.\nPremise 2.2: If Luke complains often about annoying siblings, then he has siblings who are the same age.\nConclusion 2: If Luke complains often about annoying siblings, then he is a twin or triplet.\n\nPremise 3.1: If people do not live at home regularly, then they do not develop strong bonds with their family members.\nPremise 3.2: If Luke does not live at home regularly, then he does not develop strong bonds with his family members.\nConclusion 3: If Luke does not live at home regularly, then he does not develop strong bonds with his family members.\n\nPremise 4.1: If Luke is a twin or triplet, then he spends a lot of time hanging out with and playing with his siblings.\nPremise 4.2: If Luke does not live at home regularly, then he does not develop strong bonds with his family members.\nConclusion 4: If Luke is a twin or triplet and does not live at home regularly, then he does not develop strong bonds with his family members.\n\nPremise 5.1: Luke is either a twin or triplet and develops strong bonds with his family members, or he neither is a twin or triplet nor develops strong bonds with his family members.\nConclusion 5: Therefore, it is uncertain whether Luke complains often about annoying siblings.\n\nAnswer: C. Uncertain", "logic_premises": "[[(((9∨a)→b)∪((c∨d)→e)), ((f→(g∨h))∪(i→(j∨k)))], [((7→8)∪(9→a)), (2→3)], [(6→7), (2→3)], [((0∨1)→2), (3→4)], [((0∧1)⊻(2∧3))]]", "logic_conclusion": "[((6∨7)→8), (4→(5∨6)), (4→5), ((5∧6)→7), 4]", "correspondance": [{"0": "X are twins .", "1": "X are triplets .", "2": "X spend a lot of time hanging out with and playing with X 's siblings .", "3": "X have siblings who are the same age .", "4": "X are twins .", "5": "X are triplets .", "6": "Luke is a twin .", "7": "Luke is a triplet .", "8": "Luke spends a lot of time hanging out with and playing with Luke 's siblings .", "9": "the same age are twins .", "a": "the same age are triplets .", "b": "the same age spend a lot of time hanging out with and playing with the same age 's siblings .", "c": "Luke are twins .", "d": "Luke are triplets .", "e": "Luke spend a lot of time hanging out with and playing with Luke 's siblings .", "f": "the same age have siblings who are the same age .", "g": "the same age are twins .", "h": "the same age are triplets .", "i": "Luke have siblings who are the same age .", "j": "Luke are twins .", "k": "Luke are triplets ."}, {"0": "X complain often about annoying siblings .", "1": "X have siblings who are the same age .", "2": "Luke complains often about annoying siblings .", "3": "Luke has siblings who are the same age .", "4": "Luke complains often about annoying siblings .", "5": "Luke is a twin .", "6": "Luke is a triplet .", "7": "the same age complain often about annoying siblings .", "8": "the same age have siblings who are the same age .", "9": "Luke complain often about annoying siblings .", "a": "Luke have siblings who are the same age ."}, {"0": "X do not live at home regularly .", "1": "X do not develop strong bonds with X 's family members .", "2": "Luke does not live at home regularly .", "3": "Luke does not develop strong bonds with Luke 's family members .", "4": "Luke does not live at home regularly .", "5": "Luke does not develop strong bonds with Luke 's family members .", "6": "Luke do not live at home regularly .", "7": "Luke do not develop strong bonds with Luke 's family members ."}, {"0": "Luke is a twin .", "1": "Luke is a triplet .", "2": "Luke spends a lot of time hanging out with and playing with Luke 's siblings .", "3": "Luke does not live at home regularly .", "4": "Luke does not develop strong bonds with Luke 's family members .", "5": "Luke is a twin or triplet .", "6": "Luke does not live at home regularly .", "7": "Luke does not develop strong bonds with Luke 's family members ."}, {"0": "Luke is a twin or triplet .", "1": "Luke develops strong bonds with Luke 's family members .", "2": "Luke is not a twin or triplet .", "3": "Luke does not develop strong bonds with Luke 's family members .", "4": "Therefore , it is uncertain that Luke complains often about annoying siblings ."}], "errors": [[]], "entailments_dict": [{"k": ["a", "d", "8"], "g": ["9", "c", "8"], "h": ["d", "a", "8"], "j": ["c", "9", "8"], "b": ["f", "8"], "7": ["d", "a", "f", "i", "(¬j)"], "6": ["9", "c", "f", "i", "(¬k)"], "e": ["8"]}, {"4": ["9", "2"], "8": ["6"]}, {"4": ["6", "2"], "7": ["5"], "3": ["5"]}, {"6": ["3"], "5": ["1", "0"], "4": ["7", "(¬2)"]}, {"0": ["(¬2)"], "1": ["(¬3)"]}], "predicted_steps": [true, false, true, true, false]}
{"text": "If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings. If people have siblings who are the same age, then they are twins or triplets. If people complain often about annoying siblings, then they have siblings who are the same age. If people do not live at home regularly, then they do not develop strong bonds with their family members. If people spend a lot of time hanging out with and playing with their siblings, then they often did not live at home regularly. Luke is either both a twin or triplet and develops strong bonds with his family members, or he neither is a twin or triplet nor develops strong bonds with his family members.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Luke is neither a twin nor triplet nor complains often about annoying siblings?", "id": "104", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If people are twins or triplets, then they spend a lot of time hanging out with and playing with their siblings.\nPremise 1.2: If people have siblings who are the same age, then they are twins or triplets.\nConclusion 1: If people spend a lot of time hanging out with and playing with their siblings, then they have siblings who are the same age.\n\nPremise 2.1: If people complain often about annoying siblings, then they have siblings who are the same age.\nPremise 2.2: If people do not live at home regularly, then they do not develop strong bonds with their family members.\nConclusion 2: If people complain often about annoying siblings, then they do not live at home regularly.\n\nPremise 3.1: Luke is either both a twin or triplet and develops strong bonds with his family members, or he neither is a twin or triplet nor develops strong bonds with his family members.\nConclusion 3: Luke is either a twin or triplet and does not live at home regularly, or he does not develop strong bonds with his family members.\n\nPremise 4.1: If Luke is a twin or triplet, then he spends a lot of time hanging out with and playing with his siblings.\nPremise 4.2: If Luke does not live at home regularly, then he does not develop strong bonds with his family members.\nConclusion 4: If Luke is a twin or triplet, then he does not develop strong bonds with his family members.\n\nPremise 5.1: Luke is neither a twin nor triplet nor complains often about annoying siblings.\nConclusion 5: Luke does not develop strong bonds with his family members.\n\nTherefore, the answer is B. No. It is not true that Luke is neither a twin nor triplet nor complains often about annoying siblings.", "logic_premises": "[[((0∨1)→2), (3→(4∨5))], [(0→1), (2→3)], [((0∧1)⊻(2∧3))], [((0∨1)→2), (3→4)], [((0∧1)∧2)]]", "logic_conclusion": "[(6→7), (4→5), ((4∧5)⊻6), ((5∨6)→7), 3]", "correspondance": [{"0": "X are twins .", "1": "X are triplets .", "2": "X spend a lot of time hanging out with and playing with X 's siblings .", "3": "X have siblings who are the same age .", "4": "X are twins .", "5": "X are triplets .", "6": "X spend a lot of time hanging out with and playing with people 's siblings .", "7": "X have siblings who are the same age ."}, {"0": "X complain often about annoying siblings .", "1": "X have siblings who are the same age .", "2": "X do not live at home regularly .", "3": "X do not develop strong bonds with X 's family members .", "4": "X complain often about annoying siblings .", "5": "X do not live at home regularly ."}, {"0": "Luke is a twin or triplet .", "1": "Luke develops strong bonds with Luke 's family members .", "2": "Luke is not a twin or triplet .", "3": "Luke does not develop strong bonds with Luke 's family members .", "4": "Luke is a twin or triplet .", "5": "Luke does not live at home regularly .", "6": "Luke does not develop strong bonds with Luke 's family members ."}, {"0": "Luke is a twin .", "1": "Luke is a triplet .", "2": "Luke spends a lot of time hanging out with and playing with Luke 's siblings .", "3": "Luke does not live at home regularly .", "4": "Luke does not develop strong bonds with Luke 's family members .", "5": "Luke is a twin .", "6": "Luke is a triplet .", "7": "Luke does not develop strong bonds with Luke 's family members ."}, {"0": "Luke is not a twin .", "1": "Luke is not a triplet .", "2": "Luke does not complain often about annoying siblings .", "3": "Luke does not develop strong bonds with Luke 's family members ."}], "errors": [[]], "entailments_dict": [{"5": ["1", "7"], "4": ["0", "7"]}, {"4": ["0"]}, {"4": ["0", "(¬2)"], "6": ["3", "(¬1)"], "3": ["6"], "0": ["4", "(¬2)"], "1": ["(¬3)"], "(¬4)": ["2"], "(¬6)": ["1"]}, {"6": ["1"], "5": ["0"], "4": ["7", "(¬2)"]}, {}], "predicted_steps": [false, false, false, false, false]}
{"text": "It costs US $205 to take the GRE test. ETS provides financial aid to those GRE applicants who prove economic hardship. Economic hardship refers to difficulty caused by having too little money or too few resources. Tom lives in a single-parent family. His dad has been out of work for more than a year.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Tom can apply for financial aid from ETS to take the GRE test?", "id": "105", "ground_truth": "True", "reasoning": " Premise 1: ETS provides financial aid to those GRE applicants who prove economic hardship.\nPremise 2: Economic hardship refers to difficulty caused by having too little money or too few resources.\nPremise 3: Tom lives in a single-parent family.\nPremise 4: Tom's dad has been out of work for more than a year.\nConclusion 1: Tom's family is experiencing economic hardship.\nPremise 5: Tom can apply for financial aid from ETS to take the GRE test if his family is experiencing economic hardship.\nConclusion 2: Tom can apply for financial aid from ETS to take the GRE test.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, (1∨2), 3, 4], [0]]", "logic_conclusion": "[5, (1∧2)]", "correspondance": [{"0": "ETS provides financial aid to those GRE applicants who prove economic hardship .", "1": "Economic hardship refers to difficulty caused by having too little money .", "2": "Economic hardship refers to difficulty caused by having too few resources .", "3": "Tom lives in a single - parent family .", "4": "Tom 's dad has been out of work for more than a year .", "5": "Tom 's family is experiencing economic hardship ."}, {"0": "Tom can apply for financial aid from ETS to take the GRE test that Tom 's family is experiencing economic hardship .", "1": "take the GRE test .", "2": "Tom can apply for financial aid from ETS ."}], "errors": [[]], "entailments_dict": [{"4": ["5"]}, {"1": ["0"], "2": ["0"], "0": ["1", "2"]}], "predicted_steps": [true, true]}
{"text": "It costs US $205 to take the GRE test. ETS provides financial aid to those GRE applicants who prove economic hardship. Economic hardship refers to difficulty caused by having too little money or too few resources. Tom lives in a single-parent family. His dad has been out of work for more than a year.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that It cost below US $300 to take the GRE test?", "id": "106", "ground_truth": "True", "reasoning": " Premise 1: It costs US $205 to take the GRE test.\n\nPremise 2: ETS provides financial aid to those GRE applicants who prove economic hardship.\n\nPremise 3: Economic hardship refers to difficulty caused by having too little money or too few resources.\n\nPremise 4: Tom lives in a single-parent family.\n\nPremise 5: His dad has been out of work for more than a year.\n\nConclusion 1: Tom may have experienced economic hardship.\n\nConclusion 2: If Tom has experienced economic hardship, then he may be eligible for financial aid from ETS.\n\nConclusion 3: If Tom is eligible for financial aid, then it may cost less than US $300 for him to take the GRE test.\n\nConclusion 4: It is uncertain whether it cost below US $300 to take the GRE test.\n\nTherefore, the answer is C. Uncertain.", "logic_premises": "[[(0∧1), 2, (3∨4), 5, 6]]", "logic_conclusion": "[7]", "correspondance": [{"0": "take the GRE test .", "1": "It costs US $ 205 .", "2": "ETS provides financial aid to those GRE applicants who prove economic hardship .", "3": "Economic hardship refers to difficulty caused by having too little money .", "4": "Economic hardship refers to difficulty caused by having too few resources .", "5": "Tom lives in a single - parent family .", "6": "Tom 's dad has been out of work for more than a year .", "7": "Tom may have experienced economic hardship ."}], "errors": [[]], "entailments_dict": [{}], "predicted_steps": [false]}
{"text": "It costs US $205 to take the GRE test. ETS provides financial aid to those GRE applicants who prove economic hardship. Economic hardship refers to difficulty caused by having too little money or too few resources. Tom lives in a single-parent family. His dad has been out of work for more than a year.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that There is no financial aid available for the GRE test?", "id": "107", "ground_truth": "False", "reasoning": " Premise 1: ETS provides financial aid to those GRE applicants who prove economic hardship.\nPremise 2: Economic hardship refers to difficulty caused by having too little money or too few resources.\nPremise 3: Tom lives in a single-parent family.\nPremise 4: Tom's dad has been out of work for more than a year.\nConclusion 1: Tom's family is experiencing economic hardship.\nPremise 5: ETS provides financial aid to those who prove economic hardship.\nConclusion 2: Tom is eligible for financial aid for the GRE test.\nConclusion 3: There is financial aid available for the GRE test.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, (1∨2), 3, 4], [0]]", "logic_conclusion": "[5, 1]", "correspondance": [{"0": "ETS provides financial aid to those GRE applicants who prove economic hardship .", "1": "Economic hardship refers to difficulty caused by having too little money .", "2": "Economic hardship refers to difficulty caused by having too few resources .", "3": "Tom lives in a single - parent family .", "4": "Tom 's dad has been out of work for more than a year .", "5": "Tom 's family is experiencing economic hardship ."}, {"0": "ETS provides financial aid to those who prove economic hardship .", "1": "Tom is eligible for financial aid for the GRE test ."}], "errors": [[]], "entailments_dict": [{"4": ["5"]}, {}], "predicted_steps": [true, false]}
{"text": "If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning. All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing. If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning. If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings. All households with a high net income have people who have parents who are very busy with their regular jobs. Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Peter tidies his space consistently and enjoys the process of cleaning?", "id": "108", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning.\nPremise 1.2: All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.\nConclusion 1: All foodies who go out frequently to find new food restaurants to try do not tidy their spaces consistently and enjoy the process of cleaning.\n\nPremise 2.1: If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning.\nPremise 2.2: If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings.\nConclusion 2: If people have parents who are very busy with their regular jobs, then they tidy their spaces consistently and enjoy the process of cleaning.\n\nPremise 3.1: Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings.\nConclusion 3: Peter is either a person who tidies his space consistently and enjoys the process of cleaning, or he is not.\n\nConclusion 4: Therefore, it is uncertain whether Peter tidies his space consistently and enjoys the process of cleaning.\n\nAnswer: C. Uncertain", "logic_premises": "[[(0→(1∧2)), (3→4)], [(0→(1∧2)), (3→4)], [(((6→7)⊻(8→9))∪((a→b)⊻(c→d)))]]", "logic_conclusion": "[(5→(6∧7)), (5→(6∧7)), (4⊻5)]", "correspondance": [{"0": "X spill a lot of food on people 's clothing .", "1": "X do not tidy X 's spaces consistently .", "2": "X do not enjoy the process of cleaning .", "3": "X is a foody who goes out frequently to finds new food restaurants to tries .", "4": "X is a people who spills a lot of food on their clothing .", "5": "X is a foody who goes out frequently to finds new food restaurants to tries .", "6": "X does not tidies their spaces consistently .", "7": "X does not enjoys the process of cleaning ."}, {"0": "X grew up as only children with no siblings .", "1": "X tidy X 's spaces consistently .", "2": "X enjoy the process of cleaning .", "3": "X have parents who are very busy with their regular jobs .", "4": "X grew up as only children with no siblings .", "5": "X have parents who are very busy with their regular jobs .", "6": "X tidy X 's spaces consistently .", "7": "X enjoy the process of cleaning ."}, {"0": "X is both an a person who spills a lot of food on Peter 's clothing and grew up as an only child with a sibling .", "1": "Peter is not X .", "2": "X is neither an a person who spills a lot of food on Peter 's clothing nor grew up as an only child with a sibling .", "3": "Peter is not X .", "4": "Peter is a person who tidies Peter 's space consistently and enjoys the process of cleaning .", "5": "Peter is not .", "6": "Peter is both an a person who spills a lot of food on Peter 's clothing and grew up as an only child with a sibling .", "7": "Peter is not Peter .", "8": "Peter is neither an a person who spills a lot of food on Peter 's clothing nor grew up as an only child with a sibling .", "9": "Peter is not Peter .", "a": "the process of cleaning is both an a person who spills a lot of food on Peter 's clothing and grew up as an only child with a sibling .", "b": "Peter is not the process of cleaning .", "c": "the process of cleaning is neither an a person who spills a lot of food on Peter 's clothing nor grew up as an only child with a sibling .", "d": "Peter is not the process of cleaning ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "1": ["6"], "2": ["7"]}, {"4": ["0"], "5": ["3"], "1": ["6"], "2": ["7", "6"]}, {"5": ["8"], "4": ["(¬d)", "(¬b)", "(¬7)", "(¬9)"], "6": ["(¬8)", "(¬9)"], "a": ["(¬c)", "(¬d)"]}], "predicted_steps": [false, true, false]}
{"text": "If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning. All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing. If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning. If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings. All households with a high net income have people who have parents who are very busy with their regular jobs. Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Peter is either a foodie who goes out frequently to find new food restaurants to try or belongs to a household with a high net income?", "id": "109", "ground_truth": "False", "reasoning": " Here is my reasoning:\n\nPremise 1.1: If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning.\nPremise 1.2: All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.\nConclusion 1: All foodies who go out frequently to find new food restaurants to try do not tidy their spaces consistently and enjoy the process of cleaning.\n\nPremise 2.1: If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning.\nPremise 2.2: If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings.\nConclusion 2: If people have parents who are very busy with their regular jobs, then they tidy their spaces consistently and enjoy the process of cleaning.\n\nPremise 3.1: Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings.\nPremise 3.2: All households with a high net income have people who have parents who are very busy with their regular jobs.\nConclusion 3: Peter is either a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he belongs to a household with a high net income.\n\nConclusion 4: It is true that Peter is either a foodie who goes out frequently to find new food restaurants to try or belongs to a household with a high net income.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→(1∧2)), (3→4)], [(0→(1∧2)), (3→4)], [((0→1)⊻(2→3)), (4→5)]]", "logic_conclusion": "[(5→(6∧7)), (5→(6∧7)), ((6→7)⊻8)]", "correspondance": [{"0": "X spill a lot of food on people 's clothing .", "1": "X do not tidy X 's spaces consistently .", "2": "X do not enjoy the process of cleaning .", "3": "X is a foody who goes out frequently to finds new food restaurants to tries .", "4": "X is a people who spills a lot of food on their clothing .", "5": "X is a foody who goes out frequently to finds new food restaurants to tries .", "6": "X does not tidies their spaces consistently .", "7": "X does not enjoys the process of cleaning ."}, {"0": "X grew up as only children with no siblings .", "1": "X tidy X 's spaces consistently .", "2": "X enjoy the process of cleaning .", "3": "X have parents who are very busy with their regular jobs .", "4": "X grew up as only children with no siblings .", "5": "X have parents who are very busy with their regular jobs .", "6": "X tidy X 's spaces consistently .", "7": "X enjoy the process of cleaning ."}, {"0": "X is both an a person who spills a lot of food on Peter 's clothing and grew up as an only child with a sibling .", "1": "Peter is not X .", "2": "X is neither an a person who spills a lot of food on Peter 's clothing nor grew up as an only child with a sibling .", "3": "Peter is not X .", "4": "X is a household with a high net income .", "5": "X has people who has parents who is very busy with their regular jobs .", "6": "X is a person who spills a lot of food on Peter 's clothing and grew up as an only child with a sibling .", "7": "Peter is not X .", "8": "Peter belongs to a household with a high net income ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "1": ["6"], "2": ["7"]}, {"4": ["0"], "5": ["3"], "1": ["6"], "2": ["7", "6"]}, {"6": ["0"], "1": ["7"], "3": ["7"], "0": ["(¬2)"]}], "predicted_steps": [false, true, false]}
{"text": "If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning. All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing. If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning. If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings. All households with a high net income have people who have parents who are very busy with their regular jobs. Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Peter is either a foodie who goes out frequently to find new food restaurants to try and belong to a household with a high net income or he is a foodie who goes out frequently to find new food restaurants to try nor belongs to a household with a high net income?", "id": "110", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If people spill a lot of food on their clothing, then they do not tidy their spaces consistently and enjoy the process of cleaning.\nPremise 1.2: All foodies who go out frequently to find new food restaurants to try are people who spill a lot of food on their clothing.\nConclusion 1: All foodies who go out frequently to find new food restaurants to try do not tidy their spaces consistently and enjoy the process of cleaning.\n\nPremise 2.1: If people grew up as only children with no siblings, then they tidy their spaces consistently and enjoy the process of cleaning.\nPremise 2.2: If people have parents who are very busy with their regular jobs, then they grew up as only children with no siblings.\nConclusion 2: If people have parents who are very busy with their regular jobs, then they tidy their spaces consistently and enjoy the process of cleaning.\n\nPremise 3.1: Peter is either both a person who spills a lot of food on his clothing and grew up as an only child with no siblings, or he is neither a person who spills a lot of food on his clothing nor grew up as an only child with no siblings.\nPremise 3.2: All households with a high net income have people who have parents who are very busy with their regular jobs.\nConclusion 3: Peter is either a person who spills a lot of food on his clothing and belongs to a household with a high net income, or he is neither a person who spills a lot of food on his clothing nor belongs to a household with a high net income.\n\nConclusion 4: It is true that Peter is either a foodie who goes out frequently to find new food restaurants to try and belongs to a household with a high net income, or he is a foodie who goes out frequently to find new food restaurants to try nor belongs to a household with a high net income.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→(1∧2)), (3→4)], [(0→(1∧2)), (3→4)], [((9→a)⊻(b→c)), (d→e)]]", "logic_conclusion": "[(5→(6∧7)), (5→(6∧7)), (6⊻(7∧8))]", "correspondance": [{"0": "X spill a lot of food on people 's clothing .", "1": "X do not tidy X 's spaces consistently .", "2": "X do not enjoy the process of cleaning .", "3": "X is a foody who goes out frequently to finds new food restaurants to tries .", "4": "X is a people who spills a lot of food on their clothing .", "5": "X is a foody who goes out frequently to finds new food restaurants to tries .", "6": "X does not tidies their spaces consistently .", "7": "X does not enjoys the process of cleaning ."}, {"0": "X grew up as only children with no siblings .", "1": "X tidy X 's spaces consistently .", "2": "X enjoy the process of cleaning .", "3": "X have parents who are very busy with their regular jobs .", "4": "X grew up as only children with no siblings .", "5": "X have parents who are very busy with their regular jobs .", "6": "X tidy X 's spaces consistently .", "7": "X enjoy the process of cleaning ."}, {"0": "X is both an a person who spills a lot of food on Peter 's clothing and grew up as an only child with a sibling .", "1": "Peter is not X .", "2": "X is neither an a person who spills a lot of food on Peter 's clothing nor grew up as an only child with a sibling .", "3": "Peter is not X .", "4": "X is a household with a high net income .", "5": "X has people who has parents who is very busy with their regular jobs .", "6": "Peter is a person who spills a lot of food on Peter 's clothing and belongs to a household with a high net income .", "7": "Peter is not a person who spills a lot of food on Peter 's clothing .", "8": "Peter does not belong to a household with a high net income .", "9": "Peter is both an a person who spills a lot of food on Peter 's clothing and grew up as an only child with a sibling .", "a": "Peter is not Peter .", "b": "Peter is neither an a person who spills a lot of food on Peter 's clothing nor grew up as an only child with a sibling .", "c": "Peter is not Peter .", "d": "Peter is a household with a high net income .", "e": "Peter has people who has parents who is very busy with their regular jobs ."}], "errors": [[]], "entailments_dict": [{"5": ["3"], "1": ["6"], "2": ["7"]}, {"4": ["0"], "5": ["3"], "1": ["6"], "2": ["7", "6"]}, {"9": ["(¬b)", "(¬c)"], "6": ["(¬c)", "(¬a)"], "(¬8)": ["d"], "(¬6)": ["b"]}], "predicted_steps": [false, true, false]}
{"text": "All fir trees are evergreens. Some objects of worship are fir trees.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Some evergreens are not objects of worship?", "id": "111", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All fir trees are evergreens.\nPremise 1.2: Some objects of worship are fir trees.\nConclusion 1: Some evergreens are objects of worship.\nPremise 2.1: Some evergreens are objects of worship.\nConclusion 2: It is not true that all evergreens are not objects of worship.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), 2], [0]]", "logic_conclusion": "[3, (1→2)]", "correspondance": [{"0": "X is fir a tree .", "1": "X is an evergreen .", "2": "Some objects of worship are fir trees .", "3": "Some evergreens are objects of worship ."}, {"0": "Some evergreens are objects of worship .", "1": "X is an evergreen .", "2": "It is not true that X is not an object of worship ."}], "errors": [[]], "entailments_dict": [{"2": ["3"]}, {}], "predicted_steps": [true, false]}
{"text": "The Picuris Mountains are a mountain range in New Mexico or Texas. Juan de Onate visited the Picuris Mountains. The Harding Pegmatite Mine, located in the Picuris Mountains, was donated. There are no mountain ranges in texas that have mines which have been donated.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Juan de Onate visited a mountain range in New Mexico?", "id": "112", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: The Picuris Mountains are a mountain range in New Mexico or Texas.\nPremise 1.2: Juan de Onate visited the Picuris Mountains.\nConclusion 1: Juan de Onate visited a mountain range in either New Mexico or Texas.\n\nPremise 2.1: The Harding Pegmatite Mine, located in the Picuris Mountains, was donated.\nPremise 2.2: There are no mountain ranges in Texas that have mines which have been donated.\nConclusion 2: The Picuris Mountains are not located in Texas.\n\nPremise 3.1: Juan de Onate visited the Picuris Mountains.\nPremise 3.2: The Picuris Mountains are not located in Texas.\nConclusion 3: Juan de Onate visited a mountain range in New Mexico.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0∨1), 2], [0, ((4→5)∪((6→7)∪(8→9)))], [0, 1]]", "logic_conclusion": "[(3⊻4), 3, 2]", "correspondance": [{"0": "the Picuris Mountains are a mountain range in New Mexico .", "1": "the Picuris Mountains are a mountain range in Texas .", "2": "Juan de Onate visited the Picuris Mountains .", "3": "Juan de Onate visited a mountain range in New Mexico .", "4": "Juan de Onate visited a mountain range in Texas ."}, {"0": "The Harding Pegmatite Mine , located in the Picuris Mountains , was donated .", "1": "X is mountain an a range in Texas that has mines which has been donated .", "2": "There is not X .", "3": "the Picuris Mountains are not located in Texas .", "4": "Texas is mountain an a range in Texas that has mines which has been donated .", "5": "There is not Texas .", "6": "The Picuris Mountains is mountain an a range in Texas that has mines which has been donated .", "7": "There is not The Picuris Mountains .", "8": "The Harding Pegmatite Mine, located in the Picuris Mountains, is mountain an a range in Texas that has mines which has been donated .", "9": "There is not The Harding Pegmatite Mine, located in the Picuris Mountains, ."}, {"0": "Juan de Onate visited the Picuris Mountains .", "1": "the Picuris Mountains are not located in Texas .", "2": "Juan de Onate visited a mountain range in New Mexico ."}], "errors": [[]], "entailments_dict": [{"2": ["0", "4", "3"], "4": ["1", "2"], "3": ["0"], "1": ["4"]}, {"0": ["(¬7)", "(¬9)"], "7": ["(¬0)"], "9": ["(¬0)"], "3": ["(¬5)"], "(¬3)": ["0", "8", "6"], "(¬6)": ["0"], "(¬4)": ["0"]}, {"0": ["2"]}], "predicted_steps": [false, false, true]}
{"text": "The Picuris Mountains are a mountain range in New Mexico or Texas. Juan de Onate visited the Picuris Mountains. The Harding Pegmatite Mine, located in the Picuris Mountains, was donated. There are no mountain ranges in texas that have mines which have been donated.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Juan de Onate visited a mountain range in Texas?", "id": "113", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: The Picuris Mountains are a mountain range in New Mexico or Texas.\nPremise 1.2: Juan de Onate visited the Picuris Mountains.\nConclusion 1: Juan de Onate visited a mountain range in either New Mexico or Texas.\n\nPremise 2.1: There are no mountain ranges in Texas that have mines which have been donated.\nPremise 2.2: The Harding Pegmatite Mine, located in the Picuris Mountains, was donated.\nConclusion 2: The Picuris Mountains are not located in Texas.\n\nPremise 3.1: Juan de Onate visited a mountain range in either New Mexico or Texas.\nPremise 3.2: The Picuris Mountains are not located in Texas.\nConclusion 3: Juan de Onate visited a mountain range in New Mexico.\n\nConclusion 4: The answer is B. No, it is not true that Juan de Onate visited a mountain range in Texas.\n\nTherefore, the answer is B. No.", "logic_premises": "[[(0∨1), 2], [((4→5)∪((6→7)∪(8→9))), 2], [(0⊻1), 2]]", "logic_conclusion": "[(3⊻4), 3, 3]", "correspondance": [{"0": "the Picuris Mountains are a mountain range in New Mexico .", "1": "the Picuris Mountains are a mountain range in Texas .", "2": "Juan de Onate visited the Picuris Mountains .", "3": "Juan de Onate visited a mountain range in New Mexico .", "4": "Juan de Onate visited a mountain range in Texas ."}, {"0": "X is mountain an a range in Texas that has mines which has been donated .", "1": "There is not X .", "2": "The Harding Pegmatite Mine , located in the Picuris Mountains , was donated .", "3": "the Picuris Mountains are not located in Texas .", "4": "Texas is mountain an a range in Texas that has mines which has been donated .", "5": "There is not Texas .", "6": "The Picuris Mountains is mountain an a range in Texas that has mines which has been donated .", "7": "There is not The Picuris Mountains .", "8": "The Harding Pegmatite Mine, located in the Picuris Mountains, is mountain an a range in Texas that has mines which has been donated .", "9": "There is not The Harding Pegmatite Mine, located in the Picuris Mountains, ."}, {"0": "Juan de Onate visited a mountain range in New Mexico .", "1": "Juan de Onate visited a mountain range in Texas .", "2": "The Picuris Mountains are not located in Texas .", "3": "Juan de Onate visited a mountain range in New Mexico ."}], "errors": [[]], "entailments_dict": [{"2": ["0", "4", "3"], "4": ["1", "2"], "3": ["0"], "1": ["4"]}, {"2": ["(¬9)", "(¬7)"], "7": ["(¬2)"], "9": ["(¬2)"], "3": ["(¬5)"], "(¬3)": ["8", "6", "2"], "(¬6)": ["2"], "(¬4)": ["2"]}, {"3": ["0"], "0": ["3"], "1": ["(¬2)"], "(¬2)": ["1"]}], "predicted_steps": [false, false, false]}
{"text": "The Picuris Mountains are a mountain range in New Mexico or Texas. Juan de Onate visited the Picuris Mountains. The Harding Pegmatite Mine, located in the Picuris Mountains, was donated. There are no mountain ranges in texas that have mines which have been donated.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The Harding Pegmatite Mine is not located in a mountain range in New Mexico?", "id": "114", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: The Picuris Mountains are a mountain range in New Mexico or Texas.\nPremise 1.2: Juan de Onate visited the Picuris Mountains.\nConclusion 1: The Picuris Mountains are located in either New Mexico or Texas.\n\nPremise 2.1: The Harding Pegmatite Mine is located in the Picuris Mountains.\nPremise 2.2: There are no mountain ranges in Texas that have mines which have been donated.\nConclusion 2: The Harding Pegmatite Mine is not located in a mountain range in Texas.\n\nPremise 3.1: The Harding Pegmatite Mine is not located in a mountain range in Texas.\nConclusion 3: The Harding Pegmatite Mine is located in a mountain range in New Mexico.\n\nTherefore, the answer is A. Yes. The Harding Pegmatite Mine is not located in a mountain range in New Mexico.", "logic_premises": "[[(0∨1), 2], [0, ((4→5)∪((6→7)∪(8→9)))], [0]]", "logic_conclusion": "[(3⊻4), 3, 1]", "correspondance": [{"0": "the Picuris Mountains are a mountain range in New Mexico .", "1": "the Picuris Mountains are a mountain range in Texas .", "2": "Juan de Onate visited the Picuris Mountains .", "3": "the Picuris Mountains are located in New Mexico .", "4": "the Picuris Mountains are located in Texas ."}, {"0": "the Harding Pegmatite Mine is located in the Picuris Mountains .", "1": "X is mountain an a range in Texas that has mines which has been donated .", "2": "There is not X .", "3": "the Harding Pegmatite Mine is not located in a mountain range in Texas .", "4": "Texas is mountain an a range in Texas that has mines which has been donated .", "5": "There is not Texas .", "6": "The Harding Pegmatite Mine is mountain an a range in Texas that has mines which has been donated .", "7": "There is not The Harding Pegmatite Mine .", "8": "the Picuris Mountains is mountain an a range in Texas that has mines which has been donated .", "9": "There is not the Picuris Mountains ."}, {"0": "the Harding Pegmatite Mine is not located in a mountain range in Texas .", "1": "the Harding Pegmatite Mine is located in a mountain range in New Mexico ."}], "errors": [[]], "entailments_dict": [{"2": ["0", "3"], "4": ["1"], "3": ["0", "(¬1)"], "1": ["4"], "0": ["3"]}, {"9": ["3", "(¬0)"], "0": ["(¬7)", "(¬9)"], "7": ["(¬0)"], "3": ["(¬0)", "(¬7)", "(¬5)"], "(¬3)": ["0", "6"]}, {"1": ["0"]}], "predicted_steps": [false, false, false]}
{"text": "If a man is taller than another man, the taller one can block the other's shooting. Michael is a man who is taller than everyone else in his class. If person x is taller than person y, and person y is taller than person z, than x is taller than z Peter is a man who is taller than Michael. Michael can block any shooting from a person as long as the person does not jump when shooting. Michael cannot block Windy's shooting. Every shooter who can jump when shooting is a great shooter.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Peter is shorter than a man in Michael's class?", "id": "115", "ground_truth": "False", "reasoning": " Premise 1.1: If a man is taller than another man, the taller one can block the other's shooting.\nPremise 1.2: Michael is a man who is taller than everyone else in his class.\nConclusion 1: Michael can block any shooting from a person as long as the person does not jump when shooting.\nPremise 2.1: Peter is a man who is taller than Michael.\nConclusion 2: Peter can block Michael's shooting.\nPremise 3.1: Michael cannot block Windy's shooting.\nConclusion 3: Windy can jump when shooting.\nPremise 4.1: Every shooter who can jump when shooting is a great shooter.\nConclusion 4: Windy is a great shooter.\nPremise 5.1: Peter is taller than Michael.\nPremise 5.2: Michael is taller than everyone else in his class.\nConclusion 5: Peter is taller than everyone else in Michael's class.\nConclusion 6: Peter is shorter than Windy.\n\nTherefore, the answer is B. No. It is not true that Peter is shorter than a man in Michael's class.", "logic_premises": "[[((0∧1)→2), (3→4)], [0], [0], [(3→4)], [0, ((5→6)∪((7→8)∪(9→a)))]]", "logic_conclusion": "[(5→6), 1, 1, 2, ((b→c)∪((d→e)∪(f→g)))]", "correspondance": [{"0": "X is a man", "1": "X is taller than another man .", "2": "X can block another man 's shooting .", "3": "X is a person man who is taller than else in Michael 's class .", "4": "Michael is X .", "5": "X is a shooting from a person .", "6": "Michael can block X as long as a person does not jump when shooting ."}, {"0": "Peter is a man who is taller than Michael .", "1": "Peter can block Michael 's shooting ."}, {"0": "Michael can not block Windy 's 's shooting .", "1": "Windy 's can jump that shooting ."}, {"0": "X is a shooter who can jump when shooting .", "1": "X is a great shooter .", "2": "Windy is a great shooter .", "3": "Windy is a shooter who can jump when shooting .", "4": "Windy is a great shooter ."}, {"0": "Peter is taller than Michael .", "1": "X is a person else in Michael 's class .", "2": "Michael is taller than X .", "3": "X is a person else in Michael 's class .", "4": "Peter is taller than X .", "5": "Peter is a person else in Michael 's class .", "6": "Michael is taller than Peter .", "7": "Michaels class is a person else in Michael 's class .", "8": "Michael is taller than Michaels class .", "9": "Michael is a person else in Michael 's class .", "a": "Michael is taller than Michael .", "b": "Peter is a person else in Michael 's class .", "c": "Peter is taller than Peter .", "d": "Michaels class is a person else in Michael 's class .", "e": "Peter is taller than Michaels class .", "f": "Michael is a person else in Michael 's class .", "g": "Peter is taller than Michael ."}], "errors": [[]], "entailments_dict": [{}, {}, {}, {"4": ["2"]}, {"d": ["7", "9", "5", "(¬a)"], "b": ["5", "7", "9", "(¬a)"], "f": ["9", "7", "5"], "0": ["g", "(¬6)"], "6": ["(¬0)"]}], "predicted_steps": [false, false, false, false, "Contradiction in the premises"]}
{"text": "If a man is taller than another man, the taller one can block the other's shooting. Michael is a man who is taller than everyone else in his class. If person x is taller than person y, and person y is taller than person z, than x is taller than z Peter is a man who is taller than Michael. Michael can block any shooting from a person as long as the person does not jump when shooting. Michael cannot block Windy's shooting. Every shooter who can jump when shooting is a great shooter.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Windy is a great shooter?", "id": "116", "ground_truth": "True", "reasoning": " Premise 1.1: If a man is taller than another man, the taller one can block the other's shooting.\nPremise 1.2: Michael is a man who is taller than everyone else in his class.\nConclusion 1: Michael can block any shooting from a person as long as the person does not jump when shooting.\nPremise 2.1: Peter is a man who is taller than Michael.\nConclusion 2: Peter can block Michael's shooting.\nPremise 3.1: Michael cannot block Windy's shooting.\nConclusion 3: Windy can jump when shooting.\nPremise 4.1: Every shooter who can jump when shooting is a great shooter.\nConclusion 4: Windy is a great shooter.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((0∧1)→2), (3→4)], [0], [0], [(3→4)]]", "logic_conclusion": "[(5→6), 1, 1, 2]", "correspondance": [{"0": "X is a man", "1": "X is taller than another man .", "2": "X can block another man 's shooting .", "3": "X is a person man who is taller than else in Michael 's class .", "4": "Michael is X .", "5": "X is a shooting from a person .", "6": "Michael can block X as long as a person does not jump when shooting ."}, {"0": "Peter is a man who is taller than Michael .", "1": "Peter can block Michael 's shooting ."}, {"0": "Michael can not block Windy 's 's shooting .", "1": "Windy 's can jump that shooting ."}, {"0": "X is a shooter who can jump when shooting .", "1": "X is a great shooter .", "2": "Windy is a great shooter .", "3": "Windy is a shooter who can jump when shooting .", "4": "Windy is a great shooter ."}], "errors": [[]], "entailments_dict": [{}, {}, {}, {"4": ["2"]}], "predicted_steps": [false, false, false, false]}
{"text": "If a man is taller than another man, the taller one can block the other's shooting. Michael is a man who is taller than everyone else in his class. If person x is taller than person y, and person y is taller than person z, than x is taller than z Peter is a man who is taller than Michael. Michael can block any shooting from a person as long as the person does not jump when shooting. Michael cannot block Windy's shooting. Every shooter who can jump when shooting is a great shooter.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Peter can block Windy's shooting?", "id": "117", "ground_truth": "Uncertain", "reasoning": " Premise 1.1: If a man is taller than another man, the taller one can block the other's shooting.\nPremise 1.2: Michael is a man who is taller than everyone else in his class.\nConclusion 1: Michael can block any shooting from a person as long as the person does not jump when shooting.\nPremise 2.1: Peter is a man who is taller than Michael.\nConclusion 2: Peter can block Michael's shooting.\nPremise 3.1: Michael cannot block Windy's shooting.\nConclusion 3: Windy can jump when shooting.\nPremise 4.1: Every shooter who can jump when shooting is a great shooter.\nConclusion 4: Windy is a great shooter.\nPremise 5.1: Peter can block any shooting from a person as long as the person does not jump when shooting.\nPremise 5.2: Windy can jump when shooting.\nConclusion 5: Peter cannot block Windy's shooting.\n\nTherefore, the answer is B. No. Peter cannot block Windy's shooting because Windy can jump when shooting, and Peter can only block shooting from people who do not jump when shooting.", "logic_premises": "[[((0∧1)→2), (3→4)], [0], [0], [(3→4)], [((4→5)∪((6→7)∪((8→9)∪(a→b)))), 2]]", "logic_conclusion": "[(5→6), 1, 1, 2, 3]", "correspondance": [{"0": "X is a man", "1": "X is taller than another man .", "2": "X can block another man 's shooting .", "3": "X is a person man who is taller than else in Michael 's class .", "4": "Michael is X .", "5": "X is a shooting from a person .", "6": "Michael can block X as long as a person does not jump when shooting ."}, {"0": "Peter is a man who is taller than Michael .", "1": "Peter can block Michael 's shooting ."}, {"0": "Michael can not block Windy 's 's shooting .", "1": "Windy 's can jump that shooting ."}, {"0": "X is a shooter who can jump when shooting .", "1": "X is a great shooter .", "2": "Windy is a great shooter .", "3": "Windy is a shooter who can jump when shooting .", "4": "Windy is a great shooter ."}, {"0": "X is a shooting from a person .", "1": "Peter can block X as long as a person does not jump when shooting .", "2": "Windy can jump that shooting .", "3": "Peter can not block Windy 's shooting .", "4": "Peter is a shooting from a person .", "5": "Peter can block Peter as long as a person does not jump when shooting .", "6": "Windy is a shooting from a person .", "7": "Peter can block Windy as long as a person does not jump when shooting .", "8": "Windys shooting is a shooting from a person .", "9": "Peter can block Windys shooting as long as a person does not jump when shooting .", "a": "the person is a shooting from a person .", "b": "Peter can block the person as long as a person does not jump when shooting ."}], "errors": [[]], "entailments_dict": [{}, {}, {}, {"4": ["2"]}, {"9": ["(¬2)"]}], "predicted_steps": [false, false, false, false, false]}
{"text": "Barutin Cove is named after the Bulgarian settlement of Barutin. Barutin Cove is on the southwest coast of Snow Island. The South Shetland Islands include Snow Island, Greenwich Island, and Deception Island. The South Shetland Islands are considered part of Antarctica. If A is located in B and B is located in C, then A is located in C.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Barutin is named after all islands in Antarctica?", "id": "118", "ground_truth": "Uncertain", "reasoning": " No.\n\nPremise 1: Barutin Cove is named after the Bulgarian settlement of Barutin.\nPremise 2: Barutin Cove is on the southwest coast of Snow Island.\nPremise 3: Snow Island is part of the South Shetland Islands.\nPremise 4: The South Shetland Islands are considered part of Antarctica.\nConclusion 1: Barutin Cove is located in Antarctica.\nPremise 5: If A is located in B and B is located in C, then A is located in C.\nConclusion 2: Barutin is not named after all islands in Antarctica.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, 1, 2, 3], [((0∧1)→2)]]", "logic_conclusion": "[4, ((5→6)∪((7→8)∪(9→a)))]", "correspondance": [{"0": "Barutin Cove is named after the Bulgarian settlement of Barutin .", "1": "Barutin Cove is on the southwest coast of Snow Island .", "2": "Snow Island is part of the South Shetland Islands .", "3": "the South Shetland Islands are considered part of Antarctica .", "4": "Barutin Cove is located in Antarctica ."}, {"0": "A is located in B .", "1": "B is located in C .", "2": "A is located in C.", "3": "X is an island in Antarctica .", "4": "Barutin is not named after X .", "5": "B is an island in Antarctica .", "6": "Barutin is not named after B .", "7": "Barutin is an island in Antarctica .", "8": "Barutin is not named after Barutin .", "9": "Antarctica is an island in Antarctica .", "a": "Barutin is not named after Antarctica ."}], "errors": [[]], "entailments_dict": [{"3": ["2"], "1": ["2"], "4": ["1"]}, {"9": ["0"]}], "predicted_steps": [false, false]}
{"text": "Barutin Cove is named after the Bulgarian settlement of Barutin. Barutin Cove is on the southwest coast of Snow Island. The South Shetland Islands include Snow Island, Greenwich Island, and Deception Island. The South Shetland Islands are considered part of Antarctica. If A is located in B and B is located in C, then A is located in C.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that There is at least one cove in Antarctica named after a place in Bulgaria?", "id": "119", "ground_truth": "True", "reasoning": " Premise 1: Barutin Cove is named after the Bulgarian settlement of Barutin.\nPremise 2: Barutin Cove is on the southwest coast of Snow Island.\nPremise 3: Snow Island is part of the South Shetland Islands.\nPremise 4: The South Shetland Islands are considered part of Antarctica.\nConclusion 1: Barutin Cove is located in Antarctica.\nPremise 5: If A is located in B and B is located in C, then A is located in C.\nConclusion 2: Barutin Cove is located in Antarctica, and therefore, it is true that there is at least one cove in Antarctica named after a place in Bulgaria.\nAnswer: A. Yes", "logic_premises": "[[0, 1, 2, 3], [((0∧1)→2)]]", "logic_conclusion": "[4, (3∧4)]", "correspondance": [{"0": "Barutin Cove is named after the Bulgarian settlement of Barutin .", "1": "Barutin Cove is on the southwest coast of Snow Island .", "2": "Snow Island is part of the South Shetland Islands .", "3": "the South Shetland Islands are considered part of Antarctica .", "4": "Barutin Cove is located in Antarctica ."}, {"0": "A is located in B .", "1": "B is located in C .", "2": "A is located in C.", "3": "Barutin Cove is located in Antarctica .", "4": "therefore , it is true that there is at least one cove in Antarctica named after a place in Bulgaria ."}], "errors": [[]], "entailments_dict": [{"3": ["2"], "1": ["2"], "4": ["1"]}, {}], "predicted_steps": [false, false]}
{"text": "Barutin Cove is named after the Bulgarian settlement of Barutin. Barutin Cove is on the southwest coast of Snow Island. The South Shetland Islands include Snow Island, Greenwich Island, and Deception Island. The South Shetland Islands are considered part of Antarctica. If A is located in B and B is located in C, then A is located in C.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Barutin is not located in Antarctica?", "id": "120", "ground_truth": "False", "reasoning": " Premise 1: Barutin Cove is named after the Bulgarian settlement of Barutin.\nPremise 2: Barutin Cove is on the southwest coast of Snow Island.\nPremise 3: Snow Island is part of the South Shetland Islands.\nPremise 4: The South Shetland Islands are considered part of Antarctica.\nPremise 5: If A is located in B and B is located in C, then A is located in C.\n\nConclusion 1: Barutin Cove is located on Snow Island.\nConclusion 2: Snow Island is located in Antarctica.\nConclusion 3: Barutin Cove is located in Antarctica.\n\nTherefore, the answer is B. No. It is not true that Barutin is not located in Antarctica. Barutin Cove, which is named after the Bulgarian settlement of Barutin, is located on Snow Island, which is part of the South Shetland Islands and therefore part of Antarctica.", "logic_premises": "[[0, 1, 2, 3, ((4∧5)→6)]]", "logic_conclusion": "[7]", "correspondance": [{"0": "Barutin Cove is named after the Bulgarian settlement of Barutin .", "1": "Barutin Cove is on the southwest coast of Snow Island .", "2": "Snow Island is part of the South Shetland Islands .", "3": "the South Shetland Islands are considered part of Antarctica .", "4": "A is located in B .", "5": "B is located in C .", "6": "A is located in C.", "7": "Barutin Cove is located on Snow Island ."}], "errors": [[]], "entailments_dict": [{"3": ["2"], "1": ["5", "2", "7"], "7": ["1", "2", "5"]}], "predicted_steps": [true]}
{"text": "Some affection is love. Some love is positive.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Some affection is positive?", "id": "121", "ground_truth": "Uncertain", "reasoning": " Sure, I can help you with that! Here's my step-by-step reasoning:\n\nPremise 1.1: Some affection is love.\nPremise 1.2: Some love is positive.\nConclusion 1: Some affection is positive.\n\nTherefore, the answer is A. Yes.\n\nHere's a breakdown of each step:\n\nPremise 1.1: This premise states that some affection is love. This means that there is a subset of affection that can be classified as love.\n\nPremise 1.2: This premise states that some love is positive. This means that there is a subset of love that can be classified as positive.\n\nConclusion 1: By combining Premise 1.1 and Premise 1.2, we can conclude that some affection is positive. This is because some affection is love, and some love is positive. Therefore, it is true that some affection is positive.\n\nI hope this helps! Let me know if you have any questions or need further clarification.", "logic_premises": "[[0, 1], []]", "logic_conclusion": "[2, '-1']", "correspondance": [{"0": "Some affection is love .", "1": "Some love is positive .", "2": "Some affection is positive ."}, {}], "errors": ["Logic Transform Error -  Step n°: 1 The given 'sentence' contains more than one sentence. A ConstituentTree object can process only one sentence at a time.", ["Entailments Error -  Step n°: 1 'str' object has no attribute 'get_variables_implications'"]], "entailments_dict": [{"1": ["0", "2"], "0": ["1", "2"], "2": ["0", "1"]}, {}], "predicted_steps": [true, false]}
{"text": "If something can transport multiple passengers, then they are not empty. All airlines can transport multiple passengers. All planes are empty. All Boeing 707s are planes. If Greyhound is not an airline, then there are no Greyhound planes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Greyhound is an airline?", "id": "122", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If something can transport multiple passengers, then they are not empty.\nPremise 1.2: All airlines can transport multiple passengers.\nConclusion 1: All airlines are not empty.\n\nPremise 2.1: All planes are empty.\nConclusion 2: All planes are not empty (contradiction).\n\nPremise 3.1: All Boeing 707s are planes.\nConclusion 3: All Boeing 707s are not empty.\n\nPremise 4.1: If Greyhound is not an airline, then there are no Greyhound planes.\nConclusion 4: If Greyhound is not an airline, then there are no Greyhound planes (tautology).\n\nPremise 5.1: There are no Greyhound planes.\nConclusion 5: Greyhound is not an airline.\n\nTherefore, the answer is B. No. It is not true that Greyhound is an airline.", "logic_premises": "[[(0→1), (2→3)], [(0→1)], [(0→1)], [(0→1)], [((3→4)∪(5→6))]]", "logic_conclusion": "[(4→5), (2→3), (2→3), (2→3), 2]", "correspondance": [{"0": "X can transport multiple passengers .", "1": "X are not empty .", "2": "X is an airline .", "3": "X can transport multiple passengers .", "4": "X is an airline .", "5": "X is not empty ."}, {"0": "X is a plane .", "1": "X is empty .", "2": "X is a plane .", "3": "X is not empty ."}, {"0": "X is Boeing a 707 .", "1": "X is a plane .", "2": "X is Boeing a 707 .", "3": "X is not empty ."}, {"0": "Greyhound is not an airline .", "1": "there are no Greyhound planes .", "2": "Greyhound is not an airline .", "3": "there are no Greyhound planes ."}, {"0": "X is Greyhound an a plane .", "1": "There is not X .", "2": "Greyhound is not an airline .", "3": "Greyhound is Greyhound an a plane .", "4": "There is not Greyhound .", "5": "no Greyhound planes is Greyhound an a plane .", "6": "There is not no Greyhound planes ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["0", "2"], "1": ["5"]}, {"2": ["0"]}, {"2": ["0"]}, {"2": ["0"], "1": ["3"]}, {"4": ["2"], "6": ["2"]}], "predicted_steps": [true, false, false, true, false]}
{"text": "If something can transport multiple passengers, then they are not empty. All airlines can transport multiple passengers. All planes are empty. All Boeing 707s are planes. If Greyhound is not an airline, then there are no Greyhound planes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that A Greyhound is a Boeing 707?", "id": "123", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If something can transport multiple passengers, then they are not empty.\nPremise 1.2: All airlines can transport multiple passengers.\nConclusion 1: All airlines are not empty.\n\nPremise 2.1: All planes are empty.\nConclusion 2: All planes are not empty (contradiction).\n\nPremise 3.1: All Boeing 707s are planes.\nConclusion 3: All Boeing 707s are not empty (based on Conclusion 1).\n\nPremise 4.1: If Greyhound is not an airline, then there are no Greyhound planes.\nConclusion 4: If Greyhound is not an airline, then there are no Greyhound Boeing 707s (based on Premise 3.1).\n\nPremise 5.1: A Greyhound is a Boeing 707.\nConclusion 5: A Greyhound is not an airline (based on Conclusion 4).\n\nTherefore, the answer is B. No. It is not true that A Greyhound is a Boeing 707.", "logic_premises": "[[(0→1), (2→3)], [(0→1)], [(0→1)], [(0→1)], [(0→1)]]", "logic_conclusion": "[(4→5), (2→3), (2→3), (2→3), (2→3)]", "correspondance": [{"0": "X can transport multiple passengers .", "1": "X are not empty .", "2": "X is an airline .", "3": "X can transport multiple passengers .", "4": "X is an airline .", "5": "X is not empty ."}, {"0": "X is a plane .", "1": "X is empty .", "2": "X is a plane .", "3": "X is not empty ."}, {"0": "X is Boeing a 707 .", "1": "X is a plane .", "2": "X is Boeing a 707 .", "3": "X is not empty ."}, {"0": "Greyhound is not an airline .", "1": "there are no Greyhound planes .", "2": "Greyhound is not an airline .", "3": "there are no Greyhound Boeing 707s ."}, {"0": "X is A Greyhound", "1": "X is a Boeing 707 .", "2": "X is A Greyhound", "3": "X is not an airline ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["0", "2"], "1": ["5"]}, {"2": ["0"]}, {"2": ["0"]}, {"2": ["0"], "1": ["3"]}, {"2": ["0", "(¬1)"]}], "predicted_steps": [true, false, false, true, "Contradiction in the premises"]}
{"text": "If something can transport multiple passengers, then they are not empty. All airlines can transport multiple passengers. All planes are empty. All Boeing 707s are planes. If Greyhound is not an airline, then there are no Greyhound planes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that A Greyhound is not a Boeing 707?", "id": "124", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If something can transport multiple passengers, then they are not empty.\nPremise 1.2: All airlines can transport multiple passengers.\nConclusion 1: All airlines are not empty.\n\nPremise 2.1: All planes are empty.\nConclusion 2: All planes are not empty (contradiction).\n\nPremise 3.1: All Boeing 707s are planes.\nConclusion 3: All Boeing 707s are not empty (based on Conclusion 1).\n\nPremise 4.1: If Greyhound is not an airline, then there are no Greyhound planes.\nConclusion 4: If Greyhound is not an airline, then there are no Greyhound Boeing 707s (based on Premise 3.1).\n\nPremise 5.1: A Greyhound is not a Boeing 707.\nConclusion 5: A Greyhound is not a Boeing 707 (based on Conclusion 4).\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→1)], [(0→1)], [(0→1)], [(0→1)]]", "logic_conclusion": "[(4→5), (2→3), (2→3), (2→3), (2→3)]", "correspondance": [{"0": "X can transport multiple passengers .", "1": "X are not empty .", "2": "X is an airline .", "3": "X can transport multiple passengers .", "4": "X is an airline .", "5": "X is not empty ."}, {"0": "X is a plane .", "1": "X is empty .", "2": "X is a plane .", "3": "X is not empty ."}, {"0": "X is Boeing a 707 .", "1": "X is a plane .", "2": "X is Boeing a 707 .", "3": "X is not empty ."}, {"0": "Greyhound is not an airline .", "1": "there are no Greyhound planes .", "2": "Greyhound is not an airline .", "3": "there are no Greyhound Boeing 707s ."}, {"0": "X is a Greyhound", "1": "X is not a Boeing 707 .", "2": "X is a Greyhound", "3": "X is not a Boeing 707 ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["0", "2"], "1": ["5"]}, {"2": ["0"]}, {"2": ["0"]}, {"2": ["0"], "1": ["3"]}, {"2": ["0"], "1": ["3"]}], "predicted_steps": [true, false, false, true, true]}
{"text": "All mammals are animals. All monkeys are mammals. An animal is either a monkey or a bird. All birds fly. All animals breathe. If something can fly, then it has wings. If Rock is neither a fly nor a bird, then Rock neither flies nor breathes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Rock is a monkey?", "id": "125", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All mammals are animals.\nPremise 1.2: All monkeys are mammals.\nConclusion 1: All monkeys are animals.\n\nPremise 2.1: An animal is either a monkey or a bird.\nPremise 2.2: All birds fly.\nConclusion 2: If something is not a monkey, then it is a bird.\n\nPremise 3.1: All birds fly.\nPremise 3.2: All animals breathe.\nConclusion 3: If something flies, then it breathes.\n\nPremise 4.1: If Rock is neither a fly nor a bird, then Rock neither flies nor breathes.\nConclusion 4: Rock is not a bird.\n\nPremise 5.1: Rock is not a bird.\nPremise 5.2: All monkeys are animals.\nConclusion 5: Rock is a monkey.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→(1⊻2)), (3→4)], [(0→1), (2→3)], [((0∧1)→2)], [0, (4→5)]]", "logic_conclusion": "[(4→5), (5→6), (4→5), 3, 3]", "correspondance": [{"0": "X is a mammal .", "1": "X is an animal .", "2": "X is a monkey .", "3": "X is a mammal .", "4": "X is a monkey .", "5": "X is an animal ."}, {"0": "X is An animal", "1": "X is a monkey .", "2": "X is a bird .", "3": "X is a bird .", "4": "X flies .", "5": "X is not a monkey .", "6": "X is a bird ."}, {"0": "X is a bird .", "1": "X flies .", "2": "X is an animal .", "3": "X breathes .", "4": "X flies .", "5": "X breathes ."}, {"0": "Rock is not a fly .", "1": "Rock is not a bird .", "2": "Rock neither flies nor breathes .", "3": "Rock is not a bird ."}, {"0": "rock is not a bird .", "1": "X is a monkey .", "2": "X is an animal .", "3": "rock is a monkey .", "4": "Rock is a monkey .", "5": "Rock is an animal ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"], "1": ["5"]}, {"2": ["3", "6"], "4": ["6"], "1": ["(¬4)"], "5": ["(¬1)"]}, {"4": ["0"], "3": ["5"]}, {"3": ["1"], "2": ["3"]}, {"3": ["4"]}], "predicted_steps": [true, false, false, false, false]}
{"text": "All mammals are animals. All monkeys are mammals. An animal is either a monkey or a bird. All birds fly. All animals breathe. If something can fly, then it has wings. If Rock is neither a fly nor a bird, then Rock neither flies nor breathes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Rock has wings?", "id": "126", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All mammals are animals.\nPremise 1.2: All monkeys are mammals.\nConclusion 1: All monkeys are animals.\n\nPremise 2.1: An animal is either a monkey or a bird.\nPremise 2.2: All birds fly.\nConclusion 2: If something is not a monkey, then it is a bird.\n\nPremise 3.1: All birds fly.\nPremise 3.2: All animals breathe.\nConclusion 3: If something flies, then it breathes.\n\nPremise 4.1: If Rock is neither a fly nor a bird, then Rock neither flies nor breathes.\nConclusion 4: Rock does not fly.\n\nPremise 5.1: If something can fly, then it has wings.\nConclusion 5: Rock does not have wings.\n\nTherefore, the answer is B. No, it is not true that Rock has wings.", "logic_premises": "[[(0→1), (2→3)], [(0→(1⊻2)), (3→4)], [(0→1), (2→3)], [((0∧1)→2)], [(0→1)]]", "logic_conclusion": "[(4→5), (5→6), (4→5), 3, 2]", "correspondance": [{"0": "X is a mammal .", "1": "X is an animal .", "2": "X is a monkey .", "3": "X is a mammal .", "4": "X is a monkey .", "5": "X is an animal ."}, {"0": "X is An animal", "1": "X is a monkey .", "2": "X is a bird .", "3": "X is a bird .", "4": "X flies .", "5": "X is not a monkey .", "6": "X is a bird ."}, {"0": "X is a bird .", "1": "X flies .", "2": "X is an animal .", "3": "X breathes .", "4": "X flies .", "5": "X breathes ."}, {"0": "Rock is not a fly .", "1": "Rock is not a bird .", "2": "Rock neither flies nor breathes .", "3": "Rock does not fly ."}, {"0": "X can fly .", "1": "X has wings .", "2": "Rock does not have wings ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"], "1": ["5"]}, {"2": ["3", "6"], "4": ["6"], "1": ["(¬4)"], "5": ["(¬1)"]}, {"4": ["0"], "3": ["5"]}, {"3": ["1"], "2": ["3"]}, {}], "predicted_steps": [true, false, false, false, false]}
{"text": "All mammals are animals. All monkeys are mammals. An animal is either a monkey or a bird. All birds fly. All animals breathe. If something can fly, then it has wings. If Rock is neither a fly nor a bird, then Rock neither flies nor breathes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Rock does not have wings?", "id": "127", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All mammals are animals.\nPremise 1.2: All monkeys are mammals.\nConclusion 1: All monkeys are animals.\n\nPremise 2.1: An animal is either a monkey or a bird.\nPremise 2.2: All birds fly.\nConclusion 2: If something is not a monkey, then it is a bird.\n\nPremise 3.1: All birds fly.\nPremise 3.2: All animals breathe.\nConclusion 3: If something flies, then it breathes.\n\nPremise 4.1: If Rock is neither a fly nor a bird, then Rock neither flies nor breathes.\nConclusion 4: Rock does not have wings.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→(1⊻2)), (3→4)], [(0→1), (2→3)], [((0∧1)→2)]]", "logic_conclusion": "[(4→5), (5→6), (4→5), 3]", "correspondance": [{"0": "X is a mammal .", "1": "X is an animal .", "2": "X is a monkey .", "3": "X is a mammal .", "4": "X is a monkey .", "5": "X is an animal ."}, {"0": "X is An animal", "1": "X is a monkey .", "2": "X is a bird .", "3": "X is a bird .", "4": "X flies .", "5": "X is not a monkey .", "6": "X is a bird ."}, {"0": "X is a bird .", "1": "X flies .", "2": "X is an animal .", "3": "X breathes .", "4": "X flies .", "5": "X breathes ."}, {"0": "Rock is not a fly .", "1": "Rock is not a bird .", "2": "Rock neither flies nor breathes .", "3": "Rock does not have wings ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"], "1": ["5"]}, {"2": ["3", "6"], "4": ["6"], "1": ["(¬4)"], "5": ["(¬1)"]}, {"4": ["0"], "3": ["5"]}, {"3": ["1", "0"], "2": ["3"]}], "predicted_steps": [true, false, false, false]}
{"text": "All people who have a wedding are people who have at least one child. All people who travel to Paris for their honeymoon are people who have a wedding. All weddings that occur in July belong to people who travel to Paris for their honeymoon. Some weddings in July are well-attended. If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding. If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that John has a wedding that is well-attended?", "id": "128", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All people who have a wedding are people who have at least one child.\nPremise 1.2: All people who travel to Paris for their honeymoon are people who have a wedding.\nPremise 1.3: All weddings that occur in July belong to people who travel to Paris for their honeymoon.\nPremise 2.1: Some weddings in July are well-attended.\nPremise 2.2: If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.\nPremise 2.3: If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon.\n\nConclusion 1: John does not have a wedding.\n\nPremise 3.1: John does not have a wedding.\nConclusion 2: John does not have a wedding that is well-attended.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((d→e)∪((f→g)∪(h→i))), ((j→k)∪((l→m)∪(n→o))), ((p→q)∪((r→s)∪(t→u))), 6, (7→(8∧9)), (a→b)], [0]]", "logic_conclusion": "[c, 1]", "correspondance": [{"0": "X is a person who has a wedding .", "1": "X is a people who has at least one child .", "2": "X is a person who travels to Paris for their honeymoon .", "3": "X is a people who has a wedding .", "4": "X is a wedding that occurs in July .", "5": "X belongs to people who travels to Paris for their honeymoon .", "6": "Some weddings in July are well - attended .", "7": "John has at least one child .", "8": "John does not travel to Paris for John 's honeymoon .", "9": "John does not have a wedding .", "a": "John has a wedding that is well - attended .", "b": "John has a wedding in July or , if not , then John travels to Paris for their honeymoon .", "c": "John does not have a wedding .", "d": "Paris is a person who has a wedding .", "e": "Paris is a people who has at least one child .", "f": "July is a person who has a wedding .", "g": "July is a people who has at least one child .", "h": "John is a person who has a wedding .", "i": "John is a people who has at least one child .", "j": "Paris is a person who travels to Paris for their honeymoon .", "k": "Paris is a people who has a wedding .", "l": "July is a person who travels to Paris for their honeymoon .", "m": "July is a people who has a wedding .", "n": "John is a person who travels to Paris for their honeymoon .", "o": "John is a people who has a wedding .", "p": "Paris is a wedding that occurs in July .", "q": "Paris belongs to people who travels to Paris for their honeymoon .", "r": "July is a wedding that occurs in July .", "s": "July belongs to people who travels to Paris for their honeymoon .", "t": "John is a wedding that occurs in July .", "u": "John belongs to people who travels to Paris for their honeymoon ."}, {"0": "John does not have a wedding .", "1": "John does not have a wedding that is well - attended ."}], "errors": [[]], "entailments_dict": [{"b": ["n", "h", "r", "c", "(¬8)"], "u": ["n", "h", "(¬9)", "(¬8)"], "m": ["f"], "o": ["h", "(¬9)"], "i": ["7"], "q": ["n"], "k": ["d"], "9": ["c", "(¬o)"], "8": ["(¬u)"], "c": ["(¬o)"], "(¬c)": ["h", "a"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [false, true]}
{"text": "All people who have a wedding are people who have at least one child. All people who travel to Paris for their honeymoon are people who have a wedding. All weddings that occur in July belong to people who travel to Paris for their honeymoon. Some weddings in July are well-attended. If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding. If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that John does not have a wedding that is well-attended?", "id": "129", "ground_truth": "True", "reasoning": " Here is my reasoning:\n\nPremise 1.1: All people who have a wedding are people who have at least one child.\nPremise 1.2: All people who travel to Paris for their honeymoon are people who have a wedding.\nPremise 1.3: All weddings that occur in July belong to people who travel to Paris for their honeymoon.\nPremise 2.1: Some weddings in July are well-attended.\nPremise 2.2: If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.\nPremise 2.3: If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon.\nConclusion 1: John does not have a wedding that is well-attended.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((d→e)∪((f→g)∪(h→i))), ((j→k)∪((l→m)∪(n→o))), ((p→q)∪((r→s)∪(t→u))), 6, (7→(8∧9)), (a→b)]]", "logic_conclusion": "[c]", "correspondance": [{"0": "X is a person who has a wedding .", "1": "X is a people who has at least one child .", "2": "X is a person who travels to Paris for their honeymoon .", "3": "X is a people who has a wedding .", "4": "X is a wedding that occurs in July .", "5": "X belongs to people who travels to Paris for their honeymoon .", "6": "Some weddings in July are well - attended .", "7": "John has at least one child .", "8": "John does not travel to Paris for John 's honeymoon .", "9": "John does not have a wedding .", "a": "John has a wedding that is well - attended .", "b": "John has a wedding in July or , if not , then John travels to Paris for their honeymoon .", "c": "John does not have a wedding that is well - attended .", "d": "Paris is a person who has a wedding .", "e": "Paris is a people who has at least one child .", "f": "July is a person who has a wedding .", "g": "July is a people who has at least one child .", "h": "John is a person who has a wedding .", "i": "John is a people who has at least one child .", "j": "Paris is a person who travels to Paris for their honeymoon .", "k": "Paris is a people who has a wedding .", "l": "July is a person who travels to Paris for their honeymoon .", "m": "July is a people who has a wedding .", "n": "John is a person who travels to Paris for their honeymoon .", "o": "John is a people who has a wedding .", "p": "Paris is a wedding that occurs in July .", "q": "Paris belongs to people who travels to Paris for their honeymoon .", "r": "July is a wedding that occurs in July .", "s": "July belongs to people who travels to Paris for their honeymoon .", "t": "John is a wedding that occurs in July .", "u": "John belongs to people who travels to Paris for their honeymoon ."}], "errors": [[]], "entailments_dict": [{"b": ["n", "h", "r", "(¬8)"], "u": ["n", "h", "(¬9)", "(¬8)"], "m": ["f"], "o": ["h", "(¬9)"], "i": ["7"], "q": ["n"], "k": ["d"], "9": ["c", "(¬o)"], "8": ["(¬u)"], "(¬c)": ["h", "a"]}], "predicted_steps": ["Contradiction in the premises"]}
{"text": "All people who have a wedding are people who have at least one child. All people who travel to Paris for their honeymoon are people who have a wedding. All weddings that occur in July belong to people who travel to Paris for their honeymoon. Some weddings in July are well-attended. If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding. If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that John has at least one child?", "id": "130", "ground_truth": "Uncertain", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: All people who have a wedding are people who have at least one child.\nPremise 1.2: All people who travel to Paris for their honeymoon are people who have a wedding.\nPremise 1.3: All weddings that occur in July belong to people who travel to Paris for their honeymoon.\nPremise 2.1: Some weddings in July are well-attended.\nPremise 2.2: If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.\nPremise 2.3: If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon.\n\nConclusion 1: John does not have a wedding.\n\nPremise 3.1: John does not have a wedding.\nConclusion 2: John does not have at least one child.\n\nTherefore, the answer is B. No. It is not true that John has at least one child.", "logic_premises": "[[((d→e)∪((f→g)∪(h→i))), ((j→k)∪((l→m)∪(n→o))), ((p→q)∪((r→s)∪(t→u))), 6, (7→(8∧9)), (a→b)], [0]]", "logic_conclusion": "[c, 1]", "correspondance": [{"0": "X is a person who has a wedding .", "1": "X is a people who has at least one child .", "2": "X is a person who travels to Paris for their honeymoon .", "3": "X is a people who has a wedding .", "4": "X is a wedding that occurs in July .", "5": "X belongs to people who travels to Paris for their honeymoon .", "6": "Some weddings in July are well - attended .", "7": "John has at least one child .", "8": "John does not travel to Paris for John 's honeymoon .", "9": "John does not have a wedding .", "a": "John has a wedding that is well - attended .", "b": "John has a wedding in July or , if not , then John travels to Paris for their honeymoon .", "c": "John does not have a wedding .", "d": "Paris is a person who has a wedding .", "e": "Paris is a people who has at least one child .", "f": "July is a person who has a wedding .", "g": "July is a people who has at least one child .", "h": "John is a person who has a wedding .", "i": "John is a people who has at least one child .", "j": "Paris is a person who travels to Paris for their honeymoon .", "k": "Paris is a people who has a wedding .", "l": "July is a person who travels to Paris for their honeymoon .", "m": "July is a people who has a wedding .", "n": "John is a person who travels to Paris for their honeymoon .", "o": "John is a people who has a wedding .", "p": "Paris is a wedding that occurs in July .", "q": "Paris belongs to people who travels to Paris for their honeymoon .", "r": "July is a wedding that occurs in July .", "s": "July belongs to people who travels to Paris for their honeymoon .", "t": "John is a wedding that occurs in July .", "u": "John belongs to people who travels to Paris for their honeymoon ."}, {"0": "John does not have a wedding .", "1": "John does not have at least one child ."}], "errors": [[]], "entailments_dict": [{"b": ["n", "h", "r", "c", "(¬8)"], "u": ["n", "h", "(¬9)", "(¬8)"], "m": ["f"], "o": ["h", "(¬9)"], "i": ["7"], "q": ["n"], "k": ["d"], "9": ["c", "(¬o)"], "8": ["(¬u)"], "c": ["(¬o)"], "(¬c)": ["h", "a"]}, {}], "predicted_steps": [false, false]}
{"text": "All people who have a wedding are people who have at least one child. All people who travel to Paris for their honeymoon are people who have a wedding. All weddings that occur in July belong to people who travel to Paris for their honeymoon. Some weddings in July are well-attended. If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding. If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that John has neither a wedding that is well-attended nor does he travel to Paris for his honeymoon?", "id": "131", "ground_truth": "True", "reasoning": " Here is my reasoning:\n\nPremise 1.1: All people who have a wedding are people who have at least one child.\nPremise 1.2: All people who travel to Paris for their honeymoon are people who have a wedding.\nConclusion 1: People who travel to Paris for their honeymoon have at least one child.\n\nPremise 2.1: All weddings that occur in July belong to people who travel to Paris for their honeymoon.\nPremise 2.2: Some weddings in July are well-attended.\nConclusion 2: Some people who travel to Paris for their honeymoon have a wedding in July.\n\nPremise 3.1: If John has at least one child, then John does not travel to Paris for his honeymoon and does not have a wedding.\nPremise 3.2: If John has a wedding that is well-attended, then John has a wedding in July or, if not, then John travels to Paris for their honeymoon.\nConclusion 3: If John has a child, then John does not have a wedding in July and does not travel to Paris for his honeymoon.\n\nPremise 4.1: John has a child.\nConclusion 4: John does not have a wedding in July and does not travel to Paris for his honeymoon.\n\nTherefore, the answer is A. Yes, it is true that John has neither a wedding that is well-attended nor does he travel to Paris for his honeymoon.", "logic_premises": "[[(0→1), (2→3)], [((5→6)∪(7→8)), 2], [(0→(1∧2)), (3→4)], [0]]", "logic_conclusion": "[(4→5), ((9→a)∪(b→c)), (5→(6∧7)), (1∧2)]", "correspondance": [{"0": "X is a person who has a wedding .", "1": "X is a people who has at least one child .", "2": "X is a person who travels to Paris for their honeymoon .", "3": "X is a people who has a wedding .", "4": "X is a person who travels to Paris for their honeymoon .", "5": "X has at least one child ."}, {"0": "X is a wedding that occurs in July .", "1": "X belongs to people who travels to Paris for their honeymoon .", "2": "Some weddings in July are well - attended .", "3": "X is Some a person who travels to Paris for their honeymoon .", "4": "X has a wedding in July .", "5": "Paris is a wedding that occurs in July .", "6": "Paris belongs to people who travels to Paris for their honeymoon .", "7": "July is a wedding that occurs in July .", "8": "July belongs to people who travels to Paris for their honeymoon .", "9": "Paris is Some a person who travels to Paris for their honeymoon .", "a": "Paris has a wedding in July .", "b": "July is Some a person who travels to Paris for their honeymoon .", "c": "July has a wedding in July ."}, {"0": "John has at least one child .", "1": "John does not travel to Paris for John 's honeymoon .", "2": "John does not have a wedding .", "3": "John has a wedding that is well - attended .", "4": "John has a wedding in July or , if not , then John travels to Paris for his honeymoon .", "5": "John has a child .", "6": "John does not have a wedding in July .", "7": "John does not travel to Paris for John 's honeymoon ."}, {"0": "John has a child .", "1": "John does not have a wedding in July .", "2": "John does not travel to Paris for John 's honeymoon ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["0", "2"], "1": ["5"]}, {}, {"5": ["0"], "1": ["7"], "2": ["6"], "4": ["6", "(¬1)"]}, {}], "predicted_steps": [true, false, true, false]}
{"text": "[BG] Some mammals have teeth. Platypus have no teeth. Platypus are mammals. Humans have teeth.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Platypus are mammals with no teeth?", "id": "132", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Some mammals have teeth.\nPremise 1.2: Platypus have no teeth.\nConclusion 1: Platypus are mammals without teeth.\nPremise 2.1: Platypus are mammals.\nPremise 2.2: Humans have teeth.\nConclusion 2: Humans are mammals with teeth.\nPremise 3.1: Platypus are mammals without teeth.\nPremise 3.2: Humans are mammals with teeth.\nConclusion 3: Platypus and humans are different in terms of teeth.\nConclusion 4: The statement \"Platypus are mammals with no teeth\" is true.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, (4→5)], [0, (5→6)], [0, (6→7)]]", "logic_conclusion": "[3, (7→8), ((8∧9)→a)]", "correspondance": [{"0": "Some mammals have teeth .", "1": "X is a tooth .", "2": "Platypus does not have X .", "3": "Platypus are mammals without teeth .", "4": "Platypus is a tooth .", "5": "Platypus does not have Platypus ."}, {"0": "Platypus are mammals .", "1": "X is a Human .", "2": "X has teeth .", "3": "X is a Human .", "4": "X is a mammal with teeth .", "5": "Platypus is a Human .", "6": "Platypus has teeth .", "7": "Platypus is a Human .", "8": "Platypus is a mammal with teeth ."}, {"0": "Platypus are mammals without teeth .", "1": "X is a Human .", "2": "X is a mammal with teeth .", "3": "X is Platypus .", "4": "X is a human .", "5": "X is different in a term of teeth .", "6": "Platypus is a Human .", "7": "Platypus is a mammal with teeth .", "8": "Platypus is Platypus .", "9": "Platypus is a human .", "a": "Platypus is different in a term of teeth ."}], "errors": [[]], "entailments_dict": [{"3": ["(¬5)"]}, {"7": ["5", "(¬6)"], "0": ["8"], "6": ["8"]}, {"9": ["6", "(¬0)"], "0": ["a", "(¬7)"], "7": ["a", "(¬0)"], "8": ["0"], "(¬a)": ["0"]}], "predicted_steps": [false, "Contradiction in the premises", false]}
{"text": "[BG] Some mammals have teeth. Platypus have no teeth. Platypus are mammals. Humans have teeth.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Platypus are reptiles?", "id": "133", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Some mammals have teeth.\nPremise 1.2: Platypus have no teeth.\nConclusion 1: Platypus are not mammals.\n\nPremise 2.1: Platypus are mammals.\nConclusion 2: False.\n\nPremise 3.1: Humans have teeth.\nConclusion 3: Humans are mammals.\n\nPremise 4.1: Platypus are not mammals.\nPremise 4.2: Humans are mammals.\nConclusion 4: Platypus are not humans.\n\nPremise 5.1: Platypus are not reptiles.\nConclusion 5: False.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, (4→5)], [0], [(0→1)], [0, (5→6)], [(0→1)]]", "logic_conclusion": "[3, 1, (2→3), (7→8), 2]", "correspondance": [{"0": "Some mammals have teeth .", "1": "X is a tooth .", "2": "Platypus does not have X .", "3": "Platypus are not mammals .", "4": "Platypus is a tooth .", "5": "Platypus does not have Platypus ."}, {"0": "Platypus are mammals .", "1": "False ."}, {"0": "X is a Human .", "1": "X has teeth .", "2": "X is a Human .", "3": "X is a mammal ."}, {"0": "Platypus are not mammals .", "1": "X is a Human .", "2": "X is a mammal .", "3": "X is a Platypus .", "4": "X is not a human .", "5": "Platypus is a Human .", "6": "Platypus is a mammal .", "7": "Platypus is a Platypus .", "8": "Platypus is not a human ."}, {"0": "X is a Platypus .", "1": "X is not a reptile .", "2": "False ."}], "errors": [[]], "entailments_dict": [{"(¬3)": ["0"]}, {}, {"2": ["0"], "1": ["3"]}, {"6": ["8", "(¬0)"], "0": ["(¬6)"], "7": ["(¬0)"], "(¬5)": ["0"]}, {}], "predicted_steps": [false, false, true, false, false]}
{"text": "[BG] Some mammals have teeth. Platypus have no teeth. Platypus are mammals. Humans have teeth.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Humans are mammals?", "id": "134", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Some mammals have teeth.\nPremise 1.2: Platypus have no teeth.\nConclusion 1: Platypus are not mammals with teeth.\nPremise 2.1: Platypus are mammals.\nConclusion 2: Platypus are mammals without teeth.\nPremise 3.1: Humans have teeth.\nConclusion 3: Humans are mammals with teeth.\nPremise 4.1: Humans are mammals with teeth.\nConclusion 4: Humans are mammals.\n\nTherefore, the answer is A. Yes. It is true that humans are mammals.", "logic_premises": "[[0, (1→2)], [0], [(0→1)], [(0→1)]]", "logic_conclusion": "[(3→4), 1, (2→3), (2→3)]", "correspondance": [{"0": "Some mammals have teeth .", "1": "X is a tooth .", "2": "Platypus does not have X .", "3": "X is a Platypus .", "4": "X is not a mammal with teeth ."}, {"0": "Platypus are mammals .", "1": "Platypus are mammals without teeth ."}, {"0": "X is a Human .", "1": "X has teeth .", "2": "X is a Human .", "3": "X is a mammal with teeth ."}, {"0": "X is a human .", "1": "X is a mammal with teeth .", "2": "X is a human .", "3": "X is a mammal ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "(¬2)"], "2": ["4"], "(¬4)": ["0"]}, {"1": ["0"], "0": ["1"]}, {"2": ["0"], "1": ["3"]}, {"2": ["0"], "1": ["3"]}], "predicted_steps": [false, true, true, true]}
{"text": "Plungers suck. Vacuums suck. Vampires suck. Space is a vacuum. A duster is a household appliance that doesn't suck.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Space sucks?", "id": "135", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Vacuums suck.\nPremise 1.2: Space is a vacuum.\nConclusion 1: Space sucks.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X is a Vacuum .", "1": "X sucks .", "2": "Space is a vacuum .", "3": "Space sucks ."}], "errors": [[]], "entailments_dict": [{}], "predicted_steps": [false]}
{"text": "Plungers suck. Vacuums suck. Vampires suck. Space is a vacuum. A duster is a household appliance that doesn't suck.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Space is a vampire?", "id": "136", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Vampires suck.\nPremise 1.2: Space is a vacuum.\nConclusion 1: Space does not suck.\n\nPremise 2.1: A duster is a household appliance that doesn't suck.\nPremise 2.2: A duster is not a vampire.\nConclusion 2: A duster is not a vampire.\n\nPremise 3.1: Vampires are not household appliances.\nConclusion 3: Vampires are not dusters.\n\nPremise 4.1: Space is not a vampire.\nConclusion 4: Space is not a vampire.\n\nTherefore, the answer is B. No.", "logic_premises": "[[(0→1), 2], [(0→1), (2→3)], [(0→1)], [0]]", "logic_conclusion": "[3, (4→5), (2→3), 1]", "correspondance": [{"0": "X is a Vampire .", "1": "X sucks .", "2": "Space is a vacuum .", "3": "Space does not suck ."}, {"0": "X is A duster", "1": "X is a household appliance that does n't suck .", "2": "X is A duster", "3": "X is not a vampire .", "4": "X is A duster", "5": "X is not a vampire ."}, {"0": "X is a Vampire .", "1": "X is not household an appliance .", "2": "X is a Vampire .", "3": "X is not a duster ."}, {"0": "Space is not a vampire .", "1": "Space is not a vampire ."}], "errors": [[]], "entailments_dict": [{}, {"4": ["0", "2"], "3": ["5"]}, {"2": ["0"], "1": ["3"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [false, true, true, true]}
{"text": "Plungers suck. Vacuums suck. Vampires suck. Space is a vacuum. A duster is a household appliance that doesn't suck.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If something is a household appliance, it sucks?", "id": "137", "ground_truth": "False", "reasoning": " Here is my reasoning:\n\nPremise 1.1: Plungers suck.\nPremise 1.2: Vacuums suck.\nPremise 1.3: Vampires suck.\nPremise 1.4: Space is a vacuum.\nPremise 1.5: A duster is a household appliance that doesn't suck.\n\nConclusion 1: It is not true that if something is a household appliance, it sucks.\n\nExplanation:\nThe premises list various things that suck, including plungers, vacuums, and vampires. However, the duster, which is a household appliance, does not suck. This contradicts the notion that all household appliances suck. Therefore, the conclusion is that it is not true that if something is a household appliance, it sucks.\n\nAnswer: B. No", "logic_premises": "[[(0→1), (2→3), (4→5), 6, (7→8)]]", "logic_conclusion": "[(9→a)]", "correspondance": [{"0": "X is a Plunger .", "1": "X sucks .", "2": "X is a Vacuum .", "3": "X sucks .", "4": "X is a Vampire .", "5": "X sucks .", "6": "Space is a vacuum .", "7": "X is A duster", "8": "X is a household appliance that does n't suck .", "9": "It is not true that X is a household appliance .", "a": "It is not true that X sucks ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "(¬8)"], "5": ["2", "0", "(¬8)"], "1": ["2", "(¬8)"], "8": ["a", "(¬1)", "(¬3)", "(¬5)"], "(¬a)": ["0", "2"]}], "predicted_steps": [false]}
{"text": "Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning. Unsupervised learning doesn't require labelled data. The state-of-the-art text summarization model is trained with machine learning algorithms. Reinforcement learning is not used to train the state-of-the-art text summarization model. The Machine Learning algorithm for training text summarization model requires labelled data.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Supervised learning is used to train the state-of-the-art text summarization model?", "id": "138", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.\nPremise 1.2: Unsupervised learning doesn't require labelled data.\nPremise 1.3: The state-of-the-art text summarization model is trained with machine learning algorithms.\nPremise 2.1: Reinforcement learning is not used to train the state-of-the-art text summarization model.\nPremise 2.2: The Machine Learning algorithm for training text summarization model requires labelled data.\nConclusion 1: The state-of-the-art text summarization model is trained with supervised learning.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0∧(1∧2)), 3, 4, 5, 6]]", "logic_conclusion": "[7]", "correspondance": [{"0": "Machine Learning algorithms can be categorized as supervised learning .", "1": "Machine Learning algorithms can be categorized as unsupervised learning .", "2": "Machine Learning algorithms can be categorized as reinforcement learning .", "3": "Unsupervised learning does n't require labelled data .", "4": "The state - of - the - art text summarization model is trained with machine learning algorithms .", "5": "Reinforcement learning is not used to train The state - of - the - art text summarization model .", "6": "The Machine Learning algorithm for training text summarization model requires labelled data .", "7": "The state - of - the - art text summarization model is trained with supervised learning ."}], "errors": [[]], "entailments_dict": [{"4": ["6", "(¬5)"], "6": ["0", "7", "(¬3)"], "1": ["3"], "7": ["0", "4", "5", "6"], "0": ["7"], "3": ["(¬0)"], "(¬3)": ["6"], "(¬4)": ["5"], "(¬5)": ["4"], "(¬7)": ["5"]}], "predicted_steps": ["Contradiction in the premises"]}
{"text": "Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning. Unsupervised learning doesn't require labelled data. The state-of-the-art text summarization model is trained with machine learning algorithms. Reinforcement learning is not used to train the state-of-the-art text summarization model. The Machine Learning algorithm for training text summarization model requires labelled data.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Unsupervised learning is used to train the state-of-the-art text summarization model?", "id": "139", "ground_truth": "False", "reasoning": " No.\n\nPremise 1: Machine Learning algorithms can be categorized as supervised learning, unsupervised learning, and reinforcement learning.\nPremise 2: Unsupervised learning doesn't require labelled data.\nPremise 3: The state-of-the-art text summarization model is trained with machine learning algorithms.\nPremise 4: Reinforcement learning is not used to train the state-of-the-art text summarization model.\nPremise 5: The Machine Learning algorithm for training text summarization model requires labelled data.\nConclusion: Unsupervised learning is not used to train the state-of-the-art text summarization model.\n\nTherefore, the answer is B. No.", "logic_premises": "[[(0∧(1∧2)), 3, 4, 5, 6]]", "logic_conclusion": "[7]", "correspondance": [{"0": "Machine Learning algorithms can be categorized as supervised learning .", "1": "Machine Learning algorithms can be categorized as unsupervised learning .", "2": "Machine Learning algorithms can be categorized as reinforcement learning .", "3": "Unsupervised learning does n't require labelled data .", "4": "The state - of - the - art text summarization model is trained with machine learning algorithms .", "5": "Reinforcement learning is not used to train The state - of - the - art text summarization model .", "6": "The Machine Learning algorithm for training text summarization model requires labelled data .", "7": "Unsupervised learning is not used to train The state - of - the - art text summarization model ."}], "errors": [[]], "entailments_dict": [{"4": ["6", "(¬5)"], "6": ["0", "(¬3)"], "1": ["3"], "7": ["5"], "5": ["7"], "3": ["(¬0)"], "(¬3)": ["6"], "(¬4)": ["5"], "(¬5)": ["4"], "(¬7)": ["4", "5"]}], "predicted_steps": ["Contradiction in the premises"]}
{"text": "If a cartoon character is funny, then it is popular. If a cartoon character is ugly, then it is not popular. If a cartoon character is loved by children, then it is funny. If a cartoon character is from The Simpsons, then it is loved by children. If a cartoon character is yellow, then it is from The Simpsons. Ben is either from The Simpsons or funny.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Ben is loved by children?", "id": "140", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a cartoon character is funny, then it is popular.\nPremise 1.2: If a cartoon character is ugly, then it is not popular.\nPremise 2.1: If a cartoon character is loved by children, then it is funny.\nPremise 2.2: If a cartoon character is from The Simpsons, then it is loved by children.\nPremise 3.1: If a cartoon character is yellow, then it is from The Simpsons.\nPremise 3.2: Ben is either from The Simpsons or funny.\n\nConclusion 1: Ben is either funny or from The Simpsons.\n\nPremise 4.1: If Ben is from The Simpsons, then it is loved by children.\nPremise 4.2: Ben is either from The Simpsons or funny.\nConclusion 2: Ben is loved by children.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(((h∧i)→j)∪((k∧l)→m)), (((n∧o)→p)∪((q∧r)→s)), (((t∧u)→v)∪((w∧x)→y)), (((z∧A)→B)∪((C∧D)→E)), (((F∧G)→H)∪((I∧J)→K)), f], [(0→1), 2]]", "logic_conclusion": "[g, 3]", "correspondance": [{"0": "X is a cartoon character", "1": "X is funny .", "2": "X is popular .", "3": "X is a cartoon character", "4": "X is ugly .", "5": "X is not popular .", "6": "X is a cartoon character", "7": "X is loved by children .", "8": "X is funny .", "9": "X is a cartoon character", "a": "X is from The Simpsons .", "b": "X is loved by children .", "c": "X is a cartoon character", "d": "X is yellow .", "e": "X is from The Simpsons .", "f": "Ben is either from The Simpsons or funny .", "g": "Ben is either funny or from The Simpsons .", "h": "The Simpsons is a cartoon character", "i": "The Simpsons is funny .", "j": "The Simpsons is popular .", "k": "Ben is a cartoon character", "l": "Ben is funny .", "m": "Ben is popular .", "n": "The Simpsons is a cartoon character", "o": "The Simpsons is ugly .", "p": "The Simpsons is not popular .", "q": "Ben is a cartoon character", "r": "Ben is ugly .", "s": "Ben is not popular .", "t": "The Simpsons is a cartoon character", "u": "The Simpsons is loved by children .", "v": "The Simpsons is funny .", "w": "Ben is a cartoon character", "x": "Ben is loved by children .", "y": "Ben is funny .", "z": "The Simpsons is a cartoon character", "A": "The Simpsons is from The Simpsons .", "B": "The Simpsons is loved by children .", "C": "Ben is a cartoon character", "D": "Ben is from The Simpsons .", "E": "Ben is loved by children .", "F": "The Simpsons is a cartoon character", "G": "The Simpsons is yellow .", "H": "The Simpsons is from The Simpsons .", "I": "Ben is a cartoon character", "J": "Ben is yellow .", "K": "Ben is from The Simpsons ."}, {"0": "Ben is from The Simpsons .", "1": "Ben is loved by children .", "2": "Ben is either from The Simpsons or funny .", "3": "Ben is loved by children ."}], "errors": [[]], "entailments_dict": [{"B": ["u"], "H": ["h", "z", "A", "t", "n"], "y": ["l"], "K": ["k", "C", "f", "D", "w", "q", "g"], "f": ["k", "C", "w", "I", "D", "q", "g"], "E": ["x"], "v": ["i"], "g": ["l", "k", "q", "w", "D", "C", "I", "f"], "p": ["(¬j)"], "m": ["(¬s)"], "j": ["(¬p)"], "s": ["(¬m)"]}, {"2": ["0"], "1": ["3"]}], "predicted_steps": [true, true]}
{"text": "If a cartoon character is funny, then it is popular. If a cartoon character is ugly, then it is not popular. If a cartoon character is loved by children, then it is funny. If a cartoon character is from The Simpsons, then it is loved by children. If a cartoon character is yellow, then it is from The Simpsons. Ben is either from The Simpsons or funny.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Ben is ugly or yellow?", "id": "141", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a cartoon character is funny, then it is popular.\nPremise 1.2: If a cartoon character is ugly, then it is not popular.\nConclusion 1: If a cartoon character is funny, then it is not ugly.\n\nPremise 2.1: If a cartoon character is loved by children, then it is funny.\nPremise 2.2: If a cartoon character is from The Simpsons, then it is loved by children.\nConclusion 2: If a cartoon character is from The Simpsons, then it is funny.\n\nPremise 3.1: If a cartoon character is yellow, then it is from The Simpsons.\nPremise 3.2: Ben is either from The Simpsons or funny.\nConclusion 3: If Ben is yellow, then he is from The Simpsons and funny.\n\nPremise 4.1: Ben is either from The Simpsons or funny.\nPremise 4.2: Ben is not yellow.\nConclusion 4: Ben is not from The Simpsons.\n\nPremise 5.1: Ben is not from The Simpsons.\nConclusion 5: Ben is funny.\n\nTherefore, the answer is B. No. It is not true that Ben is ugly or yellow.", "logic_premises": "[[((0∧1)→2), ((3∧4)→5)], [((0∧1)→2), ((3∧4)→5)], [(((6∧7)→8)∪((9∧a)→b)), 3], [0, 1], [0]]", "logic_conclusion": "[((6∧7)→8), ((6∧7)→8), (4→5), 2, 1]", "correspondance": [{"0": "X is a cartoon character", "1": "X is funny .", "2": "X is popular .", "3": "X is a cartoon character", "4": "X is ugly .", "5": "X is not popular .", "6": "X is a cartoon character", "7": "X is funny .", "8": "X is not ugly ."}, {"0": "X is a cartoon character", "1": "X is loved by children .", "2": "X is funny .", "3": "X is a cartoon character", "4": "X is from The Simpsons .", "5": "X is loved by children .", "6": "X is a cartoon character", "7": "X is from The Simpsons .", "8": "X is funny ."}, {"0": "X is a cartoon character", "1": "X is yellow .", "2": "X is from The Simpsons .", "3": "Ben is either from The Simpsons or funny .", "4": "Ben is yellow .", "5": "Ben is from The Simpsons and funny .", "6": "The Simpsons is a cartoon character", "7": "The Simpsons is yellow .", "8": "The Simpsons is from The Simpsons .", "9": "Ben is a cartoon character", "a": "Ben is yellow .", "b": "Ben is from The Simpsons ."}, {"0": "Ben is either from The Simpsons or funny .", "1": "Ben is not yellow .", "2": "Ben is not from The Simpsons ."}, {"0": "Ben is not from The Simpsons .", "1": "Ben is funny ."}], "errors": [[]], "entailments_dict": [{"7": ["1"], "6": ["0", "3"], "5": ["(¬2)"], "2": ["(¬5)"], "(¬8)": ["4"]}, {"5": ["1"], "7": ["0", "4", "3"], "6": ["1", "0", "3"], "2": ["8"]}, {"3": ["9", "5"], "b": ["3", "5"], "4": ["a"]}, {"(¬2)": ["0"]}, {}], "predicted_steps": [false, true, false, false, false]}
{"text": "If a cartoon character is funny, then it is popular. If a cartoon character is ugly, then it is not popular. If a cartoon character is loved by children, then it is funny. If a cartoon character is from The Simpsons, then it is loved by children. If a cartoon character is yellow, then it is from The Simpsons. Ben is either from The Simpsons or funny.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Ben is either yellow and ugly or neither yellow nor ugly?", "id": "142", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a cartoon character is funny, then it is popular.\nPremise 1.2: If a cartoon character is ugly, then it is not popular.\nConclusion 1: If a cartoon character is funny, then it is not ugly.\n\nPremise 2.1: If a cartoon character is loved by children, then it is funny.\nPremise 2.2: If a cartoon character is from The Simpsons, then it is loved by children.\nConclusion 2: If a cartoon character is from The Simpsons, then it is funny.\n\nPremise 3.1: If a cartoon character is yellow, then it is from The Simpsons.\nPremise 3.2: Ben is either from The Simpsons or funny.\nConclusion 3: Ben is either yellow or funny.\n\nPremise 4.1: Ben is either yellow or funny.\nPremise 4.2: If a cartoon character is yellow, then it is not ugly.\nConclusion 4: Ben is not ugly.\n\nPremise 5.1: Ben is not ugly.\nConclusion 5: A. Yes\n\nTherefore, the answer is A. Yes. It is true that Ben is either yellow and ugly or neither yellow nor ugly.", "logic_premises": "[[((0∧1)→2), ((3∧4)→5)], [((0∧1)→2), ((3∧4)→5)], [(((6∧7)→8)∪((9∧a)→b)), 3], [(0⊻1), ((6∧7)→8)], []]", "logic_conclusion": "[((6∧7)→8), ((6∧7)→8), (4⊻5), 5, '-1']", "correspondance": [{"0": "X is a cartoon character", "1": "X is funny .", "2": "X is popular .", "3": "X is a cartoon character", "4": "X is ugly .", "5": "X is not popular .", "6": "X is a cartoon character", "7": "X is funny .", "8": "X is not ugly ."}, {"0": "X is a cartoon character", "1": "X is loved by children .", "2": "X is funny .", "3": "X is a cartoon character", "4": "X is from The Simpsons .", "5": "X is loved by children .", "6": "X is a cartoon character", "7": "X is from The Simpsons .", "8": "X is funny ."}, {"0": "X is a cartoon character", "1": "X is yellow .", "2": "X is from The Simpsons .", "3": "Ben is either from The Simpsons or funny .", "4": "Ben is yellow .", "5": "Ben is funny .", "6": "The Simpsons is a cartoon character", "7": "The Simpsons is yellow .", "8": "The Simpsons is from The Simpsons .", "9": "Ben is a cartoon character", "a": "Ben is yellow .", "b": "Ben is from The Simpsons ."}, {"0": "Ben is yellow .", "1": "Ben is funny .", "2": "X is a cartoon character", "3": "X is yellow .", "4": "X is not ugly .", "5": "Ben is not ugly .", "6": "Ben is a cartoon character", "7": "Ben is yellow .", "8": "Ben is not ugly ."}, {"0": "Ben is not ugly ."}], "errors": ["Logic Transform Error -  Step n°: 4 The given 'sentence' contains more than one sentence. A ConstituentTree object can process only one sentence at a time.", ["Entailments Error -  Step n°: 4 'str' object has no attribute 'get_variables_implications'"]], "entailments_dict": [{"7": ["1"], "6": ["0", "3"], "5": ["(¬2)"], "2": ["(¬5)"], "(¬8)": ["4"]}, {"5": ["1"], "7": ["0", "4", "3"], "6": ["1", "0", "3"], "2": ["8"]}, {"3": ["9"], "b": ["3"], "4": ["a"]}, {"0": ["7"], "8": ["5"]}, {}], "predicted_steps": [false, true, false, false, false]}
{"text": "Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals. Heck cattle were bred-back in the 1920s to resemble the aurochs. [BG] Heck cattle are animals. [BG] Aurochs are animals. Some animals to be bred-back resemble animals that are extinct.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Some Heck cattle are artificially selected?", "id": "143", "ground_truth": "True", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: Breeding back is a form of artificial selection.\nPremise 1.2: Heck cattle were bred-back in the 1920s.\nConclusion 1: Heck cattle were artificially selected.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, 1]]", "logic_conclusion": "[2]", "correspondance": [{"0": "Breeding back is a form of artificial selection .", "1": "Heck cattle were bred - back in the 1920s .", "2": "Heck cattle were artificially selected ."}], "errors": [[]], "entailments_dict": [{"1": ["0", "2"], "0": ["1", "2"], "2": ["0", "1"]}], "predicted_steps": [true]}
{"text": "Breeding back is a form of artificial selection by the deliberate selective breeding of domestic animals. Heck cattle were bred-back in the 1920s to resemble the aurochs. [BG] Heck cattle are animals. [BG] Aurochs are animals. Some animals to be bred-back resemble animals that are extinct.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Aurochs are extinct?", "id": "144", "ground_truth": "Uncertain", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: Heck cattle were bred-back in the 1920s to resemble the aurochs.\nPremise 1.2: Aurochs are animals.\nConclusion 1: Aurochs are animals that can be bred-back.\nPremise 2.1: Some animals to be bred-back resemble animals that are extinct.\nConclusion 2: Aurochs may be extinct.\nPremise 3.1: Aurochs are animals that can be bred-back.\nPremise 3.2: Aurochs may be extinct.\nConclusion 3: It is uncertain whether Aurochs are extinct.\n\nTherefore, the answer is C. Uncertain.", "logic_premises": "[[], [0], []]", "logic_conclusion": "['-1', (1→2), '-1']", "correspondance": [{"0": "X is Heck a cattle .", "1": "resembles the aurochs .", "2": "X was bred - back in the 1920s .", "3": "the aurochs are animals ."}, {"0": "Some animals to be bred - back resemble animals that are extinct .", "1": "X is an Auroch .", "2": "X may is extinct ."}, {}], "errors": ["Logic Transform Error -  Step n°: 0 list index out of range", "Logic Transform Error -  Step n°: 2 list index out of range", ["Entailments Error -  Step n°: 0 'str' object has no attribute 'get_variables_implications'", "Entailments Error -  Step n°: 2 'str' object has no attribute 'get_variables_implications'"]], "entailments_dict": [{}, {"1": ["0"]}, {}], "predicted_steps": [false, false, false]}
{"text": "All students are humans. If someone studies, then they are a student. A person either studys or teaches. No young person teaches. Jerry neither teaches nor is a manager. Rose is young or a student.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Jerry is young?", "id": "145", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All students are humans.\nPremise 1.2: If someone studies, then they are a student.\nConclusion 1: If someone is a student, then they study.\n\nPremise 2.1: A person either studies or teaches.\nPremise 2.2: No young person teaches.\nConclusion 2: If someone is young, then they do not teach.\n\nPremise 3.1: Jerry neither teaches nor is a manager.\nConclusion 3: Jerry is not a teacher or a manager.\n\nPremise 4.1: Rose is young or a student.\nConclusion 4: Rose is either young or a student.\n\nPremise 5.1: Jerry is not young.\nConclusion 5: Jerry is not young.\n\nTherefore, the answer is B. No. It is not true that Jerry is young.", "logic_premises": "[[(0→1), (2→3)], [0, (1→2)], [(0∧1)], [0], [0]]", "logic_conclusion": "[(4→5), (3→4), (2∨3), 1, 1]", "correspondance": [{"0": "X is a student .", "1": "X is a human .", "2": "X studies .", "3": "X are a student .", "4": "X is a student .", "5": "X study ."}, {"0": "A person either studies or teaches .", "1": "X is a young person .", "2": "X does not teach .", "3": "X is young .", "4": "X do not teach ."}, {"0": "Jerry does not teach .", "1": "Jerry is not a manager .", "2": "Jerry is not a teacher .", "3": "Jerry is not a manager ."}, {"0": "Rose is young or a student .", "1": "Rose is either young or a student ."}, {"0": "Jerry is not young .", "1": "Jerry is not young ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"]}, {"3": ["1"], "2": ["4"], "(¬4)": ["0"]}, {"3": ["1"], "2": ["0"], "1": ["3"], "0": ["2"]}, {"1": ["0"], "0": ["1"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [true, true, true, true, true]}
{"text": "All students are humans. If someone studies, then they are a student. A person either studys or teaches. No young person teaches. Jerry neither teaches nor is a manager. Rose is young or a student.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Jerry is not young?", "id": "146", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All students are humans.\nPremise 1.2: If someone studies, then they are a student.\nConclusion 1: If someone is a student, then they study.\n\nPremise 2.1: A person either studies or teaches.\nPremise 2.2: No young person teaches.\nConclusion 2: If someone is young, then they do not teach.\n\nPremise 3.1: Jerry neither teaches nor is a manager.\nConclusion 3: Jerry is not a teacher or a manager.\n\nPremise 4.1: Rose is young or a student.\nConclusion 4: Rose is either young or a student.\n\nPremise 5.1: Jerry is not young.\nConclusion 5: Jerry is not young.\n\nTherefore, the answer is A. Yes, it is true that Jerry is not young.", "logic_premises": "[[(0→1), (2→3)], [0, (1→2)], [(0∧1)], [0], [0]]", "logic_conclusion": "[(4→5), (3→4), (2∨3), 1, 1]", "correspondance": [{"0": "X is a student .", "1": "X is a human .", "2": "X studies .", "3": "X are a student .", "4": "X is a student .", "5": "X study ."}, {"0": "A person either studies or teaches .", "1": "X is a young person .", "2": "X does not teach .", "3": "X is young .", "4": "X do not teach ."}, {"0": "Jerry does not teach .", "1": "Jerry is not a manager .", "2": "Jerry is not a teacher .", "3": "Jerry is not a manager ."}, {"0": "Rose is young or a student .", "1": "Rose is either young or a student ."}, {"0": "Jerry is not young .", "1": "Jerry is not young ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"]}, {"3": ["1"], "2": ["4"], "(¬4)": ["0"]}, {"3": ["1"], "2": ["0"], "1": ["3"], "0": ["2"]}, {"1": ["0"], "0": ["1"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [true, true, true, true, true]}
{"text": "All students are humans. If someone studies, then they are a student. A person either studys or teaches. No young person teaches. Jerry neither teaches nor is a manager. Rose is young or a student.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Rose is a human or a manager?", "id": "147", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All students are humans.\nPremise 1.2: If someone studies, then they are a student.\nConclusion 1: If someone is a student, then they are a human.\n\nPremise 2.1: A person either studies or teaches.\nPremise 2.2: No young person teaches.\nConclusion 2: If someone is young, then they either study or are a student.\n\nPremise 3.1: Jerry neither teaches nor is a manager.\nPremise 3.2: Rose is young or a student.\nConclusion 3: Rose is either a student or young.\n\nPremise 4.1: If Rose is a student, then she is a human.\nPremise 4.2: If Rose is young, then she is not a manager.\nConclusion 4: Rose is either a human or not a manager.\n\nConclusion 5: Therefore, the answer is A. Yes, it is true that Rose is a human or a manager.", "logic_premises": "[[(0→1), (2→3)], [0, (1→2)], [(0∧1), 2], [(0→1), (2→3)]]", "logic_conclusion": "[(4→5), (3→(4⊻5)), 3, (4⊻5)]", "correspondance": [{"0": "X is a student .", "1": "X is a human .", "2": "X studies .", "3": "X are a student .", "4": "X is a student .", "5": "X are a human ."}, {"0": "A person either studies or teaches .", "1": "X is a young person .", "2": "X does not teach .", "3": "X is young .", "4": "X study .", "5": "X are a student ."}, {"0": "Jerry does not teach .", "1": "Jerry is not a manager .", "2": "Rose is young or a student .", "3": "Rose is either a student or young ."}, {"0": "Rose is a student .", "1": "Rose is a human .", "2": "Rose is young .", "3": "Rose is not a manager .", "4": "Rose is a human .", "5": "Rose is a manager ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"], "1": ["5"]}, {"3": ["1"], "0": ["4"]}, {"3": ["2"], "2": ["3"]}, {"1": ["4"], "5": ["(¬3)"]}], "predicted_steps": [true, false, true, false]}
{"text": "All students are humans. If someone studies, then they are a student. A person either studys or teaches. No young person teaches. Jerry neither teaches nor is a manager. Rose is young or a student.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Rose is a human or Jerry is a manager?", "id": "148", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All students are humans.\nPremise 1.2: If someone studies, then they are a student.\nConclusion 1: If someone is a student, then they are a human.\n\nPremise 2.1: A person either studies or teaches.\nPremise 2.2: No young person teaches.\nConclusion 2: If a person is young, then they either study or are a student.\n\nPremise 3.1: Jerry neither teaches nor is a manager.\nPremise 3.2: Rose is young or a student.\nConclusion 3: Jerry is not a manager.\n\nPremise 4.1: Rose is young or a student.\nPremise 4.2: If Rose is young, then she either studies or is a student.\nConclusion 4: Rose is a student.\n\nPremise 5.1: Rose is a student.\nConclusion 5: B. No, it is not true that Rose is a human.\n\nTherefore, the answer is B. No.", "logic_premises": "[[(0→1), (2→3)], [0, (1→2)], [(0∧1), 2], [0, (1→(2⊻3))], [0]]", "logic_conclusion": "[(4→5), ((3∧4)→(5⊻6)), 3, 4, 1]", "correspondance": [{"0": "X is a student .", "1": "X is a human .", "2": "X studies .", "3": "X are a student .", "4": "X is a student .", "5": "X are a human ."}, {"0": "A person either studies or teaches .", "1": "X is a young person .", "2": "X does not teach .", "3": "X is a person", "4": "X is young .", "5": "X study .", "6": "X are a student ."}, {"0": "Jerry does not teach .", "1": "Jerry is not a manager .", "2": "Rose is young or a student .", "3": "Jerry is not a manager ."}, {"0": "Rose is young or a student .", "1": "Rose is young .", "2": "Rose studies .", "3": "Rose is a student .", "4": "Rose is a student ."}, {"0": "Rose is a student .", "1": "B. No , it is not true that Rose is a human ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"], "1": ["5"]}, {"4": ["1"], "3": ["0"], "0": ["5"]}, {"3": ["1"], "1": ["3"]}, {"0": ["1", "4"], "3": ["0", "4"], "4": ["0"], "2": ["4"]}, {}], "predicted_steps": [true, false, true, true, false]}
{"text": "All students are humans. If someone studies, then they are a student. A person either studys or teaches. No young person teaches. Jerry neither teaches nor is a manager. Rose is young or a student.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that It is not true that Rose is a student and Jerry is a human?", "id": "149", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All students are humans.\nPremise 1.2: If someone studies, then they are a student.\nConclusion 1: If someone is a student, then they study.\n\nPremise 2.1: A person either studies or teaches.\nPremise 2.2: No young person teaches.\nConclusion 2: If someone is young, then they do not teach.\n\nPremise 3.1: Jerry neither teaches nor is a manager.\nPremise 3.2: Rose is young or a student.\nConclusion 3: Jerry is not a student.\n\nPremise 4.1: If Rose is young, then she does not teach.\nPremise 4.2: Rose is young or a student.\nConclusion 4: Rose is a student.\n\nPremise 5.1: It is not true that Rose is a student and Jerry is a human.\nConclusion 5: It is true that Rose is a student and Jerry is not a human.\n\nTherefore, the answer is B. No. It is not true that Rose is a student and Jerry is a human.", "logic_premises": "[[(0→1), (2→3)], [0, (1→2)], [(0∧1), 2], [(0→1), 2], [(0∧1)]]", "logic_conclusion": "[(4→5), (3→4), 3, 3, (2∧3)]", "correspondance": [{"0": "X is a student .", "1": "X is a human .", "2": "X studies .", "3": "X are a student .", "4": "X is a student .", "5": "X study ."}, {"0": "A person either studies or teaches .", "1": "X is a young person .", "2": "X does not teach .", "3": "X is young .", "4": "X do not teach ."}, {"0": "Jerry does not teach .", "1": "Jerry is not a manager .", "2": "Rose is young or a student .", "3": "Jerry is not a student ."}, {"0": "Rose is young .", "1": "Rose does not teach .", "2": "Rose is young or a student .", "3": "Rose is a student ."}, {"0": "It is not true that Rose is a student .", "1": "It is not true that Jerry is a human .", "2": "It is true that Rose is a student .", "3": "It is true that Jerry is not a human ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"]}, {"3": ["1"], "2": ["4"], "(¬4)": ["0"]}, {"(¬3)": ["0"]}, {"2": ["0", "3"], "3": ["2"]}, {"3": ["1"], "1": ["3"], "2": ["(¬0)"], "(¬2)": ["0"]}], "predicted_steps": [true, true, false, true, false]}
{"text": "New Vessel Press is a publishing house which specializes in translating foreign literature into English. All of New Vessel Press's published books are in English. Neapolitan Chronicles is a book published by New Vessel Press. Neapolitan Chronicles was translated from Italian. Palace of Flies is a book published by New Vessel Press.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Neapolitan Chronicles is an English book?", "id": "150", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All books published by New Vessel Press are in English.\nPremise 1.2: Neapolitan Chronicles is a book published by New Vessel Press.\nConclusion 1: Neapolitan Chronicles is in English.\n\nPremise 2.1: Neapolitan Chronicles was translated from Italian.\nPremise 2.2: A book translated from another language is not originally in English.\nConclusion 2: Neapolitan Chronicles is not originally in English.\n\nPremise 3.1: Palace of Flies is a book published by New Vessel Press.\nPremise 3.2: All books published by New Vessel Press are in English.\nConclusion 3: Palace of Flies is in English.\n\nPremise 4.1: Neapolitan Chronicles was translated from Italian.\nPremise 4.2: Palace of Flies is in English.\nConclusion 4: Neapolitan Chronicles is not in English.\n\nConclusion 5: The answer is B. No, Neapolitan Chronicles is not an English book.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [0, 1], [0, ((4→5)∪((6→7)∪(8→9)))], [0, 1]]", "logic_conclusion": "[3, 2, 3, 2]", "correspondance": [{"0": "X is a book published by New Vessel Press .", "1": "X is in English .", "2": "Neapolitan Chronicles is a book published by New Vessel Press .", "3": "Neapolitan Chronicles is in English .", "4": "New Vessel Press is a book published by New Vessel Press .", "5": "New Vessel Press is in English .", "6": "English is a book published by New Vessel Press .", "7": "English is in English .", "8": "Neapolitan Chronicles is a book published by New Vessel Press .", "9": "Neapolitan Chronicles is in English ."}, {"0": "Neapolitan Chronicles was translated from Italian .", "1": "A book translated from another language is not originally in English .", "2": "Neapolitan Chronicles is not originally in English ."}, {"0": "Palace of Flies is a book published by New Vessel Press .", "1": "X is a book published by New Vessel Press .", "2": "X is in English .", "3": "Palace of Flies is in English .", "4": "New Vessel Press is a book published by New Vessel Press .", "5": "New Vessel Press is in English .", "6": "Palace of Flies is a book published by New Vessel Press .", "7": "Palace of Flies is in English .", "8": "English is a book published by New Vessel Press .", "9": "English is in English ."}, {"0": "Neapolitan Chronicles was translated from Italian .", "1": "Palace of Flies is in English .", "2": "Neapolitan Chronicles is not in English ."}], "errors": [[]], "entailments_dict": [{"2": ["8"], "9": ["3"]}, {"1": ["0", "2"], "0": ["1", "2"], "2": ["0", "1"]}, {"0": ["6"], "7": ["3"]}, {"0": ["2"]}], "predicted_steps": [true, true, true, true]}
{"text": "New Vessel Press is a publishing house which specializes in translating foreign literature into English. All of New Vessel Press's published books are in English. Neapolitan Chronicles is a book published by New Vessel Press. Neapolitan Chronicles was translated from Italian. Palace of Flies is a book published by New Vessel Press.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry Potter was published by New Vessel Press?", "id": "151", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All books published by New Vessel Press are in English.\nPremise 1.2: Neapolitan Chronicles is a book published by New Vessel Press.\nConclusion 1: Neapolitan Chronicles is in English.\n\nPremise 2.1: Neapolitan Chronicles was translated from Italian.\nPremise 2.2: Palace of Flies is a book published by New Vessel Press.\nConclusion 2: Palace of Flies is in English.\n\nPremise 3.1: Harry Potter is not a book published by New Vessel Press.\nConclusion 3: Harry Potter was not published by New Vessel Press.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [0, 1], [0]]", "logic_conclusion": "[3, 2, 1]", "correspondance": [{"0": "X is a book published by New Vessel Press .", "1": "X is in English .", "2": "Neapolitan Chronicles is a book published by New Vessel Press .", "3": "Neapolitan Chronicles is in English .", "4": "New Vessel Press is a book published by New Vessel Press .", "5": "New Vessel Press is in English .", "6": "English is a book published by New Vessel Press .", "7": "English is in English .", "8": "Neapolitan Chronicles is a book published by New Vessel Press .", "9": "Neapolitan Chronicles is in English ."}, {"0": "Neapolitan Chronicles was translated from Italian .", "1": "Palace of Flies is a book published by New Vessel Press .", "2": "Palace of Flies is in English ."}, {"0": "Harry Potter is not a book published by New Vessel Press .", "1": "Harry Potter was not published by New Vessel Press ."}], "errors": [[]], "entailments_dict": [{"2": ["8"], "9": ["3"]}, {}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [true, false, true]}
{"text": "New Vessel Press is a publishing house which specializes in translating foreign literature into English. All of New Vessel Press's published books are in English. Neapolitan Chronicles is a book published by New Vessel Press. Neapolitan Chronicles was translated from Italian. Palace of Flies is a book published by New Vessel Press.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Palace of Flies was translated from Italian?", "id": "152", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All books published by New Vessel Press are in English.\nPremise 1.2: Neapolitan Chronicles is a book published by New Vessel Press.\nConclusion 1: Neapolitan Chronicles is in English.\n\nPremise 2.1: Neapolitan Chronicles was translated from Italian.\nPremise 2.2: Palace of Flies is a book published by New Vessel Press.\nConclusion 2: Palace of Flies was not translated from Italian.\n\nTherefore, the answer is B. No.", "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [0, 1]]", "logic_conclusion": "[3, 2]", "correspondance": [{"0": "X is a book published by New Vessel Press .", "1": "X is in English .", "2": "Neapolitan Chronicles is a book published by New Vessel Press .", "3": "Neapolitan Chronicles is in English .", "4": "New Vessel Press is a book published by New Vessel Press .", "5": "New Vessel Press is in English .", "6": "English is a book published by New Vessel Press .", "7": "English is in English .", "8": "Neapolitan Chronicles is a book published by New Vessel Press .", "9": "Neapolitan Chronicles is in English ."}, {"0": "Neapolitan Chronicles was translated from Italian .", "1": "Palace of Flies is a book published by New Vessel Press .", "2": "Palace of Flies was not translated from Italian ."}], "errors": [[]], "entailments_dict": [{"2": ["8"], "9": ["3"]}, {"2": ["1"], "(¬2)": ["1"]}], "predicted_steps": [true, false]}
{"text": "If people own a large desktop monitor at their home, then they work regularly and often at home. All people who have a fully stocked and impressive home office are people who own a large desktop monitor at their home. All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes. All people who work regularly and often at home visit the office supply store regularly. If people spend their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon. Remy either both goes to bed late and wakes up every day after noon and spends their free time tidying and organizing the spaces in their home, or they do not go to bed late and wake up every day after noon nor spend their free time tidying and organizing the spaces in their home.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Remy visits the office supply store regularly?", "id": "153", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If people own a large desktop monitor at home, they work regularly and often at home.\nPremise 1.2: All people who have a fully stocked and impressive home office are people who own a large desktop monitor at home.\nConclusion 1: People who have a fully stocked and impressive home office work regularly and often at home.\n\nPremise 2.1: All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes.\nPremise 2.2: All people who work regularly and often at home visit the office supply store regularly.\nConclusion 2: People who spend their free time tidying and organizing the spaces in their homes visit the office supply store regularly.\n\nPremise 3.1: Remy either both goes to bed late and wakes up every day after noon and spends their free time tidying and organizing the spaces in their home, or they do not go to bed late and wake up every day after noon nor spend their free time tidying and organizing the spaces in their home.\nPremise 3.2: Remy does not go to bed late and wake up every day after noon.\nConclusion 3: Remy does not spend their free time tidying and organizing the spaces in their home.\n\nPremise 4.1: If people spend their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon.\nPremise 4.2: Remy does not spend their free time tidying and organizing the spaces in their home.\nConclusion 4: Remy goes to bed late and wakes up every day after noon.\n\nPremise 5.1: Remy visits the office supply store regularly.\nConclusion 5: A. Yes, Remy visits the office supply store regularly.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), ((2∧3)→4)], [(0→1), (2→3)], [((c→(((1∧d)∧3)⊻((5∧f)∧7)))∪(g→(((1∧h)∧3)⊻((5∧j)∧7)))), ((k→(9∧l))∪(m→(9∧n)))], [((7→(8∧9))∪(a→(b∧c))), 3], [0]]", "logic_conclusion": "[((5∧6)→7), (4→5), b, ((d→(5∧e))∪(f→(5∧g))), 1]", "correspondance": [{"0": "X own a large desktop monitor at home .", "1": "X work regularly and often at home .", "2": "X is a person who has a fully stocked home office .", "3": "X is a person who has a impressive home office .", "4": "X is a people who owns a large desktop monitor at home .", "5": "X is a person who has a fully stocked home office .", "6": "X is a person who has a impressive home office .", "7": "X works regularly and often at home ."}, {"0": "X is a person who works regularly and often at home .", "1": "X spends their free time tidying and organizing the spaces in their homes .", "2": "X is a person who works regularly and often at home .", "3": "X visits the office supply store regularly .", "4": "X is a person who spends their free time tidying and organizing the spaces in their homes .", "5": "X visits the office supply store regularly ."}, {"0": "X is a day .", "1": "Remy goes to bed late .", "2": "Remy wakes up X after noon .", "3": "Remy spends Remy 's free time tidying and organizing the spaces in Remy 's home .", "4": "X is a day .", "5": "Remy does not goes to bed late .", "6": "Remy wakes up X after noon .", "7": "Remy spendses Remy 's free time tidying and organizing the spaces in Remy 's home .", "8": "X is a day .", "9": "Remy does not goes to bed late .", "a": "Remy does not wakes up X after noon .", "b": "Remy does not spend Remy 's free time tidying and organizing the spaces in Remy 's home .", "c": "Remy is a day .", "d": "Remy wakes up Remy after noon .", "e": "Remy is a day .", "f": "Remy wakes up Remy after noon .", "g": "the spaces in their home is a day .", "h": "Remy wakes up the spaces in their home after noon .", "i": "the spaces in their home is a day .", "j": "Remy wakes up the spaces in their home after noon .", "k": "Remy is a day .", "l": "Remy does not wakes up Remy after noon .", "m": "the spaces in their home is a day .", "n": "Remy does not wakes up the spaces in their home after noon ."}, {"0": "X spend people 's free time tidying and organizing the spaces in people 's home .", "1": "X do not go to bed late .", "2": "X do not wake up every day after noon .", "3": "Remy does not spend Remy 's free time tidying and organizing the spaces in Remy 's home .", "4": "X is a day .", "5": "Remy goes to bed late .", "6": "Remy wakes up X after noon .", "7": "Remy spend people 's free time tidying and organizing the spaces in people 's home .", "8": "Remy do not go to bed late .", "9": "Remy do not wake up every day after noon .", "a": "the spaces in their home spend people 's free time tidying and organizing the spaces in people 's home .", "b": "the spaces in their home do not go to bed late .", "c": "the spaces in their home do not wake up every day after noon .", "d": "Remy is a day .", "e": "Remy wakes up Remy after noon .", "f": "the spaces in their home is a day .", "g": "Remy wakes up the spaces in their home after noon ."}, {"0": "Remy visits the office supply store regularly .", "1": "A. Yes , Remy visits the office supply store regularly ."}], "errors": [[]], "entailments_dict": [{"4": ["0"], "6": ["3"], "5": ["2"], "1": ["7"]}, {"3": ["5"]}, {"n": ["b", "(¬h)", "(¬j)", "(¬d)", "(¬f)"], "1": ["(¬9)", "(¬5)", "(¬5)"], "9": ["(¬1)"], "b": ["(¬7)", "(¬3)"], "f": ["(¬l)"], "j": ["(¬n)", "(¬l)"], "l": ["(¬d)", "(¬f)"], "h": ["(¬l)", "(¬n)"], "d": ["(¬l)"]}, {"(¬g)": ["3"], "(¬a)": ["3"], "(¬7)": ["3"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [true, false, false, false, true]}
{"text": "If people own a large desktop monitor at their home, then they work regularly and often at home. All people who have a fully stocked and impressive home office are people who own a large desktop monitor at their home. All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes. All people who work regularly and often at home visit the office supply store regularly. If people spend their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon. Remy either both goes to bed late and wakes up every day after noon and spends their free time tidying and organizing the spaces in their home, or they do not go to bed late and wake up every day after noon nor spend their free time tidying and organizing the spaces in their home.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Remy has a fully stocked and impressive home office and also visits the office supply store regularly?", "id": "154", "ground_truth": "False", "reasoning": " Here is my reasoning:\n\nPremise 1.1: If people own a large desktop monitor at their home, then they work regularly and often at home.\nPremise 1.2: All people who have a fully stocked and impressive home office are people who own a large desktop monitor at their home.\nConclusion 1: People who have a fully stocked and impressive home office work regularly and often at home.\n\nPremise 2.1: All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes.\nPremise 2.2: All people who work regularly and often at home visit the office supply store regularly.\nConclusion 2: People who work regularly and often at home visit the office supply store regularly and spend their free time tidying and organizing the spaces in their homes.\n\nPremise 3.1: Remy either both goes to bed late and wakes up every day after noon and spends their free time tidying and organizing the spaces in their home, or they do not go to bed late and wake up every day after noon nor spend their free time tidying and organizing the spaces in their home.\nPremise 3.2: If Remy spends their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon.\nConclusion 3: Remy does not go to bed late and wake up every day after noon.\n\nPremise 4.1: People who have a fully stocked and impressive home office visit the office supply store regularly.\nPremise 4.2: Remy has a fully stocked and impressive home office.\nConclusion 4: Remy visits the office supply store regularly.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), ((2∧3)→4)], [(0→1), (2→3)], [((e→(((1∧f)∧3)⊻((5∧h)∧7)))∪(i→(((1∧j)∧3)⊻((5∧l)∧7)))), (8→(9∧a))], [(((6∧7)→8)∪((9∧a)→b)), (3∧4)]]", "logic_conclusion": "[((5∧6)→7), (4→(5∧6)), ((m→(c∧n))∪(o→(c∧p))), 5]", "correspondance": [{"0": "X own a large desktop monitor at people 's home .", "1": "X work regularly and often at home .", "2": "X is a person who has a fully stocked home office .", "3": "X is a person who has a impressive home office .", "4": "X is a people who owns a large desktop monitor at their home .", "5": "X is a person who has a fully stocked home office .", "6": "X is a person who has a impressive home office .", "7": "X works regularly and often at home ."}, {"0": "X is a person who works regularly and often at home .", "1": "X spends their free time tidying and organizing the spaces in their homes .", "2": "X is a person who works regularly and often at home .", "3": "X visits the office supply store regularly .", "4": "X is a person who works regularly and often at home .", "5": "X visits the office supply store regularly .", "6": "X spends their free time tidying and organizing the spaces in their homes ."}, {"0": "X is a day .", "1": "Remy goes to bed late .", "2": "Remy wakes up X after noon .", "3": "Remy spends Remy 's free time tidying and organizing the spaces in Remy 's home .", "4": "X is a day .", "5": "Remy does not goes to bed late .", "6": "Remy wakes up X after noon .", "7": "Remy spendses Remy 's free time tidying and organizing the spaces in Remy 's home .", "8": "Remy spends Remy 's free time tidying and organizing the spaces in Remy 's home .", "9": "Remy do not go to bed late .", "a": "Remy do not wake up every day after noon .", "b": "X is a day .", "c": "Remy does not goes to bed late .", "d": "Remy does not wakes up X after noon .", "e": "Remy is a day .", "f": "Remy wakes up Remy after noon .", "g": "Remy is a day .", "h": "Remy wakes up Remy after noon .", "i": "the spaces in their home is a day .", "j": "Remy wakes up the spaces in their home after noon .", "k": "the spaces in their home is a day .", "l": "Remy wakes up the spaces in their home after noon .", "m": "Remy is a day .", "n": "Remy does not wakes up Remy after noon .", "o": "the spaces in their home is a day .", "p": "Remy does not wakes up the spaces in their home after noon ."}, {"0": "X is a person who has a fully stocked home office .", "1": "X is a person who has a impressive home office .", "2": "X visits the office supply store regularly .", "3": "Remy has a fully stocked home office .", "4": "Remy has a impressive home office .", "5": "Remy visits the office supply store regularly .", "6": "the office supply store is a person who has a fully stocked home office .", "7": "the office supply store is a person who has a impressive home office .", "8": "the office supply store visits the office supply store regularly .", "9": "Remy is a person who has a fully stocked home office .", "a": "Remy is a person who has a impressive home office .", "b": "Remy visits the office supply store regularly ."}], "errors": [[]], "entailments_dict": [{"6": ["3"], "5": ["0", "2"], "1": ["7"]}, {"4": ["0", "2"], "1": ["6"], "3": ["5"]}, {"j": ["8", "(¬a)"], "7": ["8"], "3": ["8"], "l": ["8", "(¬a)"], "m": ["e"], "o": ["i"], "1": ["n", "(¬9)", "(¬5)", "(¬5)"], "5": ["c"], "9": ["c", "(¬f)", "(¬1)", "(¬h)"], "a": ["n", "(¬f)", "(¬h)"], "(¬p)": ["8"]}, {"4": ["9", "a"], "3": ["9", "a"], "b": ["5"]}], "predicted_steps": [true, true, "Contradiction in the premises", true]}
{"text": "If people own a large desktop monitor at their home, then they work regularly and often at home. All people who have a fully stocked and impressive home office are people who own a large desktop monitor at their home. All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes. All people who work regularly and often at home visit the office supply store regularly. If people spend their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon. Remy either both goes to bed late and wakes up every day after noon and spends their free time tidying and organizing the spaces in their home, or they do not go to bed late and wake up every day after noon nor spend their free time tidying and organizing the spaces in their home.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Remy either goes to bed late and wakes up every day after noon or visits the office supply store regularly, then Remy neither spends their free time tidying and organizing the spaces in their home nor has a fully stocked and impressive home office?", "id": "155", "ground_truth": "True", "reasoning": " Here is my reasoning:\n\nPremise 1.1: If people own a large desktop monitor at their home, then they work regularly and often at home.\nPremise 1.2: All people who have a fully stocked and impressive home office are people who own a large desktop monitor at their home.\nConclusion 1: People who have a fully stocked and impressive home office work regularly and often at home.\n\nPremise 2.1: All people who work regularly and often at home spend their free time tidying and organizing the spaces in their homes.\nPremise 2.2: All people who work regularly and often at home visit the office supply store regularly.\nConclusion 2: People who visit the office supply store regularly spend their free time tidying and organizing the spaces in their homes.\n\nPremise 3.1: Remy either goes to bed late and wakes up every day after noon or visits the office supply store regularly.\nPremise 3.2: Remy does not go to bed late and wake up every day after noon.\nConclusion 3: Remy visits the office supply store regularly.\n\nPremise 4.1: If people spend their free time tidying and organizing the spaces in their home, then they do not go to bed late and wake up every day after noon.\nPremise 4.2: Remy visits the office supply store regularly.\nConclusion 4: Remy does not spend their free time tidying and organizing the spaces in their home.\n\nPremise 5.1: Remy does not spend their free time tidying and organizing the spaces in their home.\nPremise 5.2: Remy has a fully stocked and impressive home office.\nConclusion 5: Remy does not have a fully stocked and impressive home office.\n\nTherefore, the answer is B. No. It is not true that If Remy either goes to bed late and wakes up every day after noon or visits the office supply store regularly, then Remy neither spends their free time tidying and organizing the spaces in their home nor has a fully stocked and impressive home office.", "logic_premises": "[[(0→1), ((2∧3)→4)], [(0→1), (2→3)], [((8→((1∧9)⊻3))∪(a→((1∧b)⊻3))), ((c→(5∧d))∪(e→(5∧f)))], [((5→(6∧7))∪((8→(9∧a))∪(b→(c∧d)))), 3], [0, (1∧2)]]", "logic_conclusion": "[((5∧6)→7), (4→5), 7, 4, (3∧4)]", "correspondance": [{"0": "X own a large desktop monitor at people 's home .", "1": "X work regularly and often at home .", "2": "X is a person who has a fully stocked home office .", "3": "X is a person who has a impressive home office .", "4": "X is a people who owns a large desktop monitor at their home .", "5": "X is a person who has a fully stocked home office .", "6": "X is a person who has a impressive home office .", "7": "X works regularly and often at home ."}, {"0": "X is a person who works regularly and often at home .", "1": "X spends their free time tidying and organizing the spaces in their homes .", "2": "X is a person who works regularly and often at home .", "3": "X visits the office supply store regularly .", "4": "X is a person who visits the office supply store regularly .", "5": "X spends their free time tidying and organizing the spaces in their homes ."}, {"0": "X is a day .", "1": "Remy goes to bed late .", "2": "Remy wakes up X after noon .", "3": "Remy visits the office supply store regularly .", "4": "X is a day .", "5": "Remy does not goes to bed late .", "6": "Remy does not wakes up X after noon .", "7": "Remy visits the office supply store regularly .", "8": "the office supply store is a day .", "9": "Remy wakes up the office supply store after noon .", "a": "Remy is a day .", "b": "Remy wakes up Remy after noon .", "c": "the office supply store is a day .", "d": "Remy does not wakes up the office supply store after noon .", "e": "Remy is a day .", "f": "Remy does not wakes up Remy after noon ."}, {"0": "X spend people 's free time tidying and organizing the spaces in people 's home .", "1": "X do not go to bed late .", "2": "X do not wake up every day after noon .", "3": "Remy visits the office supply store regularly .", "4": "Remy does not spend Remy 's free time tidying and organizing the spaces in Remy 's home .", "5": "the office supply store spend people 's free time tidying and organizing the spaces in people 's home .", "6": "the office supply store do not go to bed late .", "7": "the office supply store do not wake up every day after noon .", "8": "Remy spend people 's free time tidying and organizing the spaces in people 's home .", "9": "Remy do not go to bed late .", "a": "Remy do not wake up every day after noon .", "b": "the spaces in their home spend people 's free time tidying and organizing the spaces in people 's home .", "c": "the spaces in their home do not go to bed late .", "d": "the spaces in their home do not wake up every day after noon ."}, {"0": "Remy does not spend Remy 's free time tidying and organizing the spaces in Remy 's home .", "1": "Remy has a fully stocked home office .", "2": "Remy has a impressive home office .", "3": "Remy does not have a fully stocked home office .", "4": "Remy does not have a impressive home office ."}], "errors": [[]], "entailments_dict": [{"6": ["3"], "5": ["0", "2"], "1": ["7"]}, {"1": ["5"]}, {"3": ["7"], "f": ["(¬b)"], "5": ["(¬1)"], "9": ["(¬d)", "(¬f)"], "d": ["(¬9)", "(¬b)"], "1": ["(¬5)"], "b": ["(¬f)"]}, {}, {"4": ["(¬1)", "(¬2)"], "3": ["(¬1)", "(¬2)"], "(¬4)": ["1", "2"], "(¬3)": ["1"], "(¬1)": ["0"]}], "predicted_steps": [true, false, false, false, false]}
{"text": "All humans are mortal. All Greeks are humans.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Some Greeks are mortal?", "id": "156", "ground_truth": "Uncertain", "reasoning": " Sure! Here's my step-by-step reasoning:\n\nPremise 1: All humans are mortal.\nPremise 2: All Greeks are humans.\nConclusion 1: All Greeks are mortal.\n\nTherefore, the answer is A. Yes.\n\nHere's a breakdown of the reasoning:\n\n1. Premise 1 states that all humans are mortal. This means that every human being is mortal.\n2. Premise 2 states that all Greeks are humans. This means that every Greek person is a human being.\n3. Conclusion 1 logically follows from Premises 1 and 2. Since all humans are mortal, and all Greeks are humans, it is true that all Greeks are mortal.\n\nSo, the answer to the question is A. Yes, it is true that some Greeks are mortal.", "logic_premises": "[[(0→1), (2→3)]]", "logic_conclusion": "[(4→5)]", "correspondance": [{"0": "X is a human .", "1": "X is mortal .", "2": "X is a Greek .", "3": "X is a human .", "4": "X is a Greek .", "5": "X is mortal ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"], "1": ["5"]}], "predicted_steps": [true]}
{"text": "No students who work in the library are from the computer science department. All students who have part-time jobs offered by the university are students who work in the library. All students who take the database course are from the computer science department. All students instructed by professor David are taking the database course. All students working in the lab are instructed by professor David. James is a student working in the lab. Jack neither has a part-time job offered by the university nor works in the lab.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that James has a part-time job offered by the university?", "id": "157", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All students who have part-time jobs offered by the university are students who work in the library.\nPremise 1.2: No students who work in the library are from the computer science department.\nConclusion 1: All students who have part-time jobs offered by the university are not from the computer science department.\n\nPremise 2.1: All students who take the database course are from the computer science department.\nPremise 2.2: All students instructed by professor David are taking the database course.\nConclusion 2: All students instructed by professor David are from the computer science department.\n\nPremise 3.1: All students working in the lab are instructed by professor David.\nPremise 3.2: James is a student working in the lab.\nConclusion 3: James is instructed by professor David.\n\nPremise 4.1: Jack neither has a part-time job offered by the university nor works in the lab.\nConclusion 4: Jack does not work in the lab and does not have a part-time job offered by the university.\n\nPremise 5.1: James is a student working in the lab.\nPremise 5.2: James is instructed by professor David.\nConclusion 5: James has a part-time job offered by the university.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [((4→5)∪((6→7)∪(8→9))), 2], [(0∧1)], [0, 1]]", "logic_conclusion": "[(4→5), (4→5), 3, (2∧3), 2]", "correspondance": [{"0": "X is a student who has part - time jobs offered by the university .", "1": "X is a student who works in the library .", "2": "X is a student who works in the library .", "3": "X is not from the computer science department .", "4": "X is a student who has part - time jobs offered by the university .", "5": "X is not from the computer science department ."}, {"0": "X is a student who takes the database course .", "1": "X is from the computer science department .", "2": "X is a student instructed by professor David .", "3": "X is taking the database course .", "4": "X is a student instructed by professor David .", "5": "X is from the computer science department ."}, {"0": "X is a student working in the lab .", "1": "X is instructed by professor David .", "2": "James is a student working in the lab .", "3": "James is instructed by professor David .", "4": "professor David is a student working in the lab .", "5": "professor David is instructed by professor David .", "6": "James is a student working in the lab .", "7": "James is instructed by professor David .", "8": "the lab is a student working in the lab .", "9": "the lab is instructed by professor David ."}, {"0": "Jack does not have a part - time job offered by the university .", "1": "Jack does not work in the lab .", "2": "Jack does not work in the lab .", "3": "Jack does not have a part - time job offered by the university ."}, {"0": "James is a student working in the lab .", "1": "James is instructed by professor David .", "2": "James has a part - time job offered by the university ."}], "errors": [[]], "entailments_dict": [{"1": ["2"], "4": ["0"], "3": ["5"]}, {"3": ["0"], "4": ["2"], "1": ["5"]}, {"2": ["8", "6"], "7": ["3"], "3": ["(¬5)"]}, {"3": ["0"], "2": ["1"], "1": ["2"], "0": ["3"]}, {"2": ["0"], "0": ["2"]}], "predicted_steps": [true, true, true, true, true]}
{"text": "No students who work in the library are from the computer science department. All students who have part-time jobs offered by the university are students who work in the library. All students who take the database course are from the computer science department. All students instructed by professor David are taking the database course. All students working in the lab are instructed by professor David. James is a student working in the lab. Jack neither has a part-time job offered by the university nor works in the lab.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that James does not have a part-time job offered by the university?", "id": "158", "ground_truth": "True", "reasoning": " Premise 1: No students who work in the library are from the computer science department.\nPremise 2: All students who have part-time jobs offered by the university are students who work in the library.\nConclusion 1: No students who work in the library have part-time jobs offered by the university.\n\nPremise 3: All students who take the database course are from the computer science department.\nPremise 4: All students instructed by professor David are taking the database course.\nConclusion 2: All students instructed by professor David are from the computer science department.\n\nPremise 5: All students working in the lab are instructed by professor David.\nConclusion 3: All students working in the lab are from the computer science department.\n\nPremise 6: James is a student working in the lab.\nConclusion 4: James is from the computer science department.\n\nPremise 7: Jack neither has a part-time job offered by the university nor works in the lab.\nConclusion 5: Jack is not from the computer science department.\n\nNow, let's answer the question:\n\nIs it true that James does not have a part-time job offered by the university?\n\nA. Yes\nB. No\nC. Uncertain\n\nConclusion 6: James has a part-time job offered by the university. (This conclusion contradicts the statement in option A, so we can eliminate option A.)\n\nTherefore, the answer is B. No.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [(0→1)], [0], [(0∧1)]]", "logic_conclusion": "[(4→5), (4→5), (2→3), 1, 2]", "correspondance": [{"0": "X is a student who works in the library .", "1": "X is not from the computer science department .", "2": "X is a student who has part - time jobs offered by the university .", "3": "X is a student who works in the library .", "4": "X is a student who works in the library .", "5": "X does not have part - time jobs offered by the university ."}, {"0": "X is a student who takes the database course .", "1": "X is from the computer science department .", "2": "X is a student instructed by professor David .", "3": "X is taking the database course .", "4": "X is a student instructed by professor David .", "5": "X is from the computer science department ."}, {"0": "X is a student working in the lab .", "1": "X is instructed by professor David .", "2": "X is a student working in the lab .", "3": "X is from the computer science department ."}, {"0": "James is a student working in the lab .", "1": "James is from the computer science department ."}, {"0": "Jack does not have a part - time job offered by the university .", "1": "Jack does not work in the lab .", "2": "Jack is not from the computer science department ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["0", "2"], "(¬5)": ["2"]}, {"3": ["0"], "4": ["2"], "1": ["5"]}, {"2": ["0"]}, {"1": ["0"]}, {}], "predicted_steps": [false, true, false, false, false]}
{"text": "No students who work in the library are from the computer science department. All students who have part-time jobs offered by the university are students who work in the library. All students who take the database course are from the computer science department. All students instructed by professor David are taking the database course. All students working in the lab are instructed by professor David. James is a student working in the lab. Jack neither has a part-time job offered by the university nor works in the lab.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that James either takes the database course or has a part-time job offered by the university?", "id": "159", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All students who work in the library are from the computer science department.\nPremise 1.2: All students who have part-time jobs offered by the university are students who work in the library.\nConclusion 1: No students who have part-time jobs offered by the university are from the computer science department.\n\nPremise 2.1: All students who take the database course are from the computer science department.\nPremise 2.2: All students instructed by professor David are taking the database course.\nConclusion 2: All students instructed by professor David are from the computer science department.\n\nPremise 3.1: All students working in the lab are instructed by professor David.\nPremise 3.2: James is a student working in the lab.\nConclusion 3: James is a student instructed by professor David.\n\nPremise 4.1: James is a student instructed by professor David.\nPremise 4.2: All students instructed by professor David are taking the database course.\nConclusion 4: James is taking the database course.\n\nPremise 5.1: Jack neither has a part-time job offered by the university nor works in the lab.\nConclusion 5: Jack is not taking the database course.\n\nNow, let's evaluate the question:\n\nIs it true that James either takes the database course or has a part-time job offered by the university?\n\nA. Yes\nB. No\nC. Uncertain\n\nFrom our conclusions, we know that James is taking the database course (Conclusion 4) and does not have a part-time job offered by the university (Premise 5.1). Therefore, the answer is:\n\nA. Yes", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [((4→5)∪((6→7)∪(8→9))), 2], [0, ((4→5)∪((6→7)∪(8→9)))], [(0∧1)]]", "logic_conclusion": "[(4→5), (4→5), 3, 3, 2]", "correspondance": [{"0": "X is a student who works in the library .", "1": "X is from the computer science department .", "2": "X is a student who has part - time jobs offered by the university .", "3": "X is a student who works in the library .", "4": "X is a student who has part - time jobs offered by the university .", "5": "X is not from the computer science department ."}, {"0": "X is a student who takes the database course .", "1": "X is from the computer science department .", "2": "X is a student instructed by professor David .", "3": "X is taking the database course .", "4": "X is a student instructed by professor David .", "5": "X is from the computer science department ."}, {"0": "X is a student working in the lab .", "1": "X is instructed by professor David .", "2": "James is a student working in the lab .", "3": "James is a student instructed by professor David .", "4": "professor David is a student working in the lab .", "5": "professor David is instructed by professor David .", "6": "James is a student working in the lab .", "7": "James is instructed by professor David .", "8": "the lab is a student working in the lab .", "9": "the lab is instructed by professor David ."}, {"0": "James is a student instructed by professor David .", "1": "X is a student instructed by professor David .", "2": "X is taking the database course .", "3": "James is taking the database course .", "4": "James is a student instructed by professor David .", "5": "James is taking the database course .", "6": "the database course is a student instructed by professor David .", "7": "the database course is taking the database course .", "8": "professor David is a student instructed by professor David .", "9": "professor David is taking the database course ."}, {"0": "Jack does not have a part - time job offered by the university .", "1": "Jack does not work in the lab .", "2": "Jack is not taking the database course ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"]}, {"3": ["0"], "4": ["2"], "1": ["5"]}, {"2": ["8", "6"], "7": ["3"], "3": ["(¬5)"]}, {"0": ["4"], "7": ["3"], "5": ["3"]}, {}], "predicted_steps": [false, true, true, true, false]}
{"text": "No students who work in the library are from the computer science department. All students who have part-time jobs offered by the university are students who work in the library. All students who take the database course are from the computer science department. All students instructed by professor David are taking the database course. All students working in the lab are instructed by professor David. James is a student working in the lab. Jack neither has a part-time job offered by the university nor works in the lab.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Jack takes the database course?", "id": "160", "ground_truth": "Uncertain", "reasoning": " Here's my step-by-step reasoning:\n\nPremise 1.1: No students who work in the library are from the computer science department.\nPremise 1.2: All students who have part-time jobs offered by the university are students who work in the library.\nConclusion 1: No students with part-time jobs offered by the university are from the computer science department.\n\nPremise 2.1: All students who take the database course are from the computer science department.\nPremise 2.2: All students instructed by professor David are taking the database course.\nConclusion 2: All students instructed by professor David are from the computer science department.\n\nPremise 3.1: All students working in the lab are instructed by professor David.\nPremise 3.2: James is a student working in the lab.\nConclusion 3: James is a student instructed by professor David.\n\nPremise 4.1: Jack neither has a part-time job offered by the university nor works in the lab.\nConclusion 4: Jack is not instructed by professor David.\n\nPremise 5.1: All students instructed by professor David are taking the database course.\nConclusion 5: Jack is not taking the database course.\n\nTherefore, the answer is B. No. It is not true that Jack takes the database course.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [((4→5)∪((6→7)∪(8→9))), 2], [(0∧1)], [((3→4)∪((5→6)∪(7→8)))]]", "logic_conclusion": "[(4→5), (4→5), 3, 2, 2]", "correspondance": [{"0": "X is a student who works in the library .", "1": "X is not from the computer science department .", "2": "X is a student who has part - time jobs offered by the university .", "3": "X is a student who works in the library .", "4": "X is a student with part - time jobs offered by the university .", "5": "X is not from the computer science department ."}, {"0": "X is a student who takes the database course .", "1": "X is from the computer science department .", "2": "X is a student instructed by professor David .", "3": "X is taking the database course .", "4": "X is a student instructed by professor David .", "5": "X is from the computer science department ."}, {"0": "X is a student working in the lab .", "1": "X is instructed by professor David .", "2": "James is a student working in the lab .", "3": "James is a student instructed by professor David .", "4": "professor David is a student working in the lab .", "5": "professor David is instructed by professor David .", "6": "James is a student working in the lab .", "7": "James is instructed by professor David .", "8": "the lab is a student working in the lab .", "9": "the lab is instructed by professor David ."}, {"0": "Jack does not have a part - time job offered by the university .", "1": "Jack does not work in the lab .", "2": "Jack is not instructed by professor David ."}, {"0": "X is a student instructed by professor David .", "1": "X is taking the database course .", "2": "Jack is not taking the database course .", "3": "Jack is a student instructed by professor David .", "4": "Jack is taking the database course .", "5": "the database course is a student instructed by professor David .", "6": "the database course is taking the database course .", "7": "professor David is a student instructed by professor David .", "8": "professor David is taking the database course ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"], "1": ["5"]}, {"3": ["0"], "4": ["2"], "1": ["5"]}, {"2": ["8", "6"], "7": ["3"], "3": ["(¬5)"]}, {}, {"2": ["(¬4)", "(¬6)"]}], "predicted_steps": [true, true, true, false, false]}
{"text": "If George likes music, he wants to compose. If George has access to a program, he can compose. If George can compose and wants to compose, he will compose.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If George likes music and has access to a program, he will compose?", "id": "161", "ground_truth": "True", "reasoning": " Sure, I can help you with that! Here's my step-by-step reasoning:\n\nPremise 1.1: If George likes music, he wants to compose.\nPremise 1.2: If George has access to a program, he can compose.\nConclusion 1: If George likes music and has access to a program, he can compose.\n\nPremise 2.1: If George can compose and wants to compose, he will compose.\nConclusion 2: If George likes music and has access to a program, he will compose.\n\nTherefore, the answer is A. Yes. It is true that if George likes music and has access to a program, he will compose.", "logic_premises": "[[(0→1), (2→3)], [((0∧1)→2)]]", "logic_conclusion": "[((4∧5)→6), ((3∧4)→5)]", "correspondance": [{"0": "George likes music .", "1": "George wants to compose .", "2": "George has access to a program .", "3": "George can compose .", "4": "George likes music .", "5": "George has access to a program .", "6": "George can compose ."}, {"0": "George can compose .", "1": "George wants to compose .", "2": "George will compose .", "3": "George likes music .", "4": "George has access to a program .", "5": "George will compose ."}], "errors": [[]], "entailments_dict": [{"4": ["0"], "5": ["2"], "3": ["6"]}, {"2": ["5"]}], "predicted_steps": [true, false]}
{"text": "If George likes music, he wants to compose. If George has access to a program, he can compose. If George can compose and wants to compose, he will compose.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If George will not compose, George can not compose?", "id": "162", "ground_truth": "Uncertain", "reasoning": " Sure, I can help you with that! Here's my step-by-step reasoning:\n\nPremise 1.1: If George likes music, he wants to compose.\nPremise 1.2: If George has access to a program, he can compose.\nPremise 2.1: If George can compose and wants to compose, he will compose.\n\nConclusion 1: If George wants to compose, then he will compose.\n\nPremise 3.1: If George will not compose, then he does not want to compose.\n\nConclusion 2: If George does not want to compose, then he will not compose.\n\nPremise 4.1: If George can compose, then he has access to a program.\n\nConclusion 3: If George does not have access to a program, then he cannot compose.\n\nPremise 5.1: If George will not compose, then he does not have access to a program.\n\nConclusion 4: If George will not compose, then he cannot compose.\n\nBased on the above reasoning, the answer is A. Yes. It is true that if George will not compose, then he cannot compose.", "logic_premises": "[[(0→1), (2→3), ((4∧5)→6)], [(0→1)], [(0→1)], [(0→1)]]", "logic_conclusion": "[(7→8), (2→3), (2→3), (2→3)]", "correspondance": [{"0": "George likes music .", "1": "George wants to compose .", "2": "George has access to a program .", "3": "George can compose .", "4": "George can compose .", "5": "George wants to compose .", "6": "George will compose .", "7": "George wants to compose .", "8": "George will compose ."}, {"0": "George will not compose .", "1": "George does not want to compose .", "2": "George does not want to compose .", "3": "George will not compose ."}, {"0": "George can compose .", "1": "George has access to a program .", "2": "George does not have access to a program .", "3": "George can not compose ."}, {"0": "George will not compose .", "1": "George does not have access to a program .", "2": "George will not compose .", "3": "George can not compose ."}], "errors": [[]], "entailments_dict": [{"3": ["4"], "1": ["5"], "7": ["5"], "6": ["8"]}, {"2": ["0"], "1": ["3"]}, {"2": ["(¬1)"], "(¬3)": ["0"]}, {"2": ["0"]}], "predicted_steps": [false, true, true, false]}
{"text": "A hawk never lands. Some birds are hawks.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that All birds lan?", "id": "163", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: A hawk never lands.\nPremise 1.2: Some birds are hawks.\nConclusion 1: Some birds never land.\n\nPremise 2.1: Some birds never land.\nConclusion 2: Not all birds land.\n\nPremise 3.1: Not all birds land.\nConclusion 3: All birds do not land.\n\nTherefore, the answer is B. No. It is not true that all birds land.", "logic_premises": "[[0, 1], [0], [0]]", "logic_conclusion": "[2, 1, (1→2)]", "correspondance": [{"0": "A hawk never lands .", "1": "Some birds are hawks .", "2": "Some birds never land ."}, {"0": "Some birds never land .", "1": "Not all birds land ."}, {"0": "Not all birds land .", "1": "X is a bird .", "2": "X does not lands ."}], "errors": [[]], "entailments_dict": [{"2": ["0"]}, {"0": ["1"]}, {}], "predicted_steps": [false, true, false]}
{"text": "On some Mondays at 8 pm, roses are given out on TV. Every rose given out on TV is on the Bachelor. Everything on the Bachelor portrays the lives of real people. All shows portraying the lives of real people are reality TV shows. Breaking Bad is not a reality TV show.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Breaking Bad is on Monday at 8 pm?", "id": "164", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: On some Mondays at 8 pm, roses are given out on TV.\nPremise 1.2: Every rose given out on TV is on the Bachelor.\nConclusion 1: The Bachelor is on some Mondays at 8 pm.\n\nPremise 2.1: Everything on the Bachelor portrays the lives of real people.\nPremise 2.2: All shows portraying the lives of real people are reality TV shows.\nConclusion 2: The Bachelor is a reality TV show.\n\nPremise 3.1: Breaking Bad is not a reality TV show.\nConclusion 3: Breaking Bad is not on the Bachelor.\n\nPremise 4.1: The Bachelor is on some Mondays at 8 pm.\nPremise 4.2: Breaking Bad is not on the Bachelor.\nConclusion 4: Breaking Bad is not on Monday at 8 pm.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, ((4→5)∪(6→7))], [((5→6)∪((7→8)∪(9→a))), ((b→c)∪((d→e)∪(f→g)))], [0], [0, 1]]", "logic_conclusion": "[3, 4, 1, 2]", "correspondance": [{"0": "On some Mondays at 8 pm , roses are given out on TV .", "1": "X is a rose given out on TV .", "2": "X is on the Bachelor .", "3": "the Bachelor is on some Mondays at 8 pm .", "4": "The Bachelor is a rose given out on TV .", "5": "The Bachelor is on the Bachelor .", "6": "the Bachelor is a rose given out on TV .", "7": "the Bachelor is on the Bachelor ."}, {"0": "X is a thing on the Bachelor .", "1": "X portrays the lives of real people .", "2": "X is a show portraying the lives of real person .", "3": "X is reality TV a show .", "4": "the Bachelor is a reality TV show .", "5": "the lives of real people is a thing on the Bachelor .", "6": "the lives of real people portrays the lives of real people .", "7": "The Bachelor is a thing on the Bachelor .", "8": "The Bachelor portrays the lives of real people .", "9": "the Bachelor is a thing on the Bachelor .", "a": "the Bachelor portrays the lives of real people .", "b": "the lives of real people is a show portraying the lives of real person .", "c": "the lives of real people is reality TV a show .", "d": "The Bachelor is a show portraying the lives of real person .", "e": "The Bachelor is reality TV a show .", "f": "the Bachelor is a show portraying the lives of real person .", "g": "the Bachelor is reality TV a show ."}, {"0": "breaking Bad is not a reality TV show .", "1": "breaking Bad is not on the Bachelor ."}, {"0": "the Bachelor is on some Mondays at 8 pm .", "1": "Breaking Bad is not on the Bachelor .", "2": "Breaking Bad is not on Monday at 8 pm ."}], "errors": [[]], "entailments_dict": [{"7": ["0"], "5": ["0", "3"], "3": ["0"]}, {"8": ["f", "b", "d", "4"], "6": ["b", "d", "f", "4"], "a": ["b", "d", "f", "4"], "4": ["7", "9", "d", "b", "f"], "g": ["4"], "e": ["4"]}, {"1": ["0"], "0": ["1"]}, {"(¬2)": ["1"]}], "predicted_steps": [false, false, true, false]}
{"text": "On some Mondays at 8 pm, roses are given out on TV. Every rose given out on TV is on the Bachelor. Everything on the Bachelor portrays the lives of real people. All shows portraying the lives of real people are reality TV shows. Breaking Bad is not a reality TV show.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Breaking Bad is a TV show in which roses are given out on Monday at 8 pm?", "id": "165", "ground_truth": "False", "reasoning": " Premise 1.1: On some Mondays at 8 pm, roses are given out on TV.\nPremise 1.2: Every rose given out on TV is on the Bachelor.\nConclusion 1: The Bachelor is a TV show that gives out roses on some Mondays at 8 pm.\n\nPremise 2.1: Everything on the Bachelor portrays the lives of real people.\nPremise 2.2: All shows portraying the lives of real people are reality TV shows.\nConclusion 2: The Bachelor is a reality TV show.\n\nPremise 3.1: Breaking Bad is not a reality TV show.\nConclusion 3: Breaking Bad is not a TV show that gives out roses on some Mondays at 8 pm.\n\nConclusion 4: The statement \"Breaking Bad is a TV show in which roses are given out on Monday at 8 pm\" is false.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, ((4→5)∪(6→7))], [((5→6)∪((7→8)∪(9→a))), ((b→c)∪((d→e)∪(f→g)))], [0]]", "logic_conclusion": "[3, 4, 1]", "correspondance": [{"0": "On some Mondays at 8 pm , roses are given out on TV .", "1": "X is a rose given out on TV .", "2": "X is on the Bachelor .", "3": "the Bachelor is a TV show that gives out roses on some Mondays at 8 pm .", "4": "The Bachelor is a rose given out on TV .", "5": "The Bachelor is on the Bachelor .", "6": "the Bachelor is a rose given out on TV .", "7": "the Bachelor is on the Bachelor ."}, {"0": "X is a thing on the Bachelor .", "1": "X portrays the lives of real people .", "2": "X is a show portraying the lives of real person .", "3": "X is reality TV a show .", "4": "the Bachelor is a reality TV show .", "5": "the lives of real people is a thing on the Bachelor .", "6": "the lives of real people portrays the lives of real people .", "7": "The Bachelor is a thing on the Bachelor .", "8": "The Bachelor portrays the lives of real people .", "9": "the Bachelor is a thing on the Bachelor .", "a": "the Bachelor portrays the lives of real people .", "b": "the lives of real people is a show portraying the lives of real person .", "c": "the lives of real people is reality TV a show .", "d": "The Bachelor is a show portraying the lives of real person .", "e": "The Bachelor is reality TV a show .", "f": "the Bachelor is a show portraying the lives of real person .", "g": "the Bachelor is reality TV a show ."}, {"0": "breaking Bad is not a reality TV show .", "1": "breaking Bad is not a TV show that gives out roses on some Mondays at 8 pm ."}], "errors": [[]], "entailments_dict": [{"7": ["0", "3"], "5": ["0", "3"], "3": ["0"], "0": ["3"]}, {"8": ["f", "b", "d", "4"], "6": ["b", "d", "f", "4"], "a": ["b", "d", "f", "4"], "4": ["7", "9", "d", "b", "f"], "g": ["4"], "e": ["4"]}, {"0": ["1"]}], "predicted_steps": [true, false, true]}
{"text": "On some Mondays at 8 pm, roses are given out on TV. Every rose given out on TV is on the Bachelor. Everything on the Bachelor portrays the lives of real people. All shows portraying the lives of real people are reality TV shows. Breaking Bad is not a reality TV show.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If roses are given out during Breaking Bad, then it is on Monday at 8 pm?", "id": "166", "ground_truth": "True", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: On some Mondays at 8 pm, roses are given out on TV.\nPremise 1.2: Every rose given out on TV is on the Bachelor.\nPremise 1.3: Everything on the Bachelor portrays the lives of real people.\nPremise 1.4: All shows portraying the lives of real people are reality TV shows.\nPremise 2.1: Breaking Bad is not a reality TV show.\nConclusion 1: Breaking Bad is not on the Bachelor.\nPremise 3.1: If roses are given out during Breaking Bad, then it is on Monday at 8 pm.\nConclusion 2: It is not true that If roses are given out during Breaking Bad, then it is on Monday at 8 pm.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, ((9→a)∪((b→c)∪(d→e))), ((f→g)∪((h→i)∪(j→k))), ((l→m)∪((n→o)∪(p→q))), 7], [(0→1)]]", "logic_conclusion": "[8, (2→3)]", "correspondance": [{"0": "On some Mondays at 8 pm , roses are given out on TV .", "1": "X is a rose given out on TV .", "2": "X is on the Bachelor .", "3": "X is a thing on the Bachelor .", "4": "X portrays the lives of real people .", "5": "X is a show portraying the lives of real person .", "6": "X is reality TV a show .", "7": "Breaking Bad is not a reality TV show .", "8": "Breaking Bad is not on the Bachelor .", "9": "the lives of real people is a rose given out on TV .", "a": "the lives of real people is on the Bachelor .", "b": "Breaking Bad is a rose given out on TV .", "c": "Breaking Bad is on the Bachelor .", "d": "the Bachelor is a rose given out on TV .", "e": "the Bachelor is on the Bachelor .", "f": "the lives of real people is a thing on the Bachelor .", "g": "the lives of real people portrays the lives of real people .", "h": "Breaking Bad is a thing on the Bachelor .", "i": "Breaking Bad portrays the lives of real people .", "j": "the Bachelor is a thing on the Bachelor .", "k": "the Bachelor portrays the lives of real people .", "l": "the lives of real people is a show portraying the lives of real person .", "m": "the lives of real people is reality TV a show .", "n": "Breaking Bad is a show portraying the lives of real person .", "o": "Breaking Bad is reality TV a show .", "p": "the Bachelor is a show portraying the lives of real person .", "q": "the Bachelor is reality TV a show ."}, {"0": "roses are given out during Breaking Bad .", "1": "it is on Monday at 8 pm .", "2": "It is not true that roses are given out during Breaking Bad .", "3": "It is not true that it is on Monday at 8 pm ."}], "errors": [[]], "entailments_dict": [{"e": ["0", "l", "p", "j"], "a": ["0", "l", "f", "p"], "k": ["l", "p", "(¬c)"], "c": ["h", "(¬7)", "(¬o)", "(¬i)", "(¬k)"], "g": ["l", "p", "(¬c)"], "m": ["7", "(¬c)"], "q": ["d", "(¬c)"], "8": ["7", "(¬c)"], "7": ["8", "(¬o)", "(¬c)", "(¬i)"], "o": ["(¬a)", "(¬c)", "(¬7)", "(¬i)"], "i": ["(¬a)", "(¬7)", "(¬c)"], "(¬h)": ["7"], "(¬n)": ["7"], "(¬l)": ["7"]}, {}], "predicted_steps": ["Contradiction in the premises", false]}
{"text": "Heinrich Scmidt was a Nazi German politician. Heeinrich Scmidt was also a member of the Prussian State Parliament and the Nazi Reichstag.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Heinrich Schmidt was either German or Russian?", "id": "167", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Heinrich Scmidt was a Nazi German politician.\nPremise 1.2: Nazi Germany was a German state.\nConclusion 1: Heinrich Scmidt was German.\n\nPremise 2.1: Heinrich Scmidt was a member of the Prussian State Parliament.\nPremise 2.2: Prussia was a German state.\nConclusion 2: Heinrich Scmidt was German.\n\nPremise 3.1: Heinrich Scmidt was a member of the Nazi Reichstag.\nPremise 3.2: The Nazi Reichstag was a German parliament.\nConclusion 3: Heinrich Scmidt was German.\n\nConclusion 4: Heinrich Scmidt was not Russian.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, 1], [0, 1], [0, 1]]", "logic_conclusion": "[2, 2, 2]", "correspondance": [{"0": "Heinrich Scmidt was a Nazi German politician .", "1": "Nazi Germany was a German state .", "2": "Heinrich Scmidt was German ."}, {"0": "Heinrich Scmidt was a member of the Prussian State Parliament .", "1": "Prussia was a German state .", "2": "Heinrich Scmidt was German ."}, {"0": "Heinrich Scmidt was a member of the Nazi Reichstag .", "1": "the Nazi Reichstag was a German parliament .", "2": "Heinrich Scmidt was German ."}], "errors": [[]], "entailments_dict": [{"0": ["1", "2"]}, {"0": ["1"]}, {"0": ["1"]}], "predicted_steps": [true, false, false]}
{"text": "Heinrich Scmidt was a Nazi German politician. Heeinrich Scmidt was also a member of the Prussian State Parliament and the Nazi Reichstag.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Some Nazi German politician was part of both the Prussian State Parliament and the Nazi Reichstag?", "id": "168", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Heinrich Scmidt was a Nazi German politician.\nPremise 1.2: Heinrich Scmidt was a member of the Prussian State Parliament.\nPremise 1.3: Heinrich Scmidt was a member of the Nazi Reichstag.\nConclusion 1: Heinrich Scmidt was a Nazi German politician who was part of both the Prussian State Parliament and the Nazi Reichstag.\n\nPremise 2.1: Some Nazi German politician was part of both the Prussian State Parliament and the Nazi Reichstag.\nPremise 2.2: Heinrich Scmidt was a Nazi German politician who was part of both the Prussian State Parliament and the Nazi Reichstag.\nConclusion 2: The statement \"Some Nazi German politician was part of both the Prussian State Parliament and the Nazi Reichstag\" is true.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, 1, 2], [(0∧1), (2∧3)]]", "logic_conclusion": "[(3∧4), 4]", "correspondance": [{"0": "Heinrich Scmidt was a Nazi German politician .", "1": "Heinrich Scmidt was a member of the Prussian State Parliament .", "2": "Heinrich Scmidt was a member of the Nazi Reichstag .", "3": "Heinrich Scmidt was a Nazi German politician who was part of the Prussian State Parliament .", "4": "Heinrich Scmidt was a Nazi German politician who was part of the Nazi Reichstag ."}, {"0": "some Nazi German politician was part of the Prussian State Parliament .", "1": "some Nazi German politician was part of the Nazi Reichstag .", "2": "some Nazi German politician was a Nazi German politician who was part of the Prussian State Parliament .", "3": "some Nazi German politician was a Nazi German politician who was part of the Nazi Reichstag .", "4": "The statement \" Some Nazi German politician was part of both the Prussian State Parliament and the Nazi Reichstag \" is true ."}], "errors": [[]], "entailments_dict": [{"0": ["2", "1", "4", "3"], "2": ["1", "0", "4", "3"], "4": ["0", "1", "2"], "3": ["0", "1", "2"], "1": ["4", "3"]}, {"0": ["2", "3", "4"], "2": ["1", "0", "4"], "1": ["3", "2", "4"], "3": ["1", "0", "4"], "4": ["1", "0", "3", "2"]}], "predicted_steps": [true, true]}
{"text": "Heinrich Scmidt was a Nazi German politician. Heeinrich Scmidt was also a member of the Prussian State Parliament and the Nazi Reichstag.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that No politicans are part of the Nazi Reichstag?", "id": "169", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Heinrich Scmidt was a Nazi German politician.\nPremise 1.2: Heinrich Scmidt was a member of the Prussian State Parliament and the Nazi Reichstag.\nConclusion 1: Heinrich Scmidt was a politician who was part of the Nazi Reichstag.\n\nPremise 2.1: No politicians are part of the Nazi Reichstag.\nConclusion 2: It is not true that no politicians are part of the Nazi Reichstag.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, (1∧2)], [(0→1)]]", "logic_conclusion": "[3, (2→3)]", "correspondance": [{"0": "Heinrich Scmidt was a Nazi German politician .", "1": "Heinrich Scmidt was a member of the Prussian State Parliament .", "2": "Heinrich Scmidt was a member of the Nazi Reichstag .", "3": "Heinrich Scmidt was a politician who was part of the Nazi Reichstag ."}, {"0": "X is a politician .", "1": "X is not part of the Nazi Reichstag .", "2": "X is a politician .", "3": "It is true that X is part of the Nazi Reichstag ."}], "errors": [[]], "entailments_dict": [{"0": ["2", "1", "3"], "2": ["0", "3"], "3": ["0", "1", "2"]}, {"2": ["0"]}], "predicted_steps": [true, false]}
{"text": "If something is a deadly disease, then its survival rate is low. All severe cancers are deadly diseases. Bile duct cancer is a severe cancer. All Cholangiocarcinoma is bile duct cancer. No one with mild flu has a low survival rate. If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Colorectal cancer is a severe cance?", "id": "170", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If something is a deadly disease, then its survival rate is low.\nPremise 1.2: All severe cancers are deadly diseases.\nConclusion 1: All severe cancers have a low survival rate.\n\nPremise 2.1: Bile duct cancer is a severe cancer.\nPremise 2.2: All Cholangiocarcinoma is bile duct cancer.\nConclusion 2: All Cholangiocarcinoma is a severe cancer.\n\nPremise 3.1: No one with mild flu has a low survival rate.\nConclusion 3: If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer.\n\nPremise 4.1: Colorectal cancer is a bile duct cancer.\nPremise 4.2: The survival rate of colorectal cancer is low.\nConclusion 4: Colorectal cancer is not a bile duct cancer.\n\nConclusion 5: Therefore, the answer is B. No, colorectal cancer is not a severe cancer.\n\nSo, the answer is B. No.", "logic_premises": "[[(0→1), (2→3)], [0, (1→2)], [(5→6)], [0, 1]]", "logic_conclusion": "[(4→5), (3→4), ((2∧3)→4), 2]", "correspondance": [{"0": "X is a deadly disease .", "1": "X 's survival rate is low .", "2": "X is a severe cancer .", "3": "X is deadly a disease .", "4": "X is a severe cancer .", "5": "X has a low survival rate ."}, {"0": "Bile duct cancer is a severe cancer .", "1": "X is a Cholangiocarcinoma .", "2": "X is bile duct cancer .", "3": "X is a Cholangiocarcinoma .", "4": "X is a severe cancer ."}, {"0": "X is a person with mild flu .", "1": "X does not have a low survival rate .", "2": "colorectal cancer is a bile duct cancer .", "3": "the survival rate is low .", "4": "colorectal cancer is not a bile duct cancer .", "5": "the survival rate is a person with mild flu .", "6": "the survival rate does not have a low survival rate ."}, {"0": "Colorectal cancer is a bile duct cancer .", "1": "The survival rate of colorectal cancer is low .", "2": "Colorectal cancer is not a bile duct cancer ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["0", "2"], "1": ["5"]}, {"3": ["0", "1"], "2": ["4"], "0": ["(¬2)"]}, {"3": ["(¬6)"]}, {"2": ["(¬0)"], "(¬2)": ["0"]}], "predicted_steps": [true, true, false, false]}
{"text": "If something is a deadly disease, then its survival rate is low. All severe cancers are deadly diseases. Bile duct cancer is a severe cancer. All Cholangiocarcinoma is bile duct cancer. No one with mild flu has a low survival rate. If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If colorectal cancer is a bile duct cancer or a Cholangiocarcinoma, then colorectal cancer is a bile duct cancer and a mild flu?", "id": "171", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If something is a deadly disease, then its survival rate is low.\nPremise 1.2: All severe cancers are deadly diseases.\nPremise 1.3: Bile duct cancer is a severe cancer.\nPremise 1.4: All Cholangiocarcinoma is bile duct cancer.\nPremise 2.1: No one with mild flu has a low survival rate.\nPremise 2.2: If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer.\nConclusion 1: Colorectal cancer is not a bile duct cancer.\nConclusion 2: If colorectal cancer is a bile duct cancer or a Cholangiocarcinoma, then colorectal cancer is not a bile duct cancer.\nConclusion 3: Therefore, the statement \"If colorectal cancer is a bile duct cancer or a Cholangiocarcinoma, then colorectal cancer is a bile duct cancer and a mild flu\" is false.\n\nSo, the answer is B. No.", "logic_premises": "[[(d→e), (f→g), 4, (h→i), (j→k), ((9∧a)→b)]]", "logic_conclusion": "[c]", "correspondance": [{"0": "X is a deadly disease .", "1": "X 's survival rate is low .", "2": "X is a severe cancer .", "3": "X is deadly a disease .", "4": "Bile duct cancer is a severe cancer .", "5": "X is a Cholangiocarcinoma .", "6": "X is bile duct cancer .", "7": "X is a person with mild flu .", "8": "X does not have a low survival rate .", "9": "colorectal cancer is a bile duct cancer .", "a": "the survival rate is low .", "b": "colorectal cancer is not a bile duct cancer .", "c": "colorectal cancer is not a bile duct cancer .", "d": "the survival rate is a deadly disease .", "e": "the survival rate 's survival rate is low .", "f": "the survival rate is a severe cancer .", "g": "the survival rate is deadly a disease .", "h": "the survival rate is a Cholangiocarcinoma .", "i": "the survival rate is bile duct cancer .", "j": "the survival rate is a person with mild flu .", "k": "the survival rate does not have a low survival rate ."}], "errors": [[]], "entailments_dict": [{"e": ["a", "(¬k)"], "4": ["a"], "g": ["d", "(¬k)"], "b": ["c"], "i": ["(¬k)", "(¬b)"], "(¬c)": ["9"]}], "predicted_steps": [true]}
{"text": "If something is a deadly disease, then its survival rate is low. All severe cancers are deadly diseases. Bile duct cancer is a severe cancer. All Cholangiocarcinoma is bile duct cancer. No one with mild flu has a low survival rate. If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If colorectal cancer is not a mild flu and a Cholangiocarcinoma, then colorectal cancer is a bile duct cancer or a Cholangiocarcinoma?", "id": "172", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If something is a deadly disease, then its survival rate is low.\nPremise 1.2: All severe cancers are deadly diseases.\nPremise 1.3: Bile duct cancer is a severe cancer.\nPremise 1.4: All Cholangiocarcinoma is bile duct cancer.\nPremise 2.1: No one with mild flu has a low survival rate.\nPremise 2.2: If colorectal cancer is a bile duct cancer and the survival rate is low, then colorectal cancer is not a bile duct cancer.\nConclusion 1: Colorectal cancer is not a bile duct cancer.\nConclusion 2: Colorectal cancer is not a mild flu.\nConclusion 3: If colorectal cancer is not a mild flu and a Cholangiocarcinoma, then colorectal cancer is a bile duct cancer or a Cholangiocarcinoma.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(d→e), (f→g), 4, (h→i), (j→k), ((9∧a)→b)]]", "logic_conclusion": "[c]", "correspondance": [{"0": "X is a deadly disease .", "1": "X 's survival rate is low .", "2": "X is a severe cancer .", "3": "X is deadly a disease .", "4": "Bile duct cancer is a severe cancer .", "5": "X is a Cholangiocarcinoma .", "6": "X is bile duct cancer .", "7": "X is a person with mild flu .", "8": "X does not have a low survival rate .", "9": "colorectal cancer is a bile duct cancer .", "a": "the survival rate is low .", "b": "colorectal cancer is not a bile duct cancer .", "c": "colorectal cancer is not a bile duct cancer .", "d": "the survival rate is a deadly disease .", "e": "the survival rate 's survival rate is low .", "f": "the survival rate is a severe cancer .", "g": "the survival rate is deadly a disease .", "h": "the survival rate is a Cholangiocarcinoma .", "i": "the survival rate is bile duct cancer .", "j": "the survival rate is a person with mild flu .", "k": "the survival rate does not have a low survival rate ."}], "errors": [[]], "entailments_dict": [{"e": ["a", "(¬k)"], "4": ["a"], "g": ["d", "(¬k)"], "b": ["c"], "i": ["(¬k)", "(¬b)"], "(¬c)": ["9"]}], "predicted_steps": [true]}
{"text": "All people who eat salads regularly are very conscious about their health and eating habits. All people who grew up in health-conscious childhood homes eat salads regularly. All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes. If people have good relationships with their parents, then they fulfill their nutritional daily intakes. If people have good relationships with their parents, then they do not eat salads regularly. If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes. It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Taylor eats salads regularly?", "id": "173", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All people who eat salads regularly are very conscious about their health and eating habits.\nPremise 1.2: All people who grew up in health-conscious childhood homes eat salads regularly.\nConclusion 1: People who grew up in health-conscious childhood homes are likely to eat salads regularly.\n\nPremise 2.1: All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes.\nPremise 2.2: If people have good relationships with their parents, then they fulfill their nutritional daily intakes.\nConclusion 2: People who have good relationships with their parents are likely to fulfill their nutritional daily intakes.\n\nPremise 3.1: If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.\nConclusion 3: People who visit the gym regularly are likely to fulfill their nutritional daily intakes.\n\nPremise 4.1: It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents.\nPremise 4.2: Taylor visits the gym at least once a day.\nConclusion 4: Taylor is likely to fulfill her nutritional daily intakes.\n\nPremise 5.1: Taylor fulfills her nutritional daily intakes.\nConclusion 5: Taylor eats salads regularly.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [(0→1)], [((0∧1)⊻(2∧3)), 4], [0]]", "logic_conclusion": "[(4→5), (4→5), (2→3), 5, 1]", "correspondance": [{"0": "X is a person who eats salads regularly .", "1": "X is very conscious about their health and eating habits .", "2": "X is a person who grew up in health - conscious childhood homes .", "3": "X eats salads regularly .", "4": "X is a person who grew up in health - conscious childhood homes .", "5": "X is likely to eats salads regularly ."}, {"0": "X is a person who fulfills their nutritional daily intakes .", "1": "X grew up in health - conscious childhood homes .", "2": "X have good relationships with people 's parents .", "3": "X fulfill X 's nutritional daily intakes .", "4": "X is a person who has good relationships with their parents .", "5": "X is likely to fulfills their nutritional daily intakes ."}, {"0": "X visit the gym at least once a day .", "1": "X always fulfill X 's daily nutritional intakes .", "2": "X is a person who visits the gym regularly .", "3": "X is likely to fulfills their nutritional daily intakes ."}, {"0": "It is both true that Taylor grew up in a health - conscious childhood home .", "1": "Taylor has a good relationship with Taylor 's parents .", "2": "It is not true that Taylor grew up in a health - conscious childhood home .", "3": "It is not true that Taylor has a good relationship with Taylor 's parents .", "4": "Taylor visits the gym at least once a day .", "5": "Taylor is likely to fulfill Taylor 's nutritional daily intakes ."}, {"0": "Taylor fulfills Taylor 's nutritional daily intakes .", "1": "Taylor eats salads regularly ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "5"], "4": ["2"]}, {"3": ["0", "5"]}, {"1": ["3"]}, {"0": ["5", "(¬2)"], "1": ["(¬3)"]}, {}], "predicted_steps": [true, false, false, false, false]}
{"text": "All people who eat salads regularly are very conscious about their health and eating habits. All people who grew up in health-conscious childhood homes eat salads regularly. All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes. If people have good relationships with their parents, then they fulfill their nutritional daily intakes. If people have good relationships with their parents, then they do not eat salads regularly. If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes. It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Taylor visits the gym at least once a day?", "id": "174", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All people who eat salads regularly are very conscious about their health and eating habits.\nPremise 1.2: All people who grew up in health-conscious childhood homes eat salads regularly.\nConclusion 1: People who grew up in health-conscious childhood homes are very conscious about their health and eating habits.\n\nPremise 2.1: All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes.\nPremise 2.2: If people have good relationships with their parents, then they fulfill their nutritional daily intakes.\nConclusion 2: People who have good relationships with their parents grew up in health-conscious childhood homes.\n\nPremise 3.1: If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.\nPremise 3.2: It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents.\nConclusion 3: Taylor visits the gym at least once a day.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [((7→8)∪(9→a)), ((2∧3)⊻(4∧5))]]", "logic_conclusion": "[(4→5), (4→5), 6]", "correspondance": [{"0": "X is a person who eats salads regularly .", "1": "X is very conscious about their health and eating habits .", "2": "X is a person who grew up in health - conscious childhood homes .", "3": "X eats salads regularly .", "4": "X is a person who grew up in health - conscious childhood homes .", "5": "X is very conscious about their health and eating habits ."}, {"0": "X is a person who fulfills their nutritional daily intakes .", "1": "X grew up in health - conscious childhood homes .", "2": "X have good relationships with people 's parents .", "3": "X fulfill X 's nutritional daily intakes .", "4": "X is a person who has good relationships with their parents .", "5": "X grew up in health - conscious childhood homes ."}, {"0": "X visit the gym at least once a day .", "1": "X always fulfill X 's daily nutritional intakes .", "2": "It is both true that Taylor grew up in a health - conscious childhood home .", "3": "Taylor has a good relationship with Taylor 's parents .", "4": "It is not true that Taylor grew up in a health - conscious childhood home .", "5": "It is not true that Taylor has a good relationship with Taylor 's parents .", "6": "Taylor visits the gym at least once a day .", "7": "the gym visit the gym at least once a day .", "8": "the gym always fulfill the gym 's daily nutritional intakes .", "9": "Taylor visit the gym at least once a day .", "a": "Taylor always fulfill Taylor 's daily nutritional intakes ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"], "1": ["5"]}, {"3": ["0"], "1": ["5"]}, {"6": ["9"], "2": ["(¬4)"], "3": ["(¬5)"]}], "predicted_steps": [true, false, false]}
{"text": "All people who eat salads regularly are very conscious about their health and eating habits. All people who grew up in health-conscious childhood homes eat salads regularly. All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes. If people have good relationships with their parents, then they fulfill their nutritional daily intakes. If people have good relationships with their parents, then they do not eat salads regularly. If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes. It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Taylor neither grew up in a health-conscious childhood home nor does she visit the gym at least once a day?", "id": "175", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All people who eat salads regularly are very conscious about their health and eating habits.\nPremise 1.2: All people who grew up in health-conscious childhood homes eat salads regularly.\nConclusion 1: People who grew up in health-conscious childhood homes are very conscious about their health and eating habits.\n\nPremise 2.1: All people who fulfill their nutritional daily intakes grew up in health-conscious childhood homes.\nPremise 2.2: If people have good relationships with their parents, then they fulfill their nutritional daily intakes.\nConclusion 2: People who have good relationships with their parents grew up in health-conscious childhood homes.\n\nPremise 3.1: If people visit the gym at least once a day, then they always fulfill their daily nutritional intakes.\nConclusion 3: People who visit the gym at least once a day are very conscious about their health and eating habits.\n\nPremise 4.1: It is either both true that Taylor grew up in a health-conscious childhood home and she has a good relationship with her parents, or it is true that Taylor neither grew up in a health-conscious childhood home nor has a good relationship with her parents.\nConclusion 4: Taylor either grew up in a health-conscious childhood home and has a good relationship with her parents, or she didn't grow up in a health-conscious childhood home and doesn't have a good relationship with her parents.\n\nPremise 5.1: Taylor doesn't visit the gym at least once a day.\nConclusion 5: Taylor neither grew up in a health-conscious childhood home nor visits the gym at least once a day.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [(0→1)], [((0∧1)⊻(2∧3))], [0]]", "logic_conclusion": "[(4→5), (4→5), (2→3), ((4∧5)⊻(6∧7)), (1∧2)]", "correspondance": [{"0": "X is a person who eats salads regularly .", "1": "X is very conscious about their health and eating habits .", "2": "X is a person who grew up in health - conscious childhood homes .", "3": "X eats salads regularly .", "4": "X is a person who grew up in health - conscious childhood homes .", "5": "X is very conscious about their health and eating habits ."}, {"0": "X is a person who fulfills their nutritional daily intakes .", "1": "X grew up in health - conscious childhood homes .", "2": "X have good relationships with people 's parents .", "3": "X fulfill X 's nutritional daily intakes .", "4": "X is a person who has good relationships with their parents .", "5": "X grew up in health - conscious childhood homes ."}, {"0": "X visit the gym at least once a day .", "1": "X always fulfill X 's daily nutritional intakes .", "2": "X is a person who visits the gym at least once a day .", "3": "X is very conscious about their health and eating habits ."}, {"0": "It is both true that Taylor grew up in a health - conscious childhood home .", "1": "Taylor has a good relationship with Taylor 's parents .", "2": "It is not true that Taylor grew up in a health - conscious childhood home .", "3": "It is not true that Taylor has a good relationship with Taylor 's parents .", "4": "Taylor grew up in a health - conscious childhood home .", "5": "Taylor has a good relationship with Taylor 's parents .", "6": "Taylor did n't grow up in a health - conscious childhood home .", "7": "Taylor does n't have a good relationship with Taylor 's parents ."}, {"0": "Taylor does n't visit the gym at least once a day .", "1": "Taylor did not grow up in a health - conscious childhood home .", "2": "Taylor does not visit the gym at least once a day ."}], "errors": [[]], "entailments_dict": [{"3": ["0"], "4": ["2"], "1": ["5"]}, {"3": ["0"], "1": ["5"]}, {"2": ["0"], "1": ["3"]}, {"7": ["3", "(¬1)"], "4": ["0", "(¬2)"], "6": ["2", "(¬0)"], "5": ["1", "(¬3)"], "2": ["6"], "1": ["5", "(¬3)"], "3": ["7"], "0": ["4", "(¬2)"], "(¬7)": ["1"], "(¬4)": ["2"], "(¬6)": ["0"], "(¬5)": ["3"]}, {"2": ["0"], "0": ["2"]}], "predicted_steps": [true, false, true, false, false]}
{"text": "[BG] The Olympic games is a sporting event. The last Olympic games was in Tokyo. The United States won the most medals in Tokyo.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The world championships is a sporting event?", "id": "176", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: The Olympic games is a sporting event.\nPremise 1.2: The last Olympic games was in Tokyo.\nConclusion 1: The Olympic games in Tokyo was a sporting event.\n\nPremise 2.1: The United States won the most medals in Tokyo.\nConclusion 2: The United States won the most medals in the Olympic games in Tokyo.\n\nPremise 3.1: The Olympic games in Tokyo was a sporting event.\nPremise 3.2: The United States won the most medals in the Olympic games in Tokyo.\nConclusion 3: The United States won the most medals in a sporting event.\n\nPremise 4.1: The world championships is a sporting event.\nConclusion 4: The world championships is a sporting event.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, 1], [0], [0, 1], [0]]", "logic_conclusion": "[2, 1, 2, 1]", "correspondance": [{"0": "The Olympic games is a sporting event .", "1": "The last Olympic games was in Tokyo .", "2": "The Olympic games in Tokyo was a sporting event ."}, {"0": "the United States won the most medals in Tokyo .", "1": "the United States won the most medals in the Olympic games in Tokyo ."}, {"0": "The Olympic games in Tokyo was a sporting event .", "1": "The United States won the most medals in the Olympic games in Tokyo .", "2": "The United States won the most medals in a sporting event ."}, {"0": "the world championships is a sporting event .", "1": "the world championships is a sporting event ."}], "errors": [[]], "entailments_dict": [{"1": ["0", "2"], "2": ["0"], "0": ["2"]}, {"1": ["0"], "0": ["1"]}, {"1": ["0", "2"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [true, true, true, true]}
{"text": "[BG] The Olympic games is a sporting event. The last Olympic games was in Tokyo. The United States won the most medals in Tokyo.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The last Olympic games were not in Tokyo?", "id": "177", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: The last Olympic games was in Tokyo.\nPremise 1.2: The United States won the most medals in Tokyo.\nConclusion 1: The United States won the most medals in the last Olympic games.\nPremise 2.1: The last Olympic games were not in Tokyo.\nConclusion 2: The statement \"The last Olympic games were not in Tokyo\" is false.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, 1], [0]]", "logic_conclusion": "[2, 1]", "correspondance": [{"0": "the last Olympic games was in Tokyo .", "1": "The United States won the most medals in Tokyo .", "2": "The United States won the most medals in the last Olympic games ."}, {"0": "the last Olympic games were not in Tokyo .", "1": "The statement \" the last Olympic games were not in Tokyo \" is false ."}], "errors": [[]], "entailments_dict": [{"1": ["2"]}, {"0": ["1"], "1": ["(¬0)"], "(¬1)": ["0"]}], "predicted_steps": [true, "Contradiction in the premises"]}
{"text": "[BG] The Olympic games is a sporting event. The last Olympic games was in Tokyo. The United States won the most medals in Tokyo.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The United States won the most medals in the last Olympic games?", "id": "178", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: The last Olympic games was in Tokyo.\nPremise 1.2: The United States won the most medals in Tokyo.\nConclusion 1: The United States won the most medals in the last Olympic games.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, 1]]", "logic_conclusion": "[2]", "correspondance": [{"0": "the last Olympic games was in Tokyo .", "1": "The United States won the most medals in Tokyo .", "2": "The United States won the most medals in the last Olympic games ."}], "errors": [[]], "entailments_dict": [{"1": ["2"]}], "predicted_steps": [true]}
{"text": "All horses have hooves. No humans have hooves.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Some humans are horses?", "id": "179", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All horses have hooves.\nPremise 1.2: No humans have hooves.\nConclusion 1: Humans do not have hooves.\n\nPremise 2.1: Some humans are horses.\nConclusion 2: Some humans have hooves.\n\nPremise 3.1: Humans do not have hooves.\nPremise 3.2: Some humans have hooves.\nConclusion 3: It is uncertain whether some humans are horses.\n\nTherefore, the answer is C. Uncertain.", "logic_premises": "[[(0→1), (2→3)], [0], [(0→1), 2]]", "logic_conclusion": "[(4→5), 1, 3]", "correspondance": [{"0": "X is a horse .", "1": "X has hooves .", "2": "X is a human .", "3": "X does not have hooves .", "4": "X is a Human .", "5": "X does not has hooves ."}, {"0": "Some humans are horses .", "1": "Some humans have hooves ."}, {"0": "X is a Human .", "1": "X does not has hooves .", "2": "Some humans have hooves .", "3": "It is uncertain that some humans are horses ."}], "errors": [[]], "entailments_dict": [{"4": ["2", "(¬1)"], "3": ["5", "(¬1)"], "(¬5)": ["0"], "(¬0)": ["2"]}, {"1": ["(¬0)"]}, {}], "predicted_steps": [true, false, false]}
{"text": "Susan flies to LGA airport. The departure and arrival can not be the same airport. John flies from LGA airport.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Susan flies from LGA airport?", "id": "180", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: The departure and arrival airports cannot be the same.\nPremise 1.2: Susan flies to LGA airport.\nConclusion 1: Susan's departure airport is not LGA.\n\nPremise 2.1: John flies from LGA airport.\nConclusion 2: John's arrival airport is LGA.\n\nPremise 3.1: Susan's departure airport is not LGA.\nPremise 3.2: John's arrival airport is LGA.\nConclusion 3: Susan and John cannot fly from the same airport.\n\nPremise 4.1: Susan flies to LGA airport.\nPremise 4.2: Susan and John cannot fly from the same airport.\nConclusion 4: Susan does not fly from LGA airport.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, 1], [0], [0, 1], [0, (1∧2)]]", "logic_conclusion": "[2, 1, (2∧3), 3]", "correspondance": [{"0": "The departure and arrival airports can not be the same .", "1": "Susan flies to LGA airport .", "2": "Susan 's departure airport is not LGA airport ."}, {"0": "John flies from LGA airport .", "1": "John 's arrival airport is LGA airport ."}, {"0": "Susan 's 's departure airport is not LGA .", "1": "John 's 's arrival airport is LGA .", "2": "Susan 's can not fly from the same airport .", "3": "John 's can not fly from the same airport ."}, {"0": "Susan flies to LGA airport .", "1": "Susan can not fly from LGA airport .", "2": "John can not fly from LGA airport .", "3": "Susan does not fly from LGA airport ."}], "errors": [[]], "entailments_dict": [{"2": ["0", "(¬1)"], "1": ["(¬0)"], "(¬2)": ["1"], "(¬1)": ["0"]}, {"1": ["0"], "0": ["1"]}, {"2": ["0"]}, {"3": ["1", "(¬0)"], "1": ["3", "(¬0)"], "0": ["(¬1)"], "(¬3)": ["0"]}], "predicted_steps": ["Contradiction in the premises", true, false, "Contradiction in the premises"]}
{"text": "Susan flies to LGA airport. The departure and arrival can not be the same airport. John flies from LGA airport.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that John flies to LGA airport?", "id": "181", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: The departure and arrival airports cannot be the same.\nPremise 1.2: Susan flies to LGA airport.\nConclusion 1: Susan's departure airport is not LGA.\n\nPremise 2.1: John flies from LGA airport.\nPremise 2.2: Susan's arrival airport is LGA.\nConclusion 2: John's departure airport is not LGA.\n\nPremise 3.1: If John flies to LGA airport, then his departure airport is LGA.\nConclusion 3: John does not fly to LGA airport.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, 1], [0, 1], [(0→1)]]", "logic_conclusion": "[2, 2, 2]", "correspondance": [{"0": "The departure and arrival airports can not be the same .", "1": "Susan flies to LGA airport .", "2": "Susan 's departure airport is not LGA airport ."}, {"0": "John flies from LGA airport .", "1": "Susan 's arrival airport is LGA airport .", "2": "John 's departure airport is not LGA airport ."}, {"0": "John flies to LGA airport .", "1": "John 's departure airport is LGA airport .", "2": "John does not fly to LGA airport ."}], "errors": [[]], "entailments_dict": [{"2": ["0", "(¬1)"], "1": ["(¬0)"], "(¬2)": ["1"], "(¬1)": ["0"]}, {"2": ["(¬0)"], "(¬2)": ["0"]}, {"2": ["(¬1)"], "(¬2)": ["0"]}], "predicted_steps": ["Contradiction in the premises", false, false]}
{"text": "No one nice to animals is mean to animals. Some grumpy people are mean to animals. All animal lovers are nice to animals. If someone owns a pet, then they love animals. Tom is a pet owner.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Tom is a grumpy person?", "id": "182", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: No one nice to animals is mean to animals.\nPremise 1.2: Some grumpy people are mean to animals.\nConclusion 1: Some grumpy people are not nice to animals.\n\nPremise 2.1: All animal lovers are nice to animals.\nPremise 2.2: If someone owns a pet, then they love animals.\nConclusion 2: Tom, a pet owner, loves animals.\n\nPremise 3.1: Tom loves animals.\nPremise 3.2: Some grumpy people are mean to animals.\nConclusion 3: Tom is not a grumpy person.\n\nTherefore, the answer is B. No. It is not true that Tom is a grumpy person.", "logic_premises": "[[(0→1), (2→3)], [(6→7), (8→9)], [0, (4→5)]]", "logic_conclusion": "[(4→5), (4∧5), 3]", "correspondance": [{"0": "X is a person nice to animals .", "1": "X is not mean to animals .", "2": "X is a Some a grumpy person .", "3": "X is mean to an animal .", "4": "X is a Some a grumpy person .", "5": "X is not nice to an animal ."}, {"0": "X is animal a lover .", "1": "X is nice to an animal .", "2": "X owns a pet .", "3": "X love animals .", "4": "Tom , loves animals .", "5": "a pet owner , loves animals .", "6": "Tom, a pet owner, is animal a lover .", "7": "Tom, a pet owner, is nice to an animal .", "8": "Tom, a pet owner, owns a pet .", "9": "Tom, a pet owner, love animals ."}, {"0": "Tom loves animals .", "1": "X is a Some a grumpy person .", "2": "X is mean to an animal .", "3": "Tom is not a grumpy person .", "4": "Tom is a Some a grumpy person .", "5": "Tom is mean to an animal ."}], "errors": [[]], "entailments_dict": [{"4": ["2"], "1": ["5", "(¬3)"], "3": ["5", "(¬1)"], "(¬5)": ["0"]}, {"9": ["6", "4", "5"], "7": ["8", "4", "5"], "4": ["6", "8"], "5": ["6", "8"]}, {"5": ["(¬0)"], "(¬3)": ["4"]}], "predicted_steps": [true, false, true]}
{"text": "No one nice to animals is mean to animals. Some grumpy people are mean to animals. All animal lovers are nice to animals. If someone owns a pet, then they love animals. Tom is a pet owner.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Tom is not a grumpy person and mean to animals?", "id": "183", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: No one nice to animals is mean to animals.\nPremise 1.2: Some grumpy people are mean to animals.\nConclusion 1: Grumpy people are not nice to animals.\n\nPremise 2.1: All animal lovers are nice to animals.\nPremise 2.2: If someone owns a pet, then they love animals.\nConclusion 2: Pet owners are animal lovers.\n\nPremise 3.1: Tom is a pet owner.\nConclusion 3: Tom is an animal lover.\n\nPremise 4.1: Tom is an animal lover.\nPremise 4.2: Grumpy people are not nice to animals.\nConclusion 4: Tom is not a grumpy person.\n\nConclusion 5: Tom is not mean to animals.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(0→1), (2→3)], [(0→1), (2→3)], [0], [0, (4→5)]]", "logic_conclusion": "[(4→5), (4→5), 1, 3]", "correspondance": [{"0": "X is a person nice to animals .", "1": "X is not mean to animals .", "2": "X is a Some a grumpy person .", "3": "X is mean to an animal .", "4": "X is a Grumpy person .", "5": "X is not nice to an animal ."}, {"0": "X is animal a lover .", "1": "X is nice to an animal .", "2": "X owns a pet .", "3": "X love animals .", "4": "X is Pet an owner .", "5": "X is animal a lover ."}, {"0": "Tom is a pet owner .", "1": "Tom is an animal lover ."}, {"0": "Tom is an animal lover .", "1": "X is a Grumpy person .", "2": "X is not nice to an animal .", "3": "Tom is not a grumpy person .", "4": "Tom is a Grumpy person .", "5": "Tom is not nice to an animal ."}], "errors": [[]], "entailments_dict": [{"4": ["2"], "1": ["5", "(¬3)"], "3": ["5", "(¬1)"], "(¬5)": ["0"]}, {"3": ["0", "5"], "4": ["0", "2"]}, {"1": ["0"], "0": ["1"]}, {"5": ["(¬0)"], "(¬3)": ["4"]}], "predicted_steps": [true, true, true, true]}
{"text": "No one nice to animals is mean to animals. Some grumpy people are mean to animals. All animal lovers are nice to animals. If someone owns a pet, then they love animals. Tom is a pet owner.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Tom is not a grumpy person and mean to animals, then Tom is neither a grumpy person nor an Animal Lover?", "id": "184", "ground_truth": "False", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: No one nice to animals is mean to animals.\nPremise 1.2: Some grumpy people are mean to animals.\nConclusion 1: Some grumpy people are not nice to animals.\n\nPremise 2.1: All animal lovers are nice to animals.\nPremise 2.2: If someone owns a pet, then they love animals.\nConclusion 2: Tom, a pet owner, loves animals.\n\nPremise 3.1: If Tom is not a grumpy person and mean to animals, then Tom is neither a grumpy person nor an animal lover.\nPremise 3.2: Tom is a pet owner and loves animals.\nConclusion 3: Tom is not a grumpy person and mean to animals.\n\nConclusion: Therefore, the answer is A. Yes. It is true that if Tom is not a grumpy person and mean to animals, then Tom is neither a grumpy person nor an animal lover.", "logic_premises": "[[(0→1), (2→3)], [(6→7), (8→9)], [(0→(1∧2)), (3∧4)]]", "logic_conclusion": "[(4→5), (4∧5), 5]", "correspondance": [{"0": "X is a person nice to animals .", "1": "X is not mean to animals .", "2": "X is a Some a grumpy person .", "3": "X is mean to an animal .", "4": "X is a Some a grumpy person .", "5": "X is not nice to an animal ."}, {"0": "X is animal a lover .", "1": "X is nice to an animal .", "2": "X owns a pet .", "3": "X love animals .", "4": "Tom , loves animals .", "5": "a pet owner , loves animals .", "6": "Tom, a pet owner, is animal a lover .", "7": "Tom, a pet owner, is nice to an animal .", "8": "Tom, a pet owner, owns a pet .", "9": "Tom, a pet owner, love animals ."}, {"0": "Tom is not a grumpy person and mean to animals .", "1": "Tom is not a grumpy person .", "2": "Tom is not an animal lover .", "3": "Tom is a pet owner .", "4": "Tom loves animals .", "5": "Tom is not a grumpy person and mean to animals ."}], "errors": [[]], "entailments_dict": [{"4": ["2"], "1": ["5", "(¬3)"], "3": ["5", "(¬1)"], "(¬5)": ["0"]}, {"9": ["6", "4", "5"], "7": ["8", "4", "5"], "4": ["6", "8"], "5": ["6", "8"]}, {"5": ["0"], "1": ["5"], "4": ["(¬2)"], "2": ["(¬4)", "(¬3)"]}], "predicted_steps": [true, false, false]}
{"text": "A podcast is not a novel. [BG] If a person is born in American City, the person is American. [BG] If a book is novel and it is written by a person, then the person is a novel writer. Dani Shapiro is an American writer. Family History is written by Dani Shapiro. Family History is a novel written in 2003. Dani Shapiro created a podcast called Family Secrets. [BG] Boston is an American city.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Dani Shapiro is a novel writer?", "id": "185", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a person is born in American City, the person is American.\nPremise 1.2: Dani Shapiro is an American writer.\nConclusion 1: Dani Shapiro is American.\n\nPremise 2.1: If a book is a novel and it is written by a person, then the person is a novel writer.\nPremise 2.2: Family History is a novel written in 2003.\nPremise 2.3: Family History is written by Dani Shapiro.\nConclusion 2: Dani Shapiro is a novel writer.\n\nPremise 3.1: Dani Shapiro created a podcast called Family Secrets.\nPremise 3.2: A podcast is not a novel.\nConclusion 3: Dani Shapiro did not create a novel called Family Secrets.\n\nConclusion 4: Dani Shapiro is a novel writer, but not for Family Secrets.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(((5∧6)→7)∪(((8∧9)→a)∪((b∧c)→d))), 3], [((((7∧8)∧2)→3)∪((((9∧a)∧2)→3)∪(((b∧c)∧2)→3))), 4, 5], [0, ((4→5)∪((6→7)∪(8→9)))]]", "logic_conclusion": "[4, 6, 3]", "correspondance": [{"0": "X is a person", "1": "X is born in American City .", "2": "X is American .", "3": "Dani Shapiro is an American writer .", "4": "Dani Shapiro is American .", "5": "American City is a person", "6": "American City is born in American City .", "7": "American City is American .", "8": "Dani Shapiro is a person", "9": "Dani Shapiro is born in American City .", "a": "Dani Shapiro is American .", "b": "the person is a person", "c": "the person is born in American City .", "d": "the person is American ."}, {"0": "X is a book", "1": "X is a novel .", "2": "a book is written by a person .", "3": "a person is a novel writer .", "4": "Family History is a novel written in 2003 .", "5": "Family History is written by Dani Shapiro .", "6": "Dani Shapiro is a novel writer .", "7": "Dani Shapiro is a book", "8": "Dani Shapiro is a novel .", "9": "Family History is a book", "a": "Family History is a novel .", "b": "the person is a book", "c": "the person is a novel ."}, {"0": "Dani Shapiro created a podcast called Family Secrets .", "1": "X is A podcast", "2": "X is not a novel .", "3": "Dani Shapiro did not create a novel called Family Secrets .", "4": "Secrets is A podcast", "5": "Secrets is not a novel .", "6": "Dani Shapiro is A podcast", "7": "Dani Shapiro is not a novel .", "8": "Family is A podcast", "9": "Family is not a novel ."}], "errors": [[]], "entailments_dict": [{"a": ["3", "4"], "3": ["8", "4"], "4": ["8", "3"]}, {"4": ["2", "7", "9", "a", "5"], "5": ["4", "9", "a", "2", "6"], "6": ["2", "9", "4", "5"], "3": ["6"]}, {"7": ["3"], "9": ["3"], "5": ["3"]}], "predicted_steps": [true, true, false]}
{"text": "A podcast is not a novel. [BG] If a person is born in American City, the person is American. [BG] If a book is novel and it is written by a person, then the person is a novel writer. Dani Shapiro is an American writer. Family History is written by Dani Shapiro. Family History is a novel written in 2003. Dani Shapiro created a podcast called Family Secrets. [BG] Boston is an American city.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Family Secrets is a novel?", "id": "186", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: A podcast is not a novel.\nPremise 1.2: Family Secrets is a podcast.\nConclusion 1: Family Secrets is not a novel.\n\nTherefore, the answer is B. No.", "logic_premises": "[[(4→5), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X is A podcast", "1": "X is not a novel .", "2": "Family Secrets is a podcast .", "3": "Family Secrets is not a novel .", "4": "Family Secrets is A podcast", "5": "Family Secrets is not a novel ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "3"], "5": ["3"]}], "predicted_steps": [true]}
{"text": "A podcast is not a novel. [BG] If a person is born in American City, the person is American. [BG] If a book is novel and it is written by a person, then the person is a novel writer. Dani Shapiro is an American writer. Family History is written by Dani Shapiro. Family History is a novel written in 2003. Dani Shapiro created a podcast called Family Secrets. [BG] Boston is an American city.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Dani Shapiro was born in Boston?", "id": "187", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If a person is born in American City, the person is American.\nPremise 1.2: Boston is an American city.\nConclusion 1: A person born in Boston is American.\n\nPremise 2.1: Dani Shapiro is an American writer.\nPremise 2.2: Dani Shapiro was born in Boston.\nConclusion 2: Dani Shapiro was born in an American city.\n\nPremise 3.1: A podcast is not a novel.\nPremise 3.2: Family History is a novel written in 2003.\nConclusion 3: Family History is not a podcast.\n\nPremise 4.1: Dani Shapiro created a podcast called Family Secrets.\nPremise 4.2: Family Secrets is not a novel.\nConclusion 4: Dani Shapiro created a podcast that is not a novel.\n\nPremise 5.1: Dani Shapiro was born in Boston.\nConclusion 5: It is true that Dani Shapiro was born in Boston.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(((5∧6)→7)∪(((8∧9)→a)∪((b∧c)→d))), 3], [0, 1], [(4→5), 2], [0, ((4→5)∪((6→7)∪((8→9)∪(a→b))))], [0]]", "logic_conclusion": "[4, 2, 3, 3, 1]", "correspondance": [{"0": "X is a person", "1": "X is born in American City .", "2": "X is American .", "3": "Boston is an American city .", "4": "A person born in Boston is American .", "5": "American City is a person", "6": "American City is born in American City .", "7": "American City is American .", "8": "Boston is a person", "9": "Boston is born in American City .", "a": "Boston is American .", "b": "the person is a person", "c": "the person is born in American City .", "d": "the person is American ."}, {"0": "Dani Shapiro is an American writer .", "1": "Dani Shapiro was born in Boston .", "2": "Dani Shapiro was born in an American city ."}, {"0": "X is A podcast", "1": "X is not a novel .", "2": "Family History is a novel written in 2003 .", "3": "Family History is not a podcast .", "4": "Family History is A podcast", "5": "Family History is not a novel ."}, {"0": "Dani Shapiro created a podcast called Family Secrets .", "1": "X is a podcast called Family Secrets", "2": "X is not a novel .", "3": "Dani Shapiro created a podcast called Family Secrets .", "4": "Secrets is a podcast called Family Secrets", "5": "Secrets is not a novel .", "6": "Family Secrets is a podcast called Family Secrets", "7": "Family Secrets is not a novel .", "8": "Dani Shapiro is a podcast called Family Secrets", "9": "Dani Shapiro is not a novel .", "a": "Family is a podcast called Family Secrets", "b": "Family is not a novel ."}, {"0": "Dani Shapiro was born in Boston .", "1": "It is true that Dani Shapiro was born in Boston ."}], "errors": [[]], "entailments_dict": [{"a": ["3", "4"], "7": ["3"], "4": ["3", "b"], "3": ["4"], "d": ["4"]}, {"1": ["0", "2"]}, {"2": ["3", "(¬5)"], "(¬3)": ["4"]}, {"3": ["0", "6"], "0": ["3", "6"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [true, true, true, true, true]}
{"text": "Some basketball players are not American. All basketball players are tall. If someone is tall, they wear large shoes. If someone wears large shoes, they wear large-sized clothes. Yuri does not wear large-size clothes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Yuri is an American?", "id": "188", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All basketball players are tall.\nPremise 1.2: If someone is tall, they wear large shoes.\nPremise 1.3: If someone wears large shoes, they wear large-sized clothes.\nPremise 2.1: Yuri does not wear large-size clothes.\nConclusion 2: Yuri does not wear large shoes.\nPremise 3.1: If someone is a basketball player, they are tall.\nConclusion 3: Yuri is not a basketball player.\nPremise 4.1: Yuri is not a basketball player.\nConclusion 4: Yuri is not American.\n\nTherefore, the answer is B. No. It is not true that Yuri is an American.", "logic_premises": "[[(9→a), (b→c), (d→(e∧f)), 7], [(3→4)], [0]]", "logic_conclusion": "[8, 2, 1]", "correspondance": [{"0": "X is basketball a player .", "1": "X is tall .", "2": "X is tall .", "3": "X wear large shoes .", "4": "X wears large shoes .", "5": "X wear large clothes .", "6": "X wear sized clothes .", "7": "Yuri does not wear large - size clothes .", "8": "Yuri does not wear large shoes .", "9": "Yuri is basketball a player .", "a": "Yuri is tall .", "b": "Yuri is tall .", "c": "Yuri wear large shoes .", "d": "Yuri wears large shoes .", "e": "Yuri wear large clothes .", "f": "Yuri wear sized clothes ."}, {"0": "X is a basketball player .", "1": "X are tall .", "2": "Yuri is not a basketball player .", "3": "Yuri is a basketball player .", "4": "Yuri are tall ."}, {"0": "Yuri is not a basketball player .", "1": "Yuri is not American ."}], "errors": [[]], "entailments_dict": [{"c": ["d"], "a": ["b"], "7": ["(¬e)"], "f": ["(¬7)"], "e": ["(¬7)"], "8": ["(¬c)"], "(¬8)": ["d"]}, {"(¬2)": ["3"]}, {}], "predicted_steps": [true, false, false]}
{"text": "Some basketball players are not American. All basketball players are tall. If someone is tall, they wear large shoes. If someone wears large shoes, they wear large-sized clothes. Yuri does not wear large-size clothes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Yuri is not an American basketball player?", "id": "189", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All basketball players are tall.\nPremise 1.2: If someone is tall, they wear large shoes.\nPremise 1.3: If someone wears large shoes, they wear large-sized clothes.\nPremise 2.1: Yuri does not wear large-size clothes.\nConclusion 2: Yuri does not wear large shoes.\nPremise 3.1: If someone is a basketball player, they are either American or not American.\nPremise 3.2: If someone is not American, they are not an American basketball player.\nConclusion 3: If Yuri is a basketball player, they are not an American basketball player.\nConclusion 4: Yuri is not an American basketball player.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[(9→a), (b→c), (d→(e∧f)), 7], [(7→(8⊻9)), (a→b)]]", "logic_conclusion": "[8, (5→6)]", "correspondance": [{"0": "X is basketball a player .", "1": "X is tall .", "2": "X is tall .", "3": "X wear large shoes .", "4": "X wears large shoes .", "5": "X wear large clothes .", "6": "X wear sized clothes .", "7": "Yuri does not wear large - size clothes .", "8": "Yuri does not wear large shoes .", "9": "Yuri is basketball a player .", "a": "Yuri is tall .", "b": "Yuri is tall .", "c": "Yuri wear large shoes .", "d": "Yuri wears large shoes .", "e": "Yuri wear large clothes .", "f": "Yuri wear sized clothes ."}, {"0": "X is a basketball player .", "1": "X are American .", "2": "X are not American .", "3": "X is not American .", "4": "X are not an American basketball player .", "5": "Yuri is a basketball player .", "6": "Yuri are not an American basketball player .", "7": "Yuri is a basketball player .", "8": "Yuri are American .", "9": "Yuri are not American .", "a": "Yuri is not American .", "b": "Yuri are not an American basketball player ."}], "errors": [[]], "entailments_dict": [{"c": ["d"], "a": ["b"], "7": ["(¬e)"], "f": ["(¬7)"], "e": ["(¬7)"], "8": ["(¬c)"], "(¬8)": ["d"]}, {"9": ["a", "6"], "5": ["7"], "b": ["6", "(¬8)"], "8": ["(¬9)"], "(¬6)": ["7"]}], "predicted_steps": [true, false]}
{"text": "Some basketball players are not American. All basketball players are tall. If someone is tall, they wear large shoes. If someone wears large shoes, they wear large-sized clothes. Yuri does not wear large-size clothes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Yuri is an American basketball player?", "id": "190", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: All basketball players are tall.\nPremise 1.2: If someone is tall, they wear large shoes.\nPremise 1.3: If someone wears large shoes, they wear large-sized clothes.\nPremise 2.1: Yuri does not wear large-size clothes.\nConclusion 2: Yuri does not wear large shoes.\nPremise 3.1: If someone is a basketball player, they are either American or not American.\nPremise 3.2: Yuri is not American.\nConclusion 3: Yuri is not an American basketball player.\n\nTherefore, the answer is B. No.", "logic_premises": "[[(9→a), (b→c), (d→(e∧f)), 7], [(5→(6⊻7)), 3]]", "logic_conclusion": "[8, 4]", "correspondance": [{"0": "X is basketball a player .", "1": "X is tall .", "2": "X is tall .", "3": "X wear large shoes .", "4": "X wears large shoes .", "5": "X wear large clothes .", "6": "X wear sized clothes .", "7": "Yuri does not wear large - size clothes .", "8": "Yuri does not wear large shoes .", "9": "Yuri is basketball a player .", "a": "Yuri is tall .", "b": "Yuri is tall .", "c": "Yuri wear large shoes .", "d": "Yuri wears large shoes .", "e": "Yuri wear large clothes .", "f": "Yuri wear sized clothes ."}, {"0": "X is a basketball player .", "1": "X are American .", "2": "X are not American .", "3": "Yuri is not American .", "4": "Yuri is not an American basketball player .", "5": "Yuri is a basketball player .", "6": "Yuri are American .", "7": "Yuri are not American ."}], "errors": [[]], "entailments_dict": [{"c": ["d"], "a": ["b"], "7": ["(¬e)"], "f": ["(¬7)"], "e": ["(¬7)"], "8": ["(¬c)"], "(¬8)": ["d"]}, {"7": ["3", "4"], "4": ["3"], "3": ["4", "(¬6)"], "6": ["(¬3)", "(¬7)"], "(¬4)": ["5"]}], "predicted_steps": [true, true]}
{"text": "Some basketball players are not American. All basketball players are tall. If someone is tall, they wear large shoes. If someone wears large shoes, they wear large-sized clothes. Yuri does not wear large-size clothes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Yuri does not wear large shoes, then Yuri is an American basketball player?", "id": "191", "ground_truth": "False", "reasoning": " Premise 1.1: All basketball players are tall.\nPremise 1.2: If someone is tall, they wear large shoes.\nConclusion 1: All basketball players wear large shoes.\n\nPremise 2.1: If someone wears large shoes, they wear large-sized clothes.\nConclusion 2: All basketball players wear large-sized clothes.\n\nPremise 3.1: Yuri does not wear large-sized clothes.\nConclusion 3: Yuri does not wear large shoes.\n\nPremise 4.1: If Yuri does not wear large shoes, then Yuri is not a basketball player.\nConclusion 4: Yuri is not a basketball player.\n\nPremise 5.1: Some basketball players are not American.\nConclusion 5: Yuri is not an American basketball player.\n\nTherefore, the answer is B. No. It is not true that if Yuri does not wear large shoes, then Yuri is an American basketball player.", "logic_premises": "[[(0→1), (2→3)], [(0→(1∧2))], [(0∧1)], [(0→1)], [0]]", "logic_conclusion": "[(4→5), (3→(4∧5)), 2, 2, 1]", "correspondance": [{"0": "X is basketball a player .", "1": "X is tall .", "2": "X is tall .", "3": "X wear large shoes .", "4": "X is basketball a player .", "5": "X wears large shoes ."}, {"0": "X wears large shoes .", "1": "X wear large clothes .", "2": "X wear sized clothes .", "3": "X is basketball a player .", "4": "X wears large clothes .", "5": "X wears sized clothes ."}, {"0": "Yuri does not wear large clothes .", "1": "Yuri does not wear sized clothes .", "2": "Yuri does not wear large shoes ."}, {"0": "Yuri does not wear large shoes .", "1": "Yuri is not a basketball player .", "2": "Yuri is not a basketball player ."}, {"0": "Some basketball players are not American .", "1": "Yuri is not an American basketball player ."}], "errors": [[]], "entailments_dict": [{"1": ["2"], "4": ["0"], "3": ["5"]}, {"1": ["4", "5"], "2": ["5"]}, {}, {"1": ["2"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [true, false, false, false, true]}
{"text": "Some basketball players are not American. All basketball players are tall. If someone is tall, they wear large shoes. If someone wears large shoes, they wear large-sized clothes. Yuri does not wear large-size clothes.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that If Yuri is not an American basketball player, then Yuri is a basketball player?", "id": "192", "ground_truth": "False", "reasoning": " Here is my reasoning:\n\nPremise 1.1: All basketball players are tall.\nPremise 1.2: If someone is tall, they wear large shoes.\nPremise 1.3: If someone wears large shoes, they wear large-sized clothes.\nPremise 2.1: Yuri does not wear large-size clothes.\nConclusion 2: Yuri does not wear large shoes.\nPremise 3.1: If someone is a basketball player, they are tall.\nConclusion 3: Yuri is not a basketball player.\nPremise 4.1: Yuri is not an American basketball player.\nConclusion 4: Yuri is not a basketball player.\n\nTherefore, the answer is B. No. It is not true that if Yuri is not an American basketball player, then Yuri is a basketball player.", "logic_premises": "[[(9→a), (b→c), (d→(e∧f)), 7], [(3→4)], [0]]", "logic_conclusion": "[8, 2, 1]", "correspondance": [{"0": "X is basketball a player .", "1": "X is tall .", "2": "X is tall .", "3": "X wear large shoes .", "4": "X wears large shoes .", "5": "X wear large clothes .", "6": "X wear sized clothes .", "7": "Yuri does not wear large - size clothes .", "8": "Yuri does not wear large shoes .", "9": "Yuri is basketball a player .", "a": "Yuri is tall .", "b": "Yuri is tall .", "c": "Yuri wear large shoes .", "d": "Yuri wears large shoes .", "e": "Yuri wear large clothes .", "f": "Yuri wear sized clothes ."}, {"0": "X is a basketball player .", "1": "X are tall .", "2": "Yuri is not a basketball player .", "3": "Yuri is a basketball player .", "4": "Yuri are tall ."}, {"0": "Yuri is not an American basketball player .", "1": "Yuri is not a basketball player ."}], "errors": [[]], "entailments_dict": [{"c": ["d"], "a": ["b"], "7": ["(¬e)"], "f": ["(¬7)"], "e": ["(¬7)"], "8": ["(¬c)"], "(¬8)": ["d"]}, {"(¬2)": ["3"]}, {"1": ["0"], "0": ["1"]}], "predicted_steps": [true, false, true]}
{"text": "Events are either happy or sad. At least one event is happy.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that All events are sad?", "id": "193", "ground_truth": "False", "reasoning": " Reasoning:\n\nPremise 1.1: Events are either happy or sad.\nPremise 1.2: At least one event is happy.\nConclusion 1: Not all events are sad.\n\nPremise 2.1: Not all events are sad.\nConclusion 2: It is not true that all events are sad.\n\nTherefore, the answer is B. No.", "logic_premises": "[[(0→(1⊻2)), 3], [0]]", "logic_conclusion": "[4, (1→2)]", "correspondance": [{"0": "X is an Event .", "1": "X is happy .", "2": "X is sad .", "3": "At least one event is happy .", "4": "Not all events are sad ."}, {"0": "Not all events are sad .", "1": "X is an event .", "2": "It is not true that X is sad ."}], "errors": [[]], "entailments_dict": [{"1": ["3", "(¬2)"], "4": ["3"], "3": ["4"], "(¬4)": ["3"]}, {}], "predicted_steps": [true, false]}
{"text": "The winner of the 1992 du Maurier Classic was Steinhauer. Steinhauer participated in the 1992 du Maurier Classic. There was one six-way tie on the leaderboard and one person in the six-way tie was from Belgium. Descampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic. All people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Steinhauer was not the winner of the 1992 du Maurier Classic?", "id": "194", "ground_truth": "False", "reasoning": " Here is my reasoning:\n\nPremise 1.1: Steinhauer participated in the 1992 du Maurier Classic.\nPremise 1.2: The winner of the 1992 du Maurier Classic was Steinhauer.\nConclusion 1: Steinhauer participated in the 1992 du Maurier Classic and was the winner.\n\nPremise 2.1: There was one six-way tie on the leaderboard.\nPremise 2.2: One person in the six-way tie was from Belgium.\nConclusion 2: One person from Belgium was in the six-way tie on the leaderboard.\n\nPremise 3.1: Descampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.\nConclusion 3: Descampe was in the six-way tie on the leaderboard.\n\nPremise 4.1: All people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.\nConclusion 4: Descampe participated in the 1992 du Maurier Classic.\n\nPremise 5.1: Steinhauer participated in the 1992 du Maurier Classic and was the winner.\nPremise 5.2: Descampe participated in the 1992 du Maurier Classic.\nConclusion 5: Steinhauer and Descampe both participated in the 1992 du Maurier Classic.\n\nNow, let's answer the question:\n\nIs it true that Steinhauer was not the winner of the 1992 du Maurier Classic?\n\nA. Yes\nB. No\nC. Uncertain\n\nConclusion:\nB. No\n\nExplanation:\nWe have established that Steinhauer participated in the 1992 du Maurier Classic and was the winner. Therefore, the statement \"Steinhauer was not the winner of the 1992 du Maurier Classic\" is false. The answer is B. No.", "logic_premises": "[[0, 1], [0, 1], [(0∧1)], [((3→4)∪((5→6)∪(7→8)))], [(0∧1), 2]]", "logic_conclusion": "[(2∧3), 2, 2, 2, (3∧4)]", "correspondance": [{"0": "Steinhauer participated in the 1992 du Maurier Classic .", "1": "The winner of the 1992 du Maurier Classic was Steinhauer .", "2": "Steinhauer participated in the 1992 du Maurier Classic .", "3": "Steinhauer was the winner ."}, {"0": "There was one six - way tie on the leaderboard .", "1": "One person in one six - way tie on the leaderboard was from Belgium .", "2": "One person from Belgium was in the six - way tie on the leaderboard ."}, {"0": "Descampe is from Belgium .", "1": "Descampe is on the leaderboard of the 1992 du Maurier Classic .", "2": "Descampe was in the six - way tie on the leaderboard of the 1992 du Maurier Classic ."}, {"0": "X is a person on the leaderboard of the 1992 du Maurier Classic .", "1": "X participated in the 1992 du Maurier Classic .", "2": "Descampe participated in the 1992 du Maurier Classic .", "3": "the 1992 du Maurier Classic is a person on the leaderboard of the 1992 du Maurier Classic .", "4": "the 1992 du Maurier Classic participated in the 1992 du Maurier Classic .", "5": "Descampe is a person on the leaderboard of the 1992 du Maurier Classic .", "6": "Descampe participated in the 1992 du Maurier Classic .", "7": "the leaderboard of the 1992 du Maurier Classic is a person on the leaderboard of the 1992 du Maurier Classic .", "8": "the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic ."}, {"0": "Steinhauer participated in the 1992 du Maurier Classic .", "1": "Steinhauer was the winner .", "2": "Descampe participated in the 1992 du Maurier Classic .", "3": "Steinhauer both participated in the 1992 du Maurier Classic .", "4": "Descampe both participated in the 1992 du Maurier Classic ."}], "errors": [[]], "entailments_dict": [{"1": ["0", "3", "2"], "0": ["1", "2"], "3": ["1", "0"], "2": ["0", "1"]}, {"1": ["0", "2"], "2": ["0", "1"]}, {"2": ["1"], "1": ["2"]}, {"2": ["5", "(¬4)"], "6": ["2"], "4": ["2"], "8": ["2"]}, {"4": ["2"], "3": ["0"], "1": ["3"], "0": ["3"], "2": ["4"]}], "predicted_steps": [true, true, true, false, true]}
{"text": "The winner of the 1992 du Maurier Classic was Steinhauer. Steinhauer participated in the 1992 du Maurier Classic. There was one six-way tie on the leaderboard and one person in the six-way tie was from Belgium. Descampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic. All people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic?", "id": "195", "ground_truth": "Uncertain", "reasoning": " Here is my reasoning:\n\nPremise 1.1: Steinhauer participated in the 1992 du Maurier Classic.\nPremise 1.2: Steinhauer won the 1992 du Maurier Classic.\nConclusion 1: Steinhauer participated in the 1992 du Maurier Classic and won it.\n\nPremise 2.1: There was a six-way tie on the leaderboard in the 1992 du Maurier Classic.\nPremise 2.2: Descampe is from Belgium and is on the leaderboard of the 1992 du Maurier Classic.\nConclusion 2: Descampe is one of the six people in the tie on the leaderboard of the 1992 du Maurier Classic.\n\nPremise 3.1: All people on the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic.\nConclusion 3: Descampe participated in the 1992 du Maurier Classic.\n\nConclusion 4: Descampe is in the six-way tie in the leaderboard of the 1992 du Maurier Classic.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0, 1], [0, (1∧2)], [((3→4)∪((5→6)∪(7→8)))]]", "logic_conclusion": "[(2∧3), ((5→6)∪((7→8)∪((9→a)∪((b→c)∪((d→e)∪(f→g)))))), 2]", "correspondance": [{"0": "Steinhauer participated in the 1992 du Maurier Classic .", "1": "Steinhauer won the 1992 du Maurier Classic .", "2": "Steinhauer participated in the 1992 du Maurier Classic .", "3": "Steinhauer won the 1992 du Maurier Classic ."}, {"0": "There was a six - way tie on the leaderboard in the 1992 du Maurier Classic .", "1": "Descampe is from Belgium .", "2": "Descampe is on the leaderboard of the 1992 du Maurier Classic .", "3": "X is an one of the six a person in the tie on the leaderboard of the 1992 du Maurier Classic .", "4": "Descampe is X .", "5": "Belgium is an one of the six a person in the tie on the leaderboard of the 1992 du Maurier Classic .", "6": "Descampe is Belgium .", "7": "the 1992 du Maurier Classic is an one of the six a person in the tie on the leaderboard of the 1992 du Maurier Classic .", "8": "Descampe is the 1992 du Maurier Classic .", "9": "the six people in the tie on the leaderboard of the 1992 du Maurier Classic is an one of the six a person in the tie on the leaderboard of the 1992 du Maurier Classic .", "a": "Descampe is the six people in the tie on the leaderboard of the 1992 du Maurier Classic .", "b": "Descampe is an one of the six a person in the tie on the leaderboard of the 1992 du Maurier Classic .", "c": "Descampe is Descampe .", "d": "the leaderboard is an one of the six a person in the tie on the leaderboard of the 1992 du Maurier Classic .", "e": "Descampe is the leaderboard .", "f": "the leaderboard of the 1992 du Maurier Classic is an one of the six a person in the tie on the leaderboard of the 1992 du Maurier Classic .", "g": "Descampe is the leaderboard of the 1992 du Maurier Classic ."}, {"0": "X is a person on the leaderboard of the 1992 du Maurier Classic .", "1": "X participated in the 1992 du Maurier Classic .", "2": "Descampe participated in the 1992 du Maurier Classic .", "3": "the 1992 du Maurier Classic is a person on the leaderboard of the 1992 du Maurier Classic .", "4": "the 1992 du Maurier Classic participated in the 1992 du Maurier Classic .", "5": "Descampe is a person on the leaderboard of the 1992 du Maurier Classic .", "6": "Descampe participated in the 1992 du Maurier Classic .", "7": "the leaderboard of the 1992 du Maurier Classic is a person on the leaderboard of the 1992 du Maurier Classic .", "8": "the leaderboard of the 1992 du Maurier Classic participated in the 1992 du Maurier Classic ."}], "errors": [[]], "entailments_dict": [{"1": ["0", "3", "2"], "3": ["0", "1"], "2": ["0"], "0": ["2"]}, {"d": ["0", "2"], "7": ["0", "2"], "5": ["0", "1", "2"], "f": ["0", "2"], "9": ["0"], "b": ["0", "2"], "0": ["a"], "1": ["c"], "2": ["c", "a"]}, {"2": ["5", "(¬4)"], "4": ["2"], "8": ["2"], "6": ["2"]}], "predicted_steps": [true, false, false]}
{"text": "If an animal barks, then Jane does not like it. All dogs are animals that bark. If an animal jumps, then Jane likes it. If an animal has legs, then it jumps. If an animal is terricolous, then it has legs. If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that KiKi is terricolous?", "id": "196", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If an animal barks, then Jane does not like it.\nPremise 1.2: All dogs are animals that bark.\nConclusion 1: Jane does not like dogs.\n\nPremise 2.1: If an animal jumps, then Jane likes it.\nPremise 2.2: If an animal has legs, then it jumps.\nConclusion 2: Animals with legs are liked by Jane.\n\nPremise 3.1: If an animal is terricolous, then it has legs.\nPremise 3.2: KiKi neither jumps nor has legs.\nConclusion 3: KiKi is terricolous or has legs.\n\nPremise 4.1: KiKi is terricolous or has legs.\nConclusion 4: KiKi has legs or is terricolous.\n\nConclusion 5: Therefore, the answer is A. Yes, KiKi is terricolous.\n\nSo, the answer is A. Yes, KiKi is terricolous.", "logic_premises": "[[((6∧7)→8), (9→a)], [((7∧8)→9), ((a∧b)→c)], [((7∧8)→9), (3∧4)], [(0∨1)]]", "logic_conclusion": "[5, 6, (5∨6), (2∨3)]", "correspondance": [{"0": "X is an animal", "1": "X barks .", "2": "Jane does not like X .", "3": "X is a dog .", "4": "X is an animal that barks .", "5": "Jane does not like dogs .", "6": "Jane is an animal", "7": "Jane barks .", "8": "Jane does not like Jane .", "9": "Jane is a dog .", "a": "Jane is an animal that barks ."}, {"0": "X is an animal", "1": "X jumps .", "2": "Jane likes X .", "3": "X is an animal", "4": "X has legs .", "5": "X jumps .", "6": "Animals with legs are liked by Jane .", "7": "Jane is an animal", "8": "Jane jumps .", "9": "Jane likes Jane .", "a": "Jane is an animal", "b": "Jane has legs .", "c": "Jane jumps ."}, {"0": "X is an animal", "1": "X is terricolous .", "2": "X has legs .", "3": "KiKi does not jump .", "4": "KiKi does not have legs .", "5": "KiKi is terricolous .", "6": "KiKi has legs .", "7": "KiKi is an animal", "8": "KiKi is terricolous .", "9": "KiKi has legs ."}, {"0": "KiKi is terricolous .", "1": "KiKi has legs .", "2": "KiKi has legs .", "3": "KiKi is terricolous ."}], "errors": [[]], "entailments_dict": [{"a": ["7", "6", "(¬8)"], "5": ["(¬8)", "(¬a)"]}, {"c": ["8"]}, {"5": ["8"], "9": ["6", "(¬4)"], "4": ["(¬9)"], "6": ["(¬4)"], "(¬6)": ["4", "3"]}, {"3": ["0"], "2": ["1"], "1": ["2"], "0": ["3"]}], "predicted_steps": ["Contradiction in the premises", false, false, true]}
{"text": "If an animal barks, then Jane does not like it. All dogs are animals that bark. If an animal jumps, then Jane likes it. If an animal has legs, then it jumps. If an animal is terricolous, then it has legs. If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that KiKi barks and is a dog?", "id": "197", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If an animal barks, then Jane does not like it.\nPremise 1.2: All dogs are animals that bark.\nConclusion 1: If an animal is a dog, then it barks and Jane does not like it.\n\nPremise 2.1: If an animal jumps, then Jane likes it.\nPremise 2.2: If an animal has legs, then it jumps.\nConclusion 2: If an animal has legs, then Jane likes it.\n\nPremise 3.1: If an animal is terricolous, then it has legs.\nPremise 3.2: If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.\nConclusion 3: If KiKi is terricolous, then it has legs and Jane likes it.\n\nPremise 4.1: If KiKi is a dog, then it barks and Jane does not like it (from Conclusion 1).\nPremise 4.2: If KiKi has legs, then Jane likes it (from Conclusion 2).\nConclusion 4: KiKi cannot be both a dog and have legs, as this would contradict Jane's preferences.\n\nPremise 5.1: KiKi is terricolous or has legs (from Conclusion 3).\nPremise 5.2: KiKi cannot be both a dog and have legs (from Conclusion 4).\nConclusion 5: Therefore, KiKi is terricolous and does not bark.\n\nAnswer: C. Uncertain. We cannot determine whether KiKi barks and is a dog because it is possible that KiKi is terricolous and does not bark, or that KiKi has legs and Jane likes it.", "logic_premises": "[[((0∧1)→2), (3→4)], [((0∧1)→2), ((3∧4)→5)], [(((b∧c)→d)∪((e∧f)→g)), ((3∧4)→(5∨6))], [(0→(1∧3)), (4→5)], [(0∨1), (2∧3)]]", "logic_conclusion": "[((5∧6)→(7∧a)), ((6∧7)→8), (7→(8∧a)), 6, (4∧5)]", "correspondance": [{"0": "X is an animal", "1": "X barks .", "2": "Jane does not like X .", "3": "X is a dog .", "4": "X is an animal that barks .", "5": "X is an animal", "6": "X is a dog .", "7": "X barks .", "8": "X is an animal", "9": "X is a dog .", "a": "Jane does not like X ."}, {"0": "X is an animal", "1": "X jumps .", "2": "Jane likes X .", "3": "X is an animal", "4": "X has legs .", "5": "X jumps .", "6": "X is an animal", "7": "X has legs .", "8": "Jane likes X ."}, {"0": "X is an animal", "1": "X is terricolous .", "2": "X has legs .", "3": "KiKi does not jump .", "4": "KiKi does not have legs .", "5": "KiKi is terricolous .", "6": "KiKi has legs .", "7": "KiKi is terricolous .", "8": "KiKi has legs .", "9": "KiKi is terricolous .", "a": "Jane likes it .", "b": "KiKi is an animal", "c": "KiKi is terricolous .", "d": "KiKi has legs .", "e": "Jane is an animal", "f": "Jane is terricolous .", "g": "Jane has legs ."}, {"0": "KiKi is a dog .", "1": "KiKi barks .", "2": "KiKi is a dog .", "3": "Jane does not like KiKi .", "4": "KiKi has legs .", "5": "Jane likes KiKi .", "6": "KiKi can not be both a dog and have legs that this would contradict Jane 's preferences ."}, {"0": "KiKi is terricolous .", "1": "KiKi has legs .", "2": "KiKi can not VP .", "3": "KiKi can not have legs .", "4": "Therefore , KiKi is terricolous .", "5": "Therefore , KiKi does not bark ."}], "errors": [[]], "entailments_dict": [{"4": ["1", "0", "7"], "6": ["1", "0", "3"], "5": ["0"], "2": ["a"]}, {"5": ["1"], "7": ["4"], "6": ["0", "3"], "2": ["8"]}, {"5": ["c"], "7": ["c"], "d": ["8"], "6": ["8"], "(¬8)": ["4", "3"]}, {"5": ["(¬3)"], "3": ["(¬5)"]}, {"4": ["0"], "0": ["4"], "1": ["(¬3)"], "3": ["(¬1)"], "(¬1)": ["3", "2"], "(¬3)": ["1"]}], "predicted_steps": [true, true, false, false, false]}
{"text": "If an animal barks, then Jane does not like it. All dogs are animals that bark. If an animal jumps, then Jane likes it. If an animal has legs, then it jumps. If an animal is terricolous, then it has legs. If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that KiKi neither barks nor is a dog?", "id": "198", "ground_truth": "True", "reasoning": " Here's my reasoning:\n\nPremise 1.1: If an animal barks, then Jane does not like it.\nPremise 1.2: All dogs are animals that bark.\nConclusion 1: If an animal is a dog, then Jane does not like it.\n\nPremise 2.1: If an animal jumps, then Jane likes it.\nPremise 2.2: If an animal has legs, then it jumps.\nConclusion 2: If an animal has legs, then Jane likes it.\n\nPremise 3.1: If an animal is terricolous, then it has legs.\nPremise 3.2: If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.\nConclusion 3: If KiKi neither jumps nor has legs, then KiKi is terricolous or has legs.\n\nPremise 4.1: If KiKi is terricolous or has legs, then KiKi neither barks nor is a dog.\nConclusion 4: KiKi neither barks nor is a dog.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[((0∧1)→2), (3→4)], [((0∧1)→2), ((3∧4)→5)], [((b∧c)→d), ((3∧4)→(5∨6))], [((0∨1)→(2∧3))]]", "logic_conclusion": "[((5∧6)→7), ((6∧7)→8), ((7∧8)→(9∨a)), (4∧5)]", "correspondance": [{"0": "X is an animal", "1": "X barks .", "2": "Jane does not like X .", "3": "X is a dog .", "4": "X is an animal that barks .", "5": "X is an animal", "6": "X is a dog .", "7": "Jane does not like X ."}, {"0": "X is an animal", "1": "X jumps .", "2": "Jane likes X .", "3": "X is an animal", "4": "X has legs .", "5": "X jumps .", "6": "X is an animal", "7": "X has legs .", "8": "Jane likes X ."}, {"0": "X is an animal", "1": "X is terricolous .", "2": "X has legs .", "3": "KiKi does not jump .", "4": "KiKi does not have legs .", "5": "KiKi is terricolous .", "6": "KiKi has legs .", "7": "KiKi does not jump .", "8": "KiKi does not have legs .", "9": "KiKi is terricolous .", "a": "KiKi has legs .", "b": "KiKi is an animal", "c": "KiKi is terricolous .", "d": "KiKi has legs ."}, {"0": "KiKi is terricolous .", "1": "KiKi has legs .", "2": "KiKi does not bark .", "3": "KiKi is not a dog .", "4": "KiKi does not bark .", "5": "KiKi is not a dog ."}], "errors": [[]], "entailments_dict": [{"4": ["1", "0"], "6": ["1", "0", "3"], "5": ["0"], "2": ["7"]}, {"5": ["1"], "7": ["4"], "6": ["0", "3"], "2": ["8"]}, {"5": ["c", "9"], "7": ["3"], "8": ["4", "3", "(¬d)", "(¬6)"], "d": ["a"], "6": ["a"], "(¬a)": ["4", "3"]}, {"3": ["5"], "2": ["4"], "(¬5)": ["1"]}], "predicted_steps": [true, true, false, false]}
{"text": "Ailton Silva, born in 1995, is commonly known as Ailton. Ailton is a football player who was loaned out to Braga. Ailton Silva is a Brazillian footballer who plays for Nautico. Nautico is a football club along with Braga. Fluminense is a football club.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that No one playing for Nautico is Brazilian?", "id": "199", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Ailton Silva is a Brazilian footballer.\nPremise 1.2: Ailton Silva plays for Nautico.\nConclusion 1: Ailton Silva is a Brazilian footballer who plays for Nautico.\n\nPremise 2.1: Ailton is a football player who was loaned out to Braga.\nPremise 2.2: Braga is a football club along with Nautico.\nConclusion 2: Ailton is a football player who was loaned out to a football club that is associated with Nautico.\n\nPremise 3.1: Fluminense is a football club.\nConclusion 3: Fluminense is a football club that is not associated with Nautico.\n\nPremise 4.1: No one playing for Nautico is Brazilian.\nPremise 4.2: Ailton Silva is a Brazilian footballer who plays for Nautico.\nConclusion 4: The statement \"No one playing for Nautico is Brazilian\" is false.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, 1], [0, 1], [0], [((5→6)∪((7→8)∪(9→a))), 2]]", "logic_conclusion": "[2, 2, 1, ((b→c)∪((d→e)∪(f→g)))]", "correspondance": [{"0": "Ailton Silva is a Brazilian footballer .", "1": "Ailton Silva plays for Nautico .", "2": "Ailton Silva is a Brazilian footballer who plays for Nautico ."}, {"0": "Ailton is a football player who was loaned out to Braga .", "1": "Braga is a football club along with Nautico .", "2": "Ailton is a football player who was loaned out to a football club that is associated with Nautico ."}, {"0": "Fluminense is a football club .", "1": "Fluminense is a football club that is not associated with Nautico ."}, {"0": "X is a person playing for Nautico .", "1": "X is not Brazilian .", "2": "Ailton Silva is a Brazilian footballer who plays for Nautico .", "3": "X is a person The statement \" playing for Nautico is Brazilian \" .", "4": "X is not false .", "5": "The statement \"No one playing for Nautico is Brazilian\" is a person playing for Nautico .", "6": "The statement \"No one playing for Nautico is Brazilian\" is not Brazilian .", "7": "Nautico is a person playing for Nautico .", "8": "Nautico is not Brazilian .", "9": "Ailton Silva is a person playing for Nautico .", "a": "Ailton Silva is not Brazilian .", "b": "The statement \"No one playing for Nautico is Brazilian\" is a person The statement \" playing for Nautico is Brazilian \" .", "c": "The statement \"No one playing for Nautico is Brazilian\" is not false .", "d": "Nautico is a person The statement \" playing for Nautico is Brazilian \" .", "e": "Nautico is not false .", "f": "Ailton Silva is a person The statement \" playing for Nautico is Brazilian \" .", "g": "Ailton Silva is not false ."}], "errors": [[]], "entailments_dict": [{"1": ["0", "2"], "2": ["0", "1"], "0": ["2"]}, {"0": ["2"], "1": ["2"]}, {"1": ["0"], "0": ["1"], "(¬1)": ["0"]}, {"2": ["9", "g", "(¬a)", "(¬8)", "(¬6)"], "f": ["9", "2", "(¬a)", "(¬8)", "(¬6)"], "d": ["7", "9", "2", "(¬8)", "(¬6)"], "8": ["c"], "6": ["(¬2)"], "b": ["(¬2)", "(¬6)"]}], "predicted_steps": [true, true, true, "Contradiction in the premises"]}
{"text": "Ailton Silva, born in 1995, is commonly known as Ailton. Ailton is a football player who was loaned out to Braga. Ailton Silva is a Brazillian footballer who plays for Nautico. Nautico is a football club along with Braga. Fluminense is a football club.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Ailton Silva foes not play for a football club?", "id": "200", "ground_truth": "False", "reasoning": " Here is my step-by-step reasoning:\n\nPremise 1.1: Ailton Silva is a football player.\nPremise 1.2: Ailton Silva was loaned out to Braga.\nConclusion 1: Ailton Silva plays for Braga.\nPremise 2.1: Ailton Silva is a Brazillian footballer.\nPremise 2.2: Ailton Silva plays for Nautico.\nConclusion 2: Nautico is a football club in Brazil.\nPremise 3.1: Nautico is a football club.\nPremise 3.2: Braga is a football club.\nConclusion 3: Braga and Nautico are both football clubs.\nPremise 4.1: Fluminense is a football club.\nConclusion 4: Fluminense is a football club.\nPremise 5.1: Ailton Silva plays for Nautico.\nPremise 5.2: Nautico is a football club.\nConclusion 5: Ailton Silva plays for a football club.\n\nTherefore, the answer is B. No. It is not true that Ailton Silva does not play for a football club.", "logic_premises": "[[0, 1], [0, 1], [0, 1], [0], [0, 1]]", "logic_conclusion": "[2, 2, (2∧3), 1, 2]", "correspondance": [{"0": "Ailton Silva is a football player .", "1": "Ailton Silva was loaned out to Braga .", "2": "Ailton Silva plays for Braga ."}, {"0": "Ailton Silva is a Brazillian footballer .", "1": "Ailton Silva plays for Nautico .", "2": "Nautico is a football club in Brazil ."}, {"0": "Nautico is a football club .", "1": "Braga is a football club .", "2": "Braga are both football clubs .", "3": "Nautico are both football clubs ."}, {"0": "Fluminense is a football club .", "1": "Fluminense is a football club ."}, {"0": "Ailton Silva plays for Nautico .", "1": "Nautico is a football club .", "2": "Ailton Silva plays for a football club ."}], "errors": [[]], "entailments_dict": [{"1": ["0", "2"], "2": ["0"]}, {"1": ["0", "2"]}, {"3": ["0"], "2": ["1"], "0": ["3"], "1": ["2"]}, {"1": ["0"], "0": ["1"]}, {"0": ["1", "2"]}], "predicted_steps": [true, true, true, true, true]}
{"text": "Ailton Silva, born in 1995, is commonly known as Ailton. Ailton is a football player who was loaned out to Braga. Ailton Silva is a Brazillian footballer who plays for Nautico. Nautico is a football club along with Braga. Fluminense is a football club.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Ailton was not loaned out to a football club?", "id": "201", "ground_truth": "False", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Ailton Silva is a Brazilian footballer who plays for Nautico.\nPremise 1.2: Nautico is a football club along with Braga.\nConclusion 1: Ailton Silva plays for Nautico or Braga.\n\nPremise 2.1: Ailton is a football player who was loaned out to Braga.\nPremise 2.2: Braga is a football club that Ailton was loaned out to.\nConclusion 2: Ailton was loaned out to a football club.\n\nPremise 3.1: Ailton was loaned out to a football club.\nPremise 3.2: Fluminense is a football club.\nConclusion 3: Ailton was not loaned out to Fluminense.\n\nConclusion 4: Ailton was loaned out to a football club, but it's uncertain which club.\n\nTherefore, the answer is C. Uncertain.", "logic_premises": "[[0, 1], [0, 1], [0, 1]]", "logic_conclusion": "[(2∨3), 2, 2]", "correspondance": [{"0": "Ailton Silva is a Brazilian footballer who plays for Nautico .", "1": "Nautico is a football club along with Braga .", "2": "Ailton Silva plays for Nautico .", "3": "Ailton Silva plays for Braga ."}, {"0": "Ailton is a football player who was loaned out to Braga .", "1": "Braga is a football club that Ailton was loaned out to .", "2": "Ailton was loaned out to Braga ."}, {"0": "Ailton was loaned out to a football club .", "1": "Fluminense is a football club .", "2": "Ailton was not loaned out to Fluminense ."}], "errors": [[]], "entailments_dict": [{"2": ["0"], "0": ["2"]}, {"1": ["0", "2"], "0": ["1", "2"], "2": ["0", "1"], "(¬0)": ["1"]}, {"(¬2)": ["0", "1"]}], "predicted_steps": [true, true, false]}
{"text": "Ailton Silva, born in 1995, is commonly known as Ailton. Ailton is a football player who was loaned out to Braga. Ailton Silva is a Brazillian footballer who plays for Nautico. Nautico is a football club along with Braga. Fluminense is a football club.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Ailton Silva played for Fluminense?", "id": "202", "ground_truth": "Uncertain", "reasoning": " Here's my reasoning:\n\nPremise 1.1: Ailton Silva is a Brazilian footballer who plays for Nautico.\nPremise 1.2: Nautico is a football club that includes Braga.\nConclusion 1: Ailton Silva plays for Nautico, which includes Braga.\nPremise 2.1: Ailton Silva is commonly known as Ailton.\nPremise 2.2: Ailton is a football player who was loaned out to Braga.\nConclusion 2: Ailton Silva, also known as Ailton, was loaned out to Braga.\nPremise 3.1: Ailton Silva plays for Nautico, which includes Braga.\nPremise 3.2: Ailton Silva was loaned out to Braga.\nConclusion 3: Ailton Silva played for Braga.\nPremise 4.1: Ailton Silva played for Braga.\nPremise 4.2: Fluminense is a football club.\nConclusion 4: Ailton Silva did not play for Fluminense.\n\nTherefore, the answer is B. No.", "logic_premises": "[[0, 1], [0, 1], [(0∧1), 2], [0, 1]]", "logic_conclusion": "[(2∧3), 2, 3, 2]", "correspondance": [{"0": "Ailton Silva is a Brazilian footballer who plays for Nautico .", "1": "Nautico is a football club that includes Braga .", "2": "Ailton Silva plays for Nautico .", "3": "Nautico includes Braga ."}, {"0": "Ailton Silva is commonly known as Ailton .", "1": "Ailton Silva is a football player who was loaned out to Braga .", "2": "Ailton Silva , was loaned out to Braga ."}, {"0": "Ailton Silva plays for Nautico .", "1": "Nautico includes Braga .", "2": "Ailton Silva was loaned out to Braga .", "3": "Ailton Silva played for Braga ."}, {"0": "Ailton Silva played for Braga .", "1": "Fluminense is a football club .", "2": "Ailton Silva did not play for Fluminense ."}], "errors": [[]], "entailments_dict": [{"3": ["0", "1"], "2": ["0"], "0": ["2"], "1": ["3"]}, {"1": ["0", "2"], "2": ["0", "1"]}, {"2": ["3"]}, {"(¬2)": ["1"]}], "predicted_steps": [true, true, true, false]}
{"text": "Ailton Silva, born in 1995, is commonly known as Ailton. Ailton is a football player who was loaned out to Braga. Ailton Silva is a Brazillian footballer who plays for Nautico. Nautico is a football club along with Braga. Fluminense is a football club.", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Ailton Silva was loaned out to a football club?", "id": "203", "ground_truth": "Uncertain", "reasoning": " Premise 1.1: Ailton Silva is a football player who was loaned out to Braga.\nConclusion 1: Ailton Silva was loaned out to a football club.\n\nTherefore, the answer is A. Yes.", "logic_premises": "[[0]]", "logic_conclusion": "[1]", "correspondance": [{"0": "Ailton Silva is a football player who was loaned out to Braga .", "1": "Ailton Silva was loaned out to a football club ."}], "errors": [[]], "entailments_dict": [{"1": ["0"], "0": ["1"]}], "predicted_steps": [true]}
