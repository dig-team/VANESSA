{"id": "0", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is red?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.2: Harry is kind.\nConclusion 1: Harry is red.\n\n", "ground_truth": [false], "logic_premises": "[[0]]", "logic_conclusion": "[1]", "correspondance": [{"0": "Harry is kind .", "1": "Harry is red ."}], "errors": [[]], "entailments_dict": [{}], "predicted_steps": [false]}
{"id": "1", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is red?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: Blue people are nice.\nPremise 1.2: Harry is blue.\nConclusion 1: Harry is nice.\n\nPremise 2.2: Harry is nice.\nConclusion 2: Harry is rough.\n\nPremise 3.1: All rough people are red.\nPremise 3.2: Harry is rough.\nConclusion 3: Harry is red.\n\n", "ground_truth": [true, false, true], "logic_premises": "[[(4→5), 2], [0], [(4→5), 2]]", "logic_conclusion": "[3, 1, 3]", "correspondance": [{"0": "X is a Blue person .", "1": "X is nice .", "2": "Harry is blue .", "3": "Harry is nice .", "4": "Harry is a Blue person .", "5": "Harry is nice ."}, {"0": "Harry is nice .", "1": "Harry is rough ."}, {"0": "X is a rough person .", "1": "X is red .", "2": "Harry is rough .", "3": "Harry is red .", "4": "Harry is a rough person .", "5": "Harry is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"1": ["(¬0)"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [true, false, true]}
{"id": "2", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Bob is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Bob is kind.\nConclusion 1: Bob is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Bob is red.\nConclusion 2: Bob is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Bob is smart.\nConclusion 3: Bob is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Bob is blue.\nConclusion 4: Bob is nice.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Bob is kind .", "3": "Bob is red .", "4": "Bob is kind .", "5": "Bob are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Bob is red .", "3": "Bob is smart .", "4": "Bob is red .", "5": "Bob are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Bob is smart .", "3": "Bob is blue .", "4": "Bob is smart .", "5": "Bob are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Bob is blue .", "3": "Bob is nice .", "4": "Bob is a Blue person .", "5": "Bob is nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [true, true, true, true]}
{"id": "3", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Bob is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nConclusion 1: Bob is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Bob is red.\nConclusion 2: Bob is smart.\n\nPremise 3.2: Bob is smart.\nConclusion 3: Bob is blue.\n\nPremise 4.2: Bob is blue.\nConclusion 4: Bob is nice.\n\n", "ground_truth": [false, true, false, false], "logic_premises": "[[(3→4)], [(4→5), 2], [0], [0]]", "logic_conclusion": "[2, 3, 1, 1]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Bob is red .", "3": "Bob is a white person .", "4": "Bob is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Bob is red .", "3": "Bob is smart .", "4": "Bob is red .", "5": "Bob are smart ."}, {"0": "Bob is smart .", "1": "Bob is blue ."}, {"0": "Bob is blue .", "1": "Bob is nice ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"2": ["4"], "5": ["3"]}, {}, {}], "predicted_steps": [false, true, false, false]}
{"id": "4", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Bob is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nConclusion 1: Bob is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Bob is red.\nConclusion 2: Bob is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Bob is smart.\nConclusion 3: Bob is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Bob is white.\nConclusion 4: Bob is nice.\n\n", "ground_truth": [false, true, true, false], "logic_premises": "[[(3→4)], [(4→5), 2], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[2, 3, 3, 4]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Bob is red .", "3": "Bob is kind .", "4": "Bob are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Bob is red .", "3": "Bob is smart .", "4": "Bob is red .", "5": "Bob are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Bob is smart .", "3": "Bob is blue .", "4": "Bob is smart .", "5": "Bob are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Bob is white .", "4": "Bob is nice .", "5": "Bob is white .", "6": "Bob is blue .", "7": "Bob are nice ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [false, true, true, false]}
{"id": "5", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Bob is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nConclusion 1: Bob is red.\n\nPremise 2.1: If someone is red then they are smart.\nConclusion 2: Bob is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nConclusion 3: Bob is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Bob is white.\nConclusion 4: Bob is nice.\n\n", "ground_truth": [false, false, false, false], "logic_premises": "[[(3→4)], [(3→4)], [(3→4)], [((5∧6)→7), 3]]", "logic_conclusion": "[2, 2, 2, 4]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Bob is red .", "3": "Bob is a white person .", "4": "Bob is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Bob is smart .", "3": "Bob is red .", "4": "Bob are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Bob is blue .", "3": "Bob is smart .", "4": "Bob are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Bob is white .", "4": "Bob is nice .", "5": "Bob is white .", "6": "Bob is blue .", "7": "Bob are nice ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"4": ["2"]}, {"4": ["2"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [false, false, false, false]}
{"id": "6", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is smart?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is red then they are smart.\nPremise 1.2: Harry is red.\nConclusion 1: Harry is smart.\n\n", "ground_truth": [true], "logic_premises": "[[(4→5), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X is red .", "1": "X are smart .", "2": "Harry is red .", "3": "Harry is smart .", "4": "Harry is red .", "5": "Harry are smart ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}], "predicted_steps": [true]}
{"id": "7", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is smart?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Harry is kind.\nConclusion 1: Harry is red.\n\nPremise 2.1: If someone is red then they are smart.\nConclusion 2: Harry is smart.\n\n", "ground_truth": [true, false], "logic_premises": "[[(4→5), 2], [(3→4)]]", "logic_conclusion": "[3, 2]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Harry is kind .", "3": "Harry is red .", "4": "Harry is kind .", "5": "Harry are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Harry is smart .", "3": "Harry is red .", "4": "Harry are smart ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["2"]}], "predicted_steps": [true, false]}
{"id": "8", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is smart?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.2: Harry is blue.\nConclusion 1: Harry is nice.\n\nPremise 2.1: If someone is nice then they are rough.\nPremise 2.2: Harry is nice.\nConclusion 2: Harry is rough.\n\nPremise 3.1: All rough people are red.\nConclusion 3: Harry is red.\n\nPremise 4.1: If someone is red then they are smart.\nConclusion 4: Harry is smart.\n\n", "ground_truth": [false, true, false, false], "logic_premises": "[[0], [(4→5), 2], [(3→4)], [(3→4)]]", "logic_conclusion": "[1, 3, 2, 2]", "correspondance": [{"0": "Harry is blue .", "1": "Harry is nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Harry is nice .", "3": "Harry is rough .", "4": "Harry is nice .", "5": "Harry are rough ."}, {"0": "X is a rough person .", "1": "X is red .", "2": "Harry is red .", "3": "Harry is a rough person .", "4": "Harry is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Harry is smart .", "3": "Harry is red .", "4": "Harry are smart ."}], "errors": [[]], "entailments_dict": [{}, {"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}, {"4": ["2"]}, {"4": ["2"]}], "predicted_steps": [false, "Contradiction in the premises", false, false]}
{"id": "9", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is red and rough then they are nice.\nPremise 1.2: Erin is red.\nPremise 1.3: Erin is rough.\nConclusion 1: Erin is nice.\n\n", "ground_truth": [true], "logic_premises": "[[((6∧7)→8), 3, 4]]", "logic_conclusion": "[5]", "correspondance": [{"0": "X is red .", "1": "X is rough .", "2": "X are nice .", "3": "Erin is red .", "4": "Erin is rough .", "5": "Erin is nice .", "6": "Erin is red .", "7": "Erin is rough .", "8": "Erin are nice ."}], "errors": [[]], "entailments_dict": [{"4": ["7", "(¬8)"], "3": ["6"], "8": ["5", "(¬4)"], "5": ["(¬4)"]}], "predicted_steps": ["Contradiction in the premises"]}
{"id": "10", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All rough people are red.\nPremise 1.2: Erin is rough.\nConclusion 1: Erin is red.\n\nPremise 2.1: If someone is red and rough then they are nice.\nPremise 2.2: Erin is red.\nConclusion 2: Erin is nice.\n\n", "ground_truth": [true, false], "logic_premises": "[[(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 4]", "correspondance": [{"0": "X is a rough person .", "1": "X is red .", "2": "Erin is rough .", "3": "Erin is red .", "4": "Erin is a rough person .", "5": "Erin is red ."}, {"0": "X is red .", "1": "X is rough .", "2": "X are nice .", "3": "Erin is red .", "4": "Erin is nice .", "5": "Erin is red .", "6": "Erin is rough .", "7": "Erin are nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, false]}
{"id": "11", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is red then they are smart.\nPremise 1.2: Erin is red.\nConclusion 1: Erin is smart.\n\nPremise 2.2: Erin is smart.\nConclusion 2: Erin is blue.\n\nPremise 3.1: Blue people are nice.\nConclusion 3: Erin is nice.\n\n", "ground_truth": [true, false, false], "logic_premises": "[[(4→5), 2], [0], [(3→4)]]", "logic_conclusion": "[3, 1, 2]", "correspondance": [{"0": "X is red .", "1": "X are smart .", "2": "Erin is red .", "3": "Erin is smart .", "4": "Erin is red .", "5": "Erin are smart ."}, {"0": "Erin is smart .", "1": "Erin is blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Erin is nice .", "3": "Erin is a Blue person .", "4": "Erin is nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {}, {"4": ["2"]}], "predicted_steps": [true, false, false]}
{"id": "12", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All rough people are red.\nPremise 1.2: Erin is rough.\nConclusion 1: Erin is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Erin is red.\nConclusion 2: Erin is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Erin is smart.\nConclusion 3: Erin is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Erin is blue.\nConclusion 4: Erin is nice.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3, 3]", "correspondance": [{"0": "X is a rough person .", "1": "X is red .", "2": "Erin is rough .", "3": "Erin is red .", "4": "Erin is a rough person .", "5": "Erin is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Erin is red .", "3": "Erin is smart .", "4": "Erin is red .", "5": "Erin are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Erin is smart .", "3": "Erin is blue .", "4": "Erin is smart .", "5": "Erin are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Erin is blue .", "3": "Erin is nice .", "4": "Erin is a Blue person .", "5": "Erin is nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4", "(¬5)"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [true, true, true, true]}
{"id": "13", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is smart?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\n", "ground_truth": [false, true], "logic_premises": "[[0], [(4→5), 2]]", "logic_conclusion": "[1, 3]", "correspondance": [{"0": "Charlie is kind .", "1": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}], "errors": [[]], "entailments_dict": [{}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [false, true]}
{"id": "14", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is smart?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nConclusion 1: Charlie is red.\n\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\n", "ground_truth": [false, false], "logic_premises": "[[(3→4)], [0]]", "logic_conclusion": "[2, 1]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is red .", "3": "Charlie is a white person .", "4": "Charlie is red ."}, {"0": "Charlie is red .", "1": "Charlie is smart ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {}], "predicted_steps": [false, false]}
{"id": "15", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not smart?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nConclusion 2: Charlie is smart.\n\n", "ground_truth": [false, false], "logic_premises": "[[(3→4)], [(3→4)]]", "logic_conclusion": "[2, 2]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is red .", "3": "Charlie is kind .", "4": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is smart .", "3": "Charlie is red .", "4": "Charlie are smart ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"4": ["2"]}], "predicted_steps": [false, false]}
{"id": "16", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not smart?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\n", "ground_truth": [false, true], "logic_premises": "[[(3→4)], [(4→5), 2]]", "logic_conclusion": "[2, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is red .", "3": "Charlie is a white person .", "4": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [false, true]}
{"id": "17", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is blue?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\n", "ground_truth": [true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [true, true, true]}
{"id": "18", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is blue?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\n", "ground_truth": [true, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is white .", "3": "Charlie is red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": ["Contradiction in the premises", true, true]}
{"id": "19", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not blue?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\n", "ground_truth": [false, true, false], "logic_premises": "[[0], [(4→5), 2], [0]]", "logic_conclusion": "[1, 3, 1]", "correspondance": [{"0": "Charlie is kind .", "1": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "Charlie is smart .", "1": "Charlie is blue ."}], "errors": [[]], "entailments_dict": [{}, {"2": ["4"], "5": ["3"]}, {}], "predicted_steps": [false, true, false]}
{"id": "20", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not blue?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\n", "ground_truth": [false, false, true], "logic_premises": "[[0], [(3→4)], [(4→5), 2]]", "logic_conclusion": "[1, 2, 3]", "correspondance": [{"0": "Charlie is white .", "1": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is smart .", "3": "Charlie is red .", "4": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}], "errors": [[]], "entailments_dict": [{"1": ["(¬0)"]}, {"4": ["2"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [false, false, true]}
{"id": "21", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is nice?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [false, true, false, true], "logic_premises": "[[(3→4)], [(4→5), 2], [(3→4)], [(4→5), 2]]", "logic_conclusion": "[2, 3, 2, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is red .", "3": "Charlie is kind .", "4": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is blue .", "3": "Charlie is smart .", "4": "Charlie are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is blue .", "3": "Charlie is nice .", "4": "Charlie is a Blue person .", "5": "Charlie is nice ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"2": ["4"], "5": ["3"]}, {"4": ["2"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [false, true, false, true]}
{"id": "22", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is nice?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [false, false, true, false], "logic_premises": "[[0], [(3→4)], [(4→5), 2], [(3→4)]]", "logic_conclusion": "[1, 2, 3, 2]", "correspondance": [{"0": "Charlie is white .", "1": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is smart .", "3": "Charlie is red .", "4": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is nice .", "3": "Charlie is a Blue person .", "4": "Charlie is nice ."}], "errors": [[]], "entailments_dict": [{"1": ["(¬0)"]}, {"4": ["2"]}, {"2": ["4"], "5": ["3"]}, {"4": ["2"]}], "predicted_steps": [false, false, true, false]}
{"id": "23", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is nice?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [true, true, false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [0], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 1, 5]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "Charlie is smart .", "1": "Charlie is blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is white .", "4": "Charlie is blue .", "5": "Charlie is nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {}, {"4": ["7", "(¬3)"], "3": ["6", "(¬4)"], "8": ["5"]}], "predicted_steps": [true, true, false, "Contradiction in the premises"]}
{"id": "24", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is nice?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [false, false, true, true], "logic_premises": "[[0], [(3→4)], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[1, 2, 3, 5]", "correspondance": [{"0": "Charlie is white .", "1": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is smart .", "3": "Charlie is red .", "4": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is white .", "4": "Charlie is blue .", "5": "Charlie is nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}], "errors": [[]], "entailments_dict": [{"1": ["(¬0)"]}, {"4": ["2"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7", "(¬3)"], "3": ["6", "(¬4)"], "8": ["5"]}], "predicted_steps": [false, false, true, "Contradiction in the premises"]}
{"id": "25", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [true, false, true, false], "logic_premises": "[[(4→5), 2], [(3→4)], [(4→5), 2], [(3→4)]]", "logic_conclusion": "[3, 2, 3, 2]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is smart .", "3": "Charlie is red .", "4": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is nice .", "3": "Charlie is a Blue person .", "4": "Charlie is nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["2"]}, {"2": ["4"], "5": ["3"]}, {"4": ["2"]}], "predicted_steps": [true, false, true, false]}
{"id": "26", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nConclusion 1: Charlie is red.\n\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nConclusion 3: Charlie is blue.\n\nPremise 4.2: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [false, false, false, false], "logic_premises": "[[(3→4)], [0], [(3→4)], [0]]", "logic_conclusion": "[2, 1, 2, 1]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is red .", "3": "Charlie is a white person .", "4": "Charlie is red ."}, {"0": "Charlie is red .", "1": "Charlie is smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is blue .", "3": "Charlie is smart .", "4": "Charlie are blue ."}, {"0": "Charlie is blue .", "1": "Charlie is nice ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {}, {"4": ["2"]}, {}], "predicted_steps": [false, false, false, false]}
{"id": "27", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [true, true, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [0], [0, 1]]", "logic_conclusion": "[3, 3, 1, 2]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "Charlie is smart .", "1": "Charlie is blue ."}, {"0": "Charlie is white .", "1": "Charlie is blue .", "2": "Charlie is nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {}, {"1": ["(¬0)"], "0": ["(¬1)"]}], "predicted_steps": [true, true, false, "Contradiction in the premises"]}
{"id": "28", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not nice?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nConclusion 3: Charlie is blue.\n\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\n", "ground_truth": [true, false, false, false], "logic_premises": "[[(4→5), 2], [0], [(3→4)], [0, 1]]", "logic_conclusion": "[3, 1, 2, 2]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is white .", "3": "Charlie is red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "Charlie is red .", "1": "Charlie is smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is blue .", "3": "Charlie is smart .", "4": "Charlie are blue ."}, {"0": "Charlie is white .", "1": "Charlie is blue .", "2": "Charlie is nice ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}, {}, {"4": ["2"]}, {"1": ["(¬0)"], "0": ["(¬1)"]}], "predicted_steps": ["Contradiction in the premises", false, false, "Contradiction in the premises"]}
{"id": "29", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is rough?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is nice then they are rough.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [false, false, true, false, false], "logic_premises": "[[0], [0], [(4→5), 2], [(3→4)], [(3→4)]]", "logic_conclusion": "[1, 1, 3, 2, 2]", "correspondance": [{"0": "Charlie is kind .", "1": "Charlie is red ."}, {"0": "Charlie is red .", "1": "Charlie is smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is nice .", "3": "Charlie is a Blue person .", "4": "Charlie is nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is rough .", "3": "Charlie is nice .", "4": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{}, {}, {"2": ["4"], "5": ["3"]}, {"4": ["2"]}, {"4": ["2"]}], "predicted_steps": [false, false, true, false, false]}
{"id": "30", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is rough?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is nice then they are rough.\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [true, true, false, false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [0], [(3→4)], [(4→5), 2]]", "logic_conclusion": "[3, 3, 1, 2, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is white .", "3": "Charlie is red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "Charlie is smart .", "1": "Charlie is blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is nice .", "3": "Charlie is a Blue person .", "4": "Charlie is nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is nice .", "3": "Charlie is rough .", "4": "Charlie is nice .", "5": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}, {"2": ["4"], "5": ["3"]}, {}, {"4": ["2"]}, {"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}], "predicted_steps": ["Contradiction in the premises", true, false, false, "Contradiction in the premises"]}
{"id": "31", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is rough?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is nice then they are rough.\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [true, false, true, true, true], "logic_premises": "[[(4→5), 2], [(3→4)], [(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2]]", "logic_conclusion": "[3, 2, 3, 5, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is smart .", "3": "Charlie is red .", "4": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is smart .", "3": "Charlie is blue .", "4": "Charlie is smart .", "5": "Charlie are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is white .", "4": "Charlie is blue .", "5": "Charlie is nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is nice .", "3": "Charlie is rough .", "4": "Charlie is nice .", "5": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["2"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7", "(¬3)"], "3": ["6", "(¬4)"], "8": ["5"]}, {"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}], "predicted_steps": [true, false, true, "Contradiction in the premises", "Contradiction in the premises"]}
{"id": "32", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is rough?", "ground truth": "Yes", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nConclusion 1: Charlie is red.\n\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [false, false, false, true, false], "logic_premises": "[[(3→4)], [0], [0], [((6∧7)→8), 3, 4], [0]]", "logic_conclusion": "[2, 1, 1, 5, 1]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is red .", "3": "Charlie is a white person .", "4": "Charlie is red ."}, {"0": "Charlie is red .", "1": "Charlie is smart ."}, {"0": "Charlie is smart .", "1": "Charlie is blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is white .", "4": "Charlie is blue .", "5": "Charlie is nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}, {"0": "Charlie is nice .", "1": "Charlie is rough ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {}, {}, {"4": ["7", "(¬3)"], "3": ["6", "(¬4)"], "8": ["5"]}, {"1": ["(¬0)"]}], "predicted_steps": [false, false, false, "Contradiction in the premises", false]}
{"id": "33", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not rough?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is nice then they are rough.\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [true, true, false, false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [0], [(3→4)], [(4→5), 2]]", "logic_conclusion": "[3, 3, 1, 2, 3]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "Charlie is smart .", "1": "Charlie is blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is nice .", "3": "Charlie is a Blue person .", "4": "Charlie is nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is nice .", "3": "Charlie is rough .", "4": "Charlie is nice .", "5": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {}, {"4": ["2"]}, {"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}], "predicted_steps": [true, true, false, false, "Contradiction in the premises"]}
{"id": "34", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not rough?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: All white people are red.\nPremise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: Blue people are nice.\nPremise 4.2: Charlie is blue.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is nice then they are rough.\nPremise 5.2: Charlie is nice.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [true, true, false, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [(3→4)], [(4→5), 2], [(4→5), 2]]", "logic_conclusion": "[3, 3, 2, 3, 3]", "correspondance": [{"0": "X is a white person .", "1": "X is red .", "2": "Charlie is white .", "3": "Charlie is red .", "4": "Charlie is a white person .", "5": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is blue .", "3": "Charlie is smart .", "4": "Charlie are blue ."}, {"0": "X is a Blue person .", "1": "X is nice .", "2": "Charlie is blue .", "3": "Charlie is nice .", "4": "Charlie is a Blue person .", "5": "Charlie is nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is nice .", "3": "Charlie is rough .", "4": "Charlie is nice .", "5": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["2"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4", "(¬5)"], "5": ["3", "(¬2)"], "3": ["(¬2)"]}], "predicted_steps": ["Contradiction in the premises", true, false, true, "Contradiction in the premises"]}
{"id": "35", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not rough?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.1: If someone is kind then they are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nPremise 2.2: Charlie is red.\nConclusion 2: Charlie is smart.\n\nPremise 3.2: Charlie is smart.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is nice then they are rough.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [true, true, false, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [0], [((5∧6)→7), 3], [(3→4)]]", "logic_conclusion": "[3, 3, 1, 4, 2]", "correspondance": [{"0": "X is kind .", "1": "X are red .", "2": "Charlie is kind .", "3": "Charlie is red .", "4": "Charlie is kind .", "5": "Charlie are red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is red .", "3": "Charlie is smart .", "4": "Charlie is red .", "5": "Charlie are smart ."}, {"0": "Charlie is smart .", "1": "Charlie is blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is blue .", "4": "Charlie is nice .", "5": "Charlie is white .", "6": "Charlie is blue .", "7": "Charlie are nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is rough .", "3": "Charlie is nice .", "4": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {}, {"3": ["6"], "7": ["4"]}, {"4": ["2"]}], "predicted_steps": [true, true, false, false, false]}
{"id": "36", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is not rough?", "ground truth": "No", "text": "Bob is kind. Bob is nice. Bob is white. Charlie is kind. Charlie is white. Erin is red. Erin is rough. Harry is blue. Harry is kind. Harry is red. Blue people are nice. All white people are red. If someone is white and blue then they are nice. All rough people are red. If someone is smart then they are blue. If someone is kind then they are red. If someone is nice then they are rough. If someone is red then they are smart. If someone is red and rough then they are nice.", "reasoning": "Premise 1.2: Charlie is white.\nConclusion 1: Charlie is red.\n\nPremise 2.1: If someone is red then they are smart.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: If someone is smart then they are blue.\nConclusion 3: Charlie is blue.\n\nPremise 4.1: If someone is white and blue then they are nice.\nPremise 4.2: Charlie is white.\nPremise 4.3: Charlie is blue.\nConclusion 4: Charlie is nice.\n\nPremise 5.1: If someone is nice then they are rough.\nConclusion 5: Charlie is rough.\n\n", "ground_truth": [false, false, false, true, false], "logic_premises": "[[0], [(3→4)], [(3→4)], [((6∧7)→8), 3, 4], [(3→4)]]", "logic_conclusion": "[1, 2, 2, 5, 2]", "correspondance": [{"0": "Charlie is white .", "1": "Charlie is red ."}, {"0": "X is red .", "1": "X are smart .", "2": "Charlie is smart .", "3": "Charlie is red .", "4": "Charlie are smart ."}, {"0": "X is smart .", "1": "X are blue .", "2": "Charlie is blue .", "3": "Charlie is smart .", "4": "Charlie are blue ."}, {"0": "X is white .", "1": "X is blue .", "2": "X are nice .", "3": "Charlie is white .", "4": "Charlie is blue .", "5": "Charlie is nice .", "6": "Charlie is white .", "7": "Charlie is blue .", "8": "Charlie are nice ."}, {"0": "X is nice .", "1": "X are rough .", "2": "Charlie is rough .", "3": "Charlie is nice .", "4": "Charlie are rough ."}], "errors": [[]], "entailments_dict": [{"1": ["(¬0)"]}, {"4": ["2"]}, {"4": ["2"]}, {"4": ["7", "(¬3)"], "3": ["6", "(¬4)"], "8": ["5"]}, {"4": ["2"]}], "predicted_steps": [false, false, false, "Contradiction in the premises", false]}
{"id": "37", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The cat is blue?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\n", "ground_truth": [true], "logic_premises": "[[((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}], "predicted_steps": [true]}
{"id": "38", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The bald eagle does not chase the tiger?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something is blue then it chases the tiger.\nConclusion 1: The bald eagle chases the tiger.\n\n", "ground_truth": [false], "logic_premises": "[[((3→4)∪(5→6))]]", "logic_conclusion": "[2]", "correspondance": [{"0": "X is blue .", "1": "X chases the tiger .", "2": "The bald eagle chases the tiger .", "3": "the tiger is blue .", "4": "the tiger chases the tiger .", "5": "The bald eagle is blue .", "6": "The bald eagle chases the tiger ."}], "errors": [[]], "entailments_dict": [{"6": ["2"]}], "predicted_steps": [false]}
{"id": "39", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The cat chases the tiger?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\n", "ground_truth": [false, true], "logic_premises": "[[0], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[1, 3]", "correspondance": [{"0": "the cat likes the bald eagle .", "1": "the cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}], "errors": [[]], "entailments_dict": [{}, {"2": ["6"], "7": ["3"]}], "predicted_steps": [false, true]}
{"id": "40", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The cat does not chase the tiger?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\n", "ground_truth": [true, true], "logic_premises": "[[((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}], "predicted_steps": [true, true]}
{"id": "41", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger likes the bald eagle?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 3.2: The tiger visits the cat.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\n", "ground_truth": [true, false, true], "logic_premises": "[[((4→5)∪(6→7)), 2], [((3→4)∪(5→6))], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4]]", "logic_conclusion": "[3, 2, 5]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat chases the tiger .", "3": "the tiger is blue .", "4": "the tiger chases the tiger .", "5": "The cat is blue .", "6": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the tiger visits the cat .", "7": "the bald eagle visits the cat .", "8": "the cat visits the cat .", "9": "The cat visits the cat .", "a": "The tiger visits the cat ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"6": ["2"]}, {"4": ["1"], "3": ["a", "6"], "2": ["5", "(¬4)"], "5": ["(¬4)"]}], "predicted_steps": [true, false, "Contradiction in the premises"]}
{"id": "42", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger likes the bald eagle?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The tiger chases the mouse.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\n", "ground_truth": [true, true, false, false], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((3→4)∪(5→6))], [(((5∧1)→2)∪(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪((9∧1)→2))))), 3]]", "logic_conclusion": "[3, 3, 2, 4]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "The tiger chases the mouse .", "3": "The tiger visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The tiger chases the mouse .", "7": "The tiger visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat chases the tiger .", "3": "the tiger is blue .", "4": "the tiger chases the tiger .", "5": "The cat is blue .", "6": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat chases the tiger .", "4": "the tiger likes the bald eagle .", "5": "the tiger visits the cat .", "6": "the bald eagle visits the cat .", "7": "the cat visits the cat .", "8": "The cat visits the cat .", "9": "The tiger visits the cat ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"], "9": ["(¬2)"], "5": ["(¬2)"]}, {"2": ["6"], "7": ["3"]}, {"6": ["2"]}, {"3": ["1"], "2": ["4", "(¬3)"], "4": ["(¬3)"]}], "predicted_steps": [true, true, false, false]}
{"id": "43", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger likes the bald eagle?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The cat chases the mouse.\nConclusion 1: The cat visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The cat visits the cat.\nConclusion 4: The tiger likes the bald eagle.\n\n", "ground_truth": [true, true, true, false], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((5∧1)→2)∪(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪((9∧1)→2))))), 3]]", "logic_conclusion": "[3, 3, 3, 4]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "the cat chases the mouse .", "3": "the cat visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The cat chases the mouse .", "7": "The cat visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat visits the cat .", "4": "the tiger likes the bald eagle .", "5": "the tiger visits the cat .", "6": "the bald eagle visits the cat .", "7": "the cat visits the cat .", "8": "The cat visits the cat .", "9": "The tiger visits the cat ."}], "errors": [[]], "entailments_dict": [{"2": ["6", "8"], "9": ["3"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"3": ["7", "8"], "2": ["4"]}], "predicted_steps": [true, true, true, false]}
{"id": "44", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not like the bald eagle?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nConclusion 1: The cat is blue.\n\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.2: The tiger visits the cat.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\n", "ground_truth": [false, false, false], "logic_premises": "[[((3→4)∪(5→6))], [0], [0, 1]]", "logic_conclusion": "[2, 1, 2]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat is blue .", "3": "the bald eagle likes the bald eagle .", "4": "the bald eagle is blue .", "5": "The cat likes the bald eagle .", "6": "The cat is blue ."}, {"0": "the cat is blue .", "1": "the cat chases the tiger ."}, {"0": "the tiger visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle ."}], "errors": [[]], "entailments_dict": [{"6": ["2"]}, {}, {"2": ["(¬1)"]}], "predicted_steps": [false, false, false]}
{"id": "45", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not like the bald eagle?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The tiger visits the cat.\nConclusion 4: The tiger likes the bald eagle.\n\n", "ground_truth": [false, false, false, false], "logic_premises": "[[((3→4)∪((5→6)∪(7→8)))], [0], [((3→4)∪(5→6))], [(((5∧1)→2)∪(((6∧1)→2)∪(((7∧1)→2)∪((8∧1)→2)))), 3]]", "logic_conclusion": "[2, 1, 2, 4]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "The tiger visits the cat .", "3": "the mouse chases the mouse .", "4": "the mouse visits the cat .", "5": "The tiger chases the mouse .", "6": "The tiger visits the cat .", "7": "the cat chases the mouse .", "8": "the cat visits the cat ."}, {"0": "the cat likes the bald eagle .", "1": "the cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat chases the tiger .", "3": "the tiger is blue .", "4": "the tiger chases the tiger .", "5": "The cat is blue .", "6": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the tiger likes the bald eagle .", "5": "the tiger visits the cat .", "6": "The tiger visits the cat .", "7": "the cat visits the cat .", "8": "the bald eagle visits the cat ."}], "errors": [[]], "entailments_dict": [{"6": ["2"]}, {}, {"6": ["2"]}, {"3": ["5", "6"], "2": ["4"]}], "predicted_steps": [false, false, false, false]}
{"id": "46", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not like the bald eagle?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.2: The cat chases the mouse.\nConclusion 1: The cat visits the cat.\n\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\n", "ground_truth": [false, false, true, false], "logic_premises": "[[0], [0], [((4→5)∪(6→7)), 2], [(((5∧1)→2)∪(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪((9∧1)→2))))), 3]]", "logic_conclusion": "[1, 1, 3, 4]", "correspondance": [{"0": "the cat chases the mouse .", "1": "the cat visits the cat ."}, {"0": "the cat likes the bald eagle .", "1": "the cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat chases the tiger .", "4": "the tiger likes the bald eagle .", "5": "the tiger visits the cat .", "6": "the bald eagle visits the cat .", "7": "the cat visits the cat .", "8": "The cat visits the cat .", "9": "The tiger visits the cat ."}], "errors": [[]], "entailments_dict": [{}, {}, {"2": ["6"], "7": ["3"]}, {"3": ["1"], "2": ["4", "(¬3)"], "4": ["(¬3)"]}], "predicted_steps": [false, false, true, false]}
{"id": "47", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is blue?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.2: The tiger visits the cat.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\nPremise 4.1: If something likes the bald eagle then it is blue.\nPremise 4.2: The tiger likes the bald eagle.\nConclusion 4: The tiger is blue.\n\n", "ground_truth": [false, true, false, true], "logic_premises": "[[0], [((4→5)∪(6→7)), 2], [0, 1], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[1, 3, 2, 3]", "correspondance": [{"0": "the cat likes the bald eagle .", "1": "the cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}, {"0": "the tiger visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}], "errors": [[]], "entailments_dict": [{}, {"2": ["6"], "7": ["3"]}, {"2": ["(¬1)"]}, {"2": ["6"], "7": ["3"]}], "predicted_steps": [false, true, false, true]}
{"id": "48", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is blue?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.2: The tiger chases the mouse.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The tiger visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nConclusion 5: The tiger is blue.\n\n", "ground_truth": [false, true, true, true, false], "logic_premises": "[[0], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((3→1)∪(4→1))]]", "logic_conclusion": "[1, 3, 3, 5, 2]", "correspondance": [{"0": "the tiger chases the mouse .", "1": "the tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the tiger visits the cat .", "7": "the bald eagle visits the cat .", "8": "the cat visits the cat .", "9": "The cat visits the cat .", "a": "The tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "the bald eagle is blue .", "2": "The tiger is blue .", "3": "the bald eagle likes the bald eagle .", "4": "The tiger likes the bald eagle ."}], "errors": [[]], "entailments_dict": [{}, {"2": ["6"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"4": ["1"], "3": ["a", "6"], "2": ["5", "(¬4)"], "5": ["(¬4)"]}, {}], "predicted_steps": [false, true, true, "Contradiction in the premises", false]}
{"id": "49", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is blue?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The cat chases the mouse.\nConclusion 1: The cat visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The cat visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is blue.\n\n", "ground_truth": [true, true, false, true, false], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((3→4)∪(5→6))], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [0]]", "logic_conclusion": "[3, 3, 2, 5, 1]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "the cat chases the mouse .", "3": "the cat visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The cat chases the mouse .", "7": "The cat visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat chases the tiger .", "3": "the tiger is blue .", "4": "the tiger chases the tiger .", "5": "The cat is blue .", "6": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the tiger visits the cat .", "7": "the bald eagle visits the cat .", "8": "the cat visits the cat .", "9": "The cat visits the cat .", "a": "The tiger visits the cat ."}, {"0": "the tiger likes the bald eagle .", "1": "the tiger is blue ."}], "errors": [[]], "entailments_dict": [{"2": ["6", "8"], "9": ["3"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"6": ["2"]}, {"4": ["1"], "3": ["9", "8"], "2": ["5", "(¬4)"], "5": ["(¬4)"]}, {}], "predicted_steps": [true, true, false, "Contradiction in the premises", false]}
{"id": "50", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is not blue?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 3.2: The tiger visits the cat.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\nPremise 4.2: The tiger likes the bald eagle.\nConclusion 4: The tiger is blue.\n\n", "ground_truth": [false, true, true, false], "logic_premises": "[[((3→4)∪(5→6))], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [0]]", "logic_conclusion": "[2, 3, 5, 1]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat is blue .", "3": "the bald eagle likes the bald eagle .", "4": "the bald eagle is blue .", "5": "The cat likes the bald eagle .", "6": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the tiger visits the cat .", "7": "the bald eagle visits the cat .", "8": "the cat visits the cat .", "9": "The cat visits the cat .", "a": "The tiger visits the cat ."}, {"0": "the tiger likes the bald eagle .", "1": "the tiger is blue ."}], "errors": [[]], "entailments_dict": [{"6": ["2"]}, {"2": ["6"], "7": ["3"]}, {"4": ["1"], "3": ["a", "6"], "2": ["5", "(¬4)"], "5": ["(¬4)"]}, {}], "predicted_steps": [false, true, "Contradiction in the premises", false]}
{"id": "51", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is not blue?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The tiger chases the mouse.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is blue.\n\n", "ground_truth": [true, false, false, false, false], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [0], [((3→4)∪(5→6))], [(((5∧1)→2)∪(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪((9∧1)→2))))), 3], [0]]", "logic_conclusion": "[3, 1, 2, 4, 1]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "The tiger chases the mouse .", "3": "The tiger visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The tiger chases the mouse .", "7": "The tiger visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "the cat likes the bald eagle .", "1": "the cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat chases the tiger .", "3": "the tiger is blue .", "4": "the tiger chases the tiger .", "5": "The cat is blue .", "6": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat chases the tiger .", "4": "the tiger likes the bald eagle .", "5": "the tiger visits the cat .", "6": "the bald eagle visits the cat .", "7": "the cat visits the cat .", "8": "The cat visits the cat .", "9": "The tiger visits the cat ."}, {"0": "the tiger likes the bald eagle .", "1": "the tiger is blue ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"], "9": ["(¬2)"], "5": ["(¬2)"]}, {}, {"6": ["2"]}, {"3": ["1"], "2": ["4", "(¬3)"], "4": ["(¬3)"]}, {}], "predicted_steps": [true, false, false, false, false]}
{"id": "52", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger is not blue?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The cat chases the mouse.\nConclusion 1: The cat visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The cat visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is blue.\n\n", "ground_truth": [true, false, true, true, false], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((3→4)∪(5→6))], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [0]]", "logic_conclusion": "[3, 2, 3, 5, 1]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "the cat chases the mouse .", "3": "the cat visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The cat chases the mouse .", "7": "The cat visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat is blue .", "3": "the bald eagle likes the bald eagle .", "4": "the bald eagle is blue .", "5": "The cat likes the bald eagle .", "6": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the tiger visits the cat .", "7": "the bald eagle visits the cat .", "8": "the cat visits the cat .", "9": "The cat visits the cat .", "a": "The tiger visits the cat ."}, {"0": "the tiger likes the bald eagle .", "1": "the tiger is blue ."}], "errors": [[]], "entailments_dict": [{"2": ["6", "8"], "9": ["3"], "7": ["3"]}, {"6": ["2"]}, {"2": ["6"], "7": ["3"]}, {"4": ["1"], "3": ["9", "8"], "2": ["5", "(¬4)"], "5": ["(¬4)"]}, {}], "predicted_steps": [true, false, true, "Contradiction in the premises", false]}
{"id": "53", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger chases the tiger?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\nPremise 4.2: The tiger likes the bald eagle.\nConclusion 4: The tiger is blue.\n\nPremise 5.1: If something is blue then it chases the tiger.\nPremise 5.2: The tiger is blue.\nConclusion 5: The tiger chases the tiger.\n\n", "ground_truth": [true, true, false, false, true], "logic_premises": "[[((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((5∧1)→2)∪(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪((9∧1)→2))))), 3], [0], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 4, 1, 3]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat chases the tiger .", "4": "the tiger likes the bald eagle .", "5": "the tiger visits the cat .", "6": "the bald eagle visits the cat .", "7": "the cat visits the cat .", "8": "The cat visits the cat .", "9": "The tiger visits the cat ."}, {"0": "the tiger likes the bald eagle .", "1": "the tiger is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "the tiger is blue .", "3": "the tiger chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The tiger is blue .", "7": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"3": ["1"], "2": ["4", "(¬3)"], "4": ["(¬3)"]}, {}, {"2": ["6", "4"], "7": ["3"], "5": ["3"]}], "predicted_steps": [true, true, false, false, true]}
{"id": "54", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger chases the tiger?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The tiger chases the mouse.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.2: The tiger visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nConclusion 5: The tiger is blue.\n\nPremise 6.1: If something is blue then it chases the tiger.\nPremise 6.2: The tiger is blue.\nConclusion 6: The tiger chases the tiger.\n\n", "ground_truth": [true, true, true, false, false, true], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [0, 1], [((3→1)∪(4→1))], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[3, 3, 3, 2, 2, 3]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "The tiger chases the mouse .", "3": "The tiger visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The tiger chases the mouse .", "7": "The tiger visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}, {"0": "the tiger visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle ."}, {"0": "X likes the bald eagle .", "1": "the bald eagle is blue .", "2": "The tiger is blue .", "3": "the bald eagle likes the bald eagle .", "4": "The tiger likes the bald eagle ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "the tiger is blue .", "3": "the tiger chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The tiger is blue .", "7": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"], "9": ["(¬2)"], "5": ["(¬2)"]}, {"2": ["6"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"2": ["(¬1)"]}, {}, {"2": ["6", "4"], "7": ["3"], "5": ["3"]}], "predicted_steps": [true, true, true, false, false, true]}
{"id": "55", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger chases the tiger?", "ground truth": "Yes", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nConclusion 1: The cat visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The cat visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is blue.\n\nPremise 6.1: If something is blue then it chases the tiger.\nPremise 6.2: The tiger is blue.\nConclusion 6: The tiger chases the tiger.\n\n", "ground_truth": [false, true, false, true, true, true], "logic_premises": "[[((3→4)∪((5→6)∪(7→8)))], [((4→5)∪(6→7)), 2], [((3→4)∪(5→6))], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2]]", "logic_conclusion": "[2, 3, 2, 5, 3, 3]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "the cat visits the cat .", "3": "the mouse chases the mouse .", "4": "the mouse visits the cat .", "5": "The cat chases the mouse .", "6": "The cat visits the cat .", "7": "the cat chases the mouse .", "8": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat chases the tiger .", "3": "the tiger is blue .", "4": "the tiger chases the tiger .", "5": "The cat is blue .", "6": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the cat visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the tiger visits the cat .", "7": "the bald eagle visits the cat .", "8": "the cat visits the cat .", "9": "The cat visits the cat .", "a": "The tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "the tiger is blue .", "3": "the tiger chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The tiger is blue .", "7": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"8": ["2"], "6": ["2"]}, {"2": ["6"], "7": ["3"]}, {"6": ["2"]}, {"4": ["1"], "3": ["9", "8"], "2": ["5", "(¬4)"], "5": ["(¬4)"]}, {"2": ["6"], "7": ["3"]}, {"2": ["6", "4"], "7": ["3"], "5": ["3"]}], "predicted_steps": [false, true, false, "Contradiction in the premises", true, true]}
{"id": "56", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not chase the tiger?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something likes the bald eagle then it is blue.\nPremise 1.2: The cat likes the bald eagle.\nConclusion 1: The cat is blue.\n\nPremise 2.1: If something is blue then it chases the tiger.\nPremise 2.2: The cat is blue.\nConclusion 2: The cat chases the tiger.\n\nPremise 3.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 3.2: The tiger visits the cat.\nPremise 3.3: The cat chases the tiger.\nConclusion 3: The tiger likes the bald eagle.\n\nPremise 4.1: If something likes the bald eagle then it is blue.\nPremise 4.2: The tiger likes the bald eagle.\nConclusion 4: The tiger is blue.\n\nPremise 5.1: If something is blue then it chases the tiger.\nConclusion 5: The tiger chases the tiger.\n\n", "ground_truth": [true, true, true, true, false], "logic_premises": "[[((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((4→5)∪(6→7)), 2], [((3→4)∪(5→6))]]", "logic_conclusion": "[3, 3, 5, 3, 2]", "correspondance": [{"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the tiger visits the cat .", "7": "the bald eagle visits the cat .", "8": "the cat visits the cat .", "9": "The cat visits the cat .", "a": "The tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "the tiger chases the tiger .", "3": "the tiger is blue .", "4": "the tiger chases the tiger .", "5": "The tiger is blue .", "6": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"4": ["1"], "3": ["a", "6"], "2": ["5", "(¬4)"], "5": ["(¬4)"]}, {"2": ["6"], "7": ["3"]}, {"4": ["2"], "6": ["2"]}], "predicted_steps": [true, true, "Contradiction in the premises", true, false]}
{"id": "57", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not chase the tiger?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nPremise 1.2: The tiger chases the mouse.\nConclusion 1: The tiger visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.1: If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle.\nPremise 4.2: The tiger visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nConclusion 5: The tiger is blue.\n\nPremise 6.1: If something is blue then it chases the tiger.\nConclusion 6: The tiger chases the tiger.\n\n", "ground_truth": [true, true, true, true, false, false], "logic_premises": "[[((4→5)∪((6→7)∪(8→9))), 2], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [(((6∧1)→2)∪(((7∧1)→2)∪(((8∧1)→2)∪(((9∧1)→2)∪((a∧1)→2))))), 3, 4], [((3→1)∪(4→1))], [((3→4)∪(5→6))]]", "logic_conclusion": "[3, 3, 3, 5, 2, 2]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "The tiger chases the mouse .", "3": "The tiger visits the cat .", "4": "the mouse chases the mouse .", "5": "the mouse visits the cat .", "6": "The tiger chases the mouse .", "7": "The tiger visits the cat .", "8": "the cat chases the mouse .", "9": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}, {"0": "X visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle .", "3": "the tiger visits the cat .", "4": "the cat chases the tiger .", "5": "the tiger likes the bald eagle .", "6": "the tiger visits the cat .", "7": "the bald eagle visits the cat .", "8": "the cat visits the cat .", "9": "The cat visits the cat .", "a": "The tiger visits the cat ."}, {"0": "X likes the bald eagle .", "1": "the bald eagle is blue .", "2": "The tiger is blue .", "3": "the bald eagle likes the bald eagle .", "4": "The tiger likes the bald eagle ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "the tiger chases the tiger .", "3": "the tiger is blue .", "4": "the tiger chases the tiger .", "5": "The tiger is blue .", "6": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"2": ["6"], "7": ["3"], "9": ["(¬2)"], "5": ["(¬2)"]}, {"2": ["6"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"4": ["1"], "3": ["a", "6"], "2": ["5", "(¬4)"], "5": ["(¬4)"]}, {}, {"4": ["2"], "6": ["2"]}], "predicted_steps": [true, true, true, "Contradiction in the premises", false, false]}
{"id": "58", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that The tiger does not chase the tiger?", "ground truth": "No", "text": "The bald eagle is blue. The bald eagle is kind. The bald eagle likes the cat. The bald eagle does not visit the tiger. The cat chases the mouse. The cat is green. The cat likes the bald eagle. The cat likes the mouse. The cat does not like the tiger. The mouse likes the cat. The tiger chases the cat. The tiger chases the mouse. The tiger is red. The tiger likes the cat. The tiger visits the cat. The tiger visits the mouse. If something likes the bald eagle then it is blue. If something visits the bald eagle and it visits the cat then the bald eagle is red. If something chases the mouse then it visits the cat. If something is blue then it chases the tiger. If something visits the cat and the cat chases the tiger then the tiger likes the bald eagle. If something likes the tiger then the tiger likes the bald eagle. If something chases the mouse then it visits the mouse.", "reasoning": "Premise 1.1: If something chases the mouse then it visits the cat.\nConclusion 1: The cat visits the cat.\n\nPremise 2.1: If something likes the bald eagle then it is blue.\nPremise 2.2: The cat likes the bald eagle.\nConclusion 2: The cat is blue.\n\nPremise 3.1: If something is blue then it chases the tiger.\nPremise 3.2: The cat is blue.\nConclusion 3: The cat chases the tiger.\n\nPremise 4.2: The cat visits the cat.\nPremise 4.3: The cat chases the tiger.\nConclusion 4: The tiger likes the bald eagle.\n\nPremise 5.1: If something likes the bald eagle then it is blue.\nPremise 5.2: The tiger likes the bald eagle.\nConclusion 5: The tiger is blue.\n\nPremise 6.1: If something is blue then it chases the tiger.\nConclusion 6: The tiger chases the tiger.\n\n", "ground_truth": [false, true, true, false, true, false], "logic_premises": "[[((3→4)∪((5→6)∪(7→8)))], [((4→5)∪(6→7)), 2], [((4→5)∪(6→7)), 2], [0, 1], [((4→5)∪(6→7)), 2], [((3→4)∪(5→6))]]", "logic_conclusion": "[2, 3, 3, 2, 3, 2]", "correspondance": [{"0": "X chases the mouse .", "1": "X visits the cat .", "2": "the cat visits the cat .", "3": "the mouse chases the mouse .", "4": "the mouse visits the cat .", "5": "The cat chases the mouse .", "6": "The cat visits the cat .", "7": "the cat chases the mouse .", "8": "the cat visits the cat ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The cat likes the bald eagle .", "3": "The cat is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The cat likes the bald eagle .", "7": "The cat is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "The cat is blue .", "3": "The cat chases the tiger .", "4": "the tiger is blue .", "5": "the tiger chases the tiger .", "6": "The cat is blue .", "7": "The cat chases the tiger ."}, {"0": "the cat visits the cat .", "1": "the cat chases the tiger .", "2": "the tiger likes the bald eagle ."}, {"0": "X likes the bald eagle .", "1": "X is blue .", "2": "The tiger likes the bald eagle .", "3": "The tiger is blue .", "4": "the bald eagle likes the bald eagle .", "5": "the bald eagle is blue .", "6": "The tiger likes the bald eagle .", "7": "The tiger is blue ."}, {"0": "X is blue .", "1": "X chases the tiger .", "2": "the tiger chases the tiger .", "3": "the tiger is blue .", "4": "the tiger chases the tiger .", "5": "The tiger is blue .", "6": "The tiger chases the tiger ."}], "errors": [[]], "entailments_dict": [{"8": ["2"], "6": ["2"]}, {"2": ["6"], "7": ["3"]}, {"2": ["6"], "7": ["3"]}, {"2": ["(¬1)"]}, {"2": ["6"], "7": ["3"]}, {"4": ["2"], "6": ["2"]}], "predicted_steps": [false, true, true, false, true, false]}
{"id": "59", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: Kind, big things are red.\nPremise 1.2: Charlie is kind.\nConclusion 1: Charlie is red.\n\n", "ground_truth": [false], "logic_premises": "[[((5∧6)→7), 3]]", "logic_conclusion": "[4]", "correspondance": [{"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["5"], "7": ["4"]}], "predicted_steps": [false]}
{"id": "60", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: Kind things are big.\nConclusion 1: Charlie is big.\n\nPremise 2.1: Kind, big things are red.\nPremise 2.2: Charlie is kind.\nPremise 2.3: Charlie is big.\nConclusion 2: Charlie is red.\n\n", "ground_truth": [false, true], "logic_premises": "[[(3→4)], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[2, 5]", "correspondance": [{"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, true]}
{"id": "61", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: Kind, big things are red.\nPremise 2.3: Charlie is big.\nConclusion 2: Charlie is red.\n\n", "ground_truth": [true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((5∧6)→7), 3]]", "logic_conclusion": "[5, 4]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": ["Contradiction in the premises", false]}
{"id": "62", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: Kind things are big.\nPremise 2.2: Charlie is kind.\nConclusion 2: Charlie is big.\n\nPremise 3.1: Kind, big things are red.\nPremise 3.2: Charlie is kind.\nPremise 3.3: Charlie is big.\nConclusion 3: Charlie is red.\n\n", "ground_truth": [false, true, true], "logic_premises": "[[0, 1], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[2, 3, 5]", "correspondance": [{"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["(¬0)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, true, true]}
{"id": "63", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: Kind things are big.\nConclusion 2: Charlie is big.\n\nPremise 3.1: Kind, big things are red.\nPremise 3.2: Charlie is kind.\nPremise 3.3: Charlie is big.\nConclusion 3: Charlie is red.\n\n", "ground_truth": [false, false, true], "logic_premises": "[[0, 1], [(3→4)], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[2, 2, 5]", "correspondance": [{"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["(¬0)"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, false, true]}
{"id": "64", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind, big things are red.\nPremise 3.2: Charlie is kind.\nPremise 3.3: Charlie is big.\nConclusion 3: Charlie is red.\n\n", "ground_truth": [true, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [0, 1], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 2, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"2": ["(¬0)"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, false, true]}
{"id": "65", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.2: Charlie is kind.\nPremise 3.3: Charlie is big.\nConclusion 3: Charlie is red.\n\n", "ground_truth": [true, false, false], "logic_premises": "[[(4→5), 2], [0, 1], [0, 1]]", "logic_conclusion": "[3, 2, 2]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["(¬0)"]}, {}], "predicted_steps": [true, false, false]}
{"id": "66", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind, big things are red.\nPremise 3.2: Charlie is kind.\nPremise 3.3: Charlie is big.\nConclusion 3: Charlie is red.\n\n", "ground_truth": [true, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((5∧6)→7), 3], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 4, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, false, true]}
{"id": "67", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are big.\nConclusion 3: Charlie is big.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, false, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(3→4)], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 4, 2, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": ["Contradiction in the premises", false, false, true]}
{"id": "68", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are big.\nConclusion 3: Charlie is big.\n\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [false, true, false, false], "logic_premises": "[[((5∧6)→7), 3], [((6∧7)→8), 3, 4], [(3→4)], [0, 1]]", "logic_conclusion": "[4, 5, 2, 2]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "7": ["4"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["2"]}, {}], "predicted_steps": [false, "Contradiction in the premises", false, false]}
{"id": "69", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are big.\nPremise 3.2: Charlie is kind.\nConclusion 3: Charlie is big.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, true, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, "Contradiction in the premises", true, true]}
{"id": "70", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 5, 5, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, true, "Contradiction in the premises", false]}
{"id": "71", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are big.\nConclusion 3: Charlie is big.\n\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(3→4)], [0, 1]]", "logic_conclusion": "[5, 5, 2, 2]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["2"]}, {}], "predicted_steps": [true, "Contradiction in the premises", false, false]}
{"id": "72", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 4, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["6"], "7": ["4"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, true, false, true]}
{"id": "73", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nConclusion 4: Charlie is big.\n\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, false, false, false, false], "logic_premises": "[[0, 1], [0, 1], [0, 1], [(3→4)], [0, 1]]", "logic_conclusion": "[2, 2, 2, 2, 2]", "correspondance": [{"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {"2": ["(¬0)"]}, {"2": ["(¬0)"]}, {"4": ["2"]}, {}], "predicted_steps": [false, false, false, false, false]}
{"id": "74", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, false, false, true, false], "logic_premises": "[[(3→4)], [((5∧6)→7), 3], [((5∧6)→7), 3], [(4→5), 2], [0, 1]]", "logic_conclusion": "[2, 4, 4, 3, 2]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"3": ["6"], "7": ["4"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {}], "predicted_steps": [false, false, false, true, false]}
{"id": "75", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, true, true, true, true], "logic_premises": "[[(3→4)], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[2, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, true, "Contradiction in the premises", true, true]}
{"id": "76", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, false, false, true, false], "logic_premises": "[[((5∧6)→7), 3], [0, 1], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[4, 2, 4, 3, 4]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is smart .", "4": "Charlie is cold .", "5": "Charlie is big .", "6": "Charlie is smart .", "7": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "7": ["4"]}, {"2": ["(¬0)"]}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [false, false, false, true, false]}
{"id": "77", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, false, false, true, false], "logic_premises": "[[0, 1], [((5∧6)→7), 3], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[2, 4, 4, 3, 4]", "correspondance": [{"0": "Charlie is big .", "1": "Charlie is smart .", "2": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {"3": ["6"], "7": ["4"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [false, false, false, true, false]}
{"id": "78", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [false, false, true, true, false, true], "logic_premises": "[[0], [((5∧6)→7), 3], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [0], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[1, 4, 5, 5, 1, 5]", "correspondance": [{"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {"3": ["6"], "7": ["4"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, false, "Contradiction in the premises", "Contradiction in the premises", false, true]}
{"id": "79", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [false, true, false, false, true, true], "logic_premises": "[[0, 1], [((6∧7)→8), 3, 4], [0, 1], [0, 1], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[2, 5, 2, 2, 3, 5]", "correspondance": [{"0": "Charlie is big .", "1": "Charlie is smart .", "2": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"2": ["(¬0)"]}, {"2": ["(¬0)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, true, false, false, true, true]}
{"id": "80", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are big.\nPremise 3.2: Charlie is kind.\nConclusion 3: Charlie is big.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[5, 5, 3, 4]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [true, "Contradiction in the premises", true, false]}
{"id": "81", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: Kind things are big.\nPremise 3.2: Charlie is kind.\nConclusion 3: Charlie is big.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.3: Charlie is big.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 5, 3, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [true, "Contradiction in the premises", true, false]}
{"id": "82", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind, big things are red.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is red.\n\n", "ground_truth": [true, true, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 5, 4, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, true, false, false]}
{"id": "83", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, false, false, true, false], "logic_premises": "[[0], [((5∧6)→7), 3], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[1, 4, 4, 3, 4]", "correspondance": [{"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {"3": ["5"], "7": ["4"]}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [false, false, false, true, false]}
{"id": "84", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, true, true, true, true], "logic_premises": "[[0, 1], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[2, 5, 5, 3, 5]", "correspondance": [{"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["(¬0)"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, true, "Contradiction in the premises", true, true]}
{"id": "85", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, true, false, false, false], "logic_premises": "[[((5∧6)→7), 3], [(4→5), 2], [0, 1], [0], [((5∧6)→7), 3]]", "logic_conclusion": "[4, 3, 2, 1, 4]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"2": ["(¬0)"]}, {}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [false, true, false, false, false]}
{"id": "86", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nConclusion 2: Charlie is smart.\n\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, false, false, false, false], "logic_premises": "[[(3→4)], [((5∧6)→7), 3], [0, 1], [(3→4)], [((5∧6)→7), 3]]", "logic_conclusion": "[2, 4, 2, 2, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"3": ["5"], "7": ["4"]}, {"2": ["(¬0)"]}, {"4": ["2"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [false, false, false, false, false]}
{"id": "87", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [true, true, true, true, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [0, 1]]", "logic_conclusion": "[3, 3, 5, 5, 2]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}], "predicted_steps": [true, true, true, "Contradiction in the premises", false]}
{"id": "88", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [true, true, false, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [0, 1], [0, 1], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 3, 2, 2, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}, {}, {"2": ["(¬0)"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, true, false, false, true]}
{"id": "89", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, false, false, true, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [0], [0, 1], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 1, 2, 5, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": ["Contradiction in the premises", false, false, "Contradiction in the premises", true, true]}
{"id": "90", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is cold.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [false, true, true, false, true, true], "logic_premises": "[[((5∧6)→7), 3], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [0, 1], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[4, 5, 5, 2, 3, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["5"], "7": ["4"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"2": ["(¬0)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, "Contradiction in the premises", true, false, true, true]}
{"id": "91", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, quiet things are smart.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, true, false, true, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(3→4)], [((6∧7)→8), 3, 4], [0], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 2, 5, 1, 5]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, "Contradiction in the premises", false, "Contradiction in the premises", false, true]}
{"id": "92", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [false, false, false, true, false, false], "logic_premises": "[[(3→4)], [((5∧6)→7), 3], [((5∧6)→7), 3], [((6∧7)→8), 3, 4], [0], [0, 1]]", "logic_conclusion": "[2, 4, 4, 5, 1, 2]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"3": ["5"], "7": ["4"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {}], "predicted_steps": [false, false, false, "Contradiction in the premises", false, false]}
{"id": "93", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, true, false, false, false, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [((5∧6)→7), 3], [0], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 5, 4, 4, 1, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"3": ["6"], "7": ["4"]}, {"3": ["6"], "7": ["4"]}, {}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [true, "Contradiction in the premises", false, false, false, false]}
{"id": "94", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, false, false, true, false, false], "logic_premises": "[[(4→5), 2], [0, 1], [0], [((6∧7)→8), 3, 4], [(3→4)], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 2, 1, 5, 2, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["(¬0)"]}, {}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["2"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, false, false, "Contradiction in the premises", false, false]}
{"id": "95", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, false, true, false, true, false], "logic_premises": "[[(4→5), 2], [(3→4)], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 2, 5, 4, 3, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [true, false, true, false, true, false]}
{"id": "96", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [false, true, true, false, true, false], "logic_premises": "[[((5∧6)→7), 3], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[4, 5, 5, 4, 3, 4]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is cold .", "5": "Charlie is big .", "6": "Charlie is smart .", "7": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["5"], "7": ["4"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [false, "Contradiction in the premises", true, false, true, false]}
{"id": "97", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, true, false, false, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [0], [((5∧6)→7), 3], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 1, 4, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, "Contradiction in the premises", false, false, true, true]}
{"id": "98", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, false, true, false, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [0], [((6∧7)→8), 3, 4], [0, 1], [(3→4)], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 1, 5, 2, 2, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"2": ["(¬0)"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, false, true, false, false, true]}
{"id": "99", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nConclusion 2: Charlie is kind.\n\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, false, false, false, true, false, false], "logic_premises": "[[0, 1], [((5∧6)→7), 3], [0], [((5∧6)→7), 3], [((6∧7)→8), 3, 4], [(3→4)], [((5∧6)→7), 3]]", "logic_conclusion": "[2, 4, 1, 4, 5, 2, 4]", "correspondance": [{"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {}, {"3": ["5"], "7": ["4"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["2"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [false, false, false, false, "Contradiction in the premises", false, false]}
{"id": "100", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, false, false, false, false, false, false], "logic_premises": "[[(4→5), 2], [((5∧6)→7), 3], [((5∧6)→7), 3], [((5∧6)→7), 3], [((5∧6)→7), 3], [(3→4)], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 4, 4, 4, 4, 2, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}, {"3": ["6"], "7": ["4"]}, {"3": ["5"], "7": ["4"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"4": ["2"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [true, false, false, false, false, false, false]}
{"id": "101", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, true, true, true, false, true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 5, 5, 3, 4, 3, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [true, true, "Contradiction in the premises", true, false, true, false]}
{"id": "102", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, true, true, false, false, true, false], "logic_premises": "[[(3→4)], [((6∧7)→8), 3, 4], [(4→5), 2], [((5∧6)→7), 3], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[2, 5, 3, 4, 4, 3, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [false, "Contradiction in the premises", true, false, false, true, false]}
{"id": "103", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, true, true, false, true, false, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [0, 1], [((6∧7)→8), 3, 4], [0], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 2, 5, 1, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, true, "Contradiction in the premises", false, "Contradiction in the premises", false, true]}
{"id": "104", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, true, true, true, false, true, false], "logic_premises": "[[0], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[1, 5, 5, 3, 4, 3, 4]", "correspondance": [{"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [false, true, "Contradiction in the premises", true, false, true, false]}
{"id": "105", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, true, true, true, false, true, false], "logic_premises": "[[0], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(4→5), 2], [0, 1]]", "logic_conclusion": "[1, 3, 5, 5, 4, 3, 2]", "correspondance": [{"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {}], "predicted_steps": [false, true, true, "Contradiction in the premises", false, true, false]}
{"id": "106", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, true, false, true, false, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(3→4)], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 2, 5, 4, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, "Contradiction in the premises", false, true, false, true, true]}
{"id": "107", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, true, false, true, false, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [((6∧7)→8), 3, 4], [0, 1], [(3→4)], [((5∧6)→7), 3]]", "logic_conclusion": "[5, 5, 4, 5, 2, 2, 4]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"2": ["(¬0)"]}, {"4": ["2"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, true, false, true, false, false, false]}
{"id": "108", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, false, false, false, true, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [0, 1], [0, 1], [0], [((6∧7)→8), 3, 4], [(4→5), 2], [0, 1]]", "logic_conclusion": "[5, 2, 2, 1, 5, 3, 2]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {}, {"2": ["(¬0)"]}, {}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {}], "predicted_steps": [true, false, false, false, "Contradiction in the premises", true, false]}
{"id": "109", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, false, false, true, false, true, false], "logic_premises": "[[((5∧6)→7), 3], [(3→4)], [((5∧6)→7), 3], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[4, 2, 4, 5, 4, 3, 4]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is smart .", "4": "Charlie is cold .", "5": "Charlie is big .", "6": "Charlie is smart .", "7": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "7": ["4"]}, {"4": ["2"]}, {"3": ["6"], "7": ["4"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [false, false, false, "Contradiction in the premises", false, true, false]}
{"id": "110", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nConclusion 3: Charlie is kind.\n\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, false, false, false, false, false, false, true], "logic_premises": "[[(4→5), 2], [((5∧6)→7), 3], [((5∧6)→7), 3], [0], [((5∧6)→7), 3], [((5∧6)→7), 3], [0], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 4, 4, 1, 4, 4, 1, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {}, {"3": ["5"], "7": ["4"]}, {"3": ["6"], "7": ["4"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, false, false, false, false, false, false, true]}
{"id": "111", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, true, true, false, true, true, true, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(3→4)], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 5, 2, 5, 5, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, true, "Contradiction in the premises", false, true, "Contradiction in the premises", true, true]}
{"id": "112", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, false, false, false, false, false, true, false], "logic_premises": "[[(4→5), 2], [(3→4)], [((5∧6)→7), 3], [((5∧6)→7), 3], [((5∧6)→7), 3], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 2, 4, 4, 4, 4, 3, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["2"]}, {"3": ["6"], "7": ["4"]}, {"3": ["6"], "7": ["4"]}, {"3": ["6"], "7": ["4"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, false, false, false, false, false, true, false]}
{"id": "113", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, true, true, true, false, true, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [0], [((6∧7)→8), 3, 4], [(3→4)], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 3, 5, 5, 1, 5, 2, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["2"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, true, true, "Contradiction in the premises", false, "Contradiction in the premises", false, false]}
{"id": "114", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, true, true, false, false, false, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [0], [((5∧6)→7), 3], [0, 1], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[5, 5, 5, 1, 4, 2, 3, 4]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"3": ["6"], "7": ["4"]}, {"2": ["(¬0)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, true, "Contradiction in the premises", false, false, false, true, false]}
{"id": "115", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, false, true, false, true, false, true, false], "logic_premises": "[[((6∧7)→8), 3, 4], [(3→4)], [((6∧7)→8), 3, 4], [0, 1], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[5, 2, 5, 2, 5, 4, 3, 4]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"2": ["(¬0)"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [true, false, true, false, true, false, true, false]}
{"id": "116", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nConclusion 1: Charlie is cold.\n\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [false, false, false, true, false, true, false, true], "logic_premises": "[[((5∧6)→7), 3], [0], [0, 1], [((6∧7)→8), 3, 4], [0], [((6∧7)→8), 3, 4], [0], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[4, 1, 2, 5, 1, 5, 1, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is cold .", "5": "Charlie is big .", "6": "Charlie is smart .", "7": "Charlie is cold ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["5"], "7": ["4"]}, {}, {}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, false, false, "Contradiction in the premises", false, "Contradiction in the premises", false, true]}
{"id": "117", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, quiet things are smart.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.1: Kind things are big.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are red.\nPremise 9.2: Charlie is kind.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [true, false, false, true, true, true, false, false, false], "logic_premises": "[[(4→5), 2], [0], [((5∧6)→7), 3], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [0, 1], [(3→4)], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 1, 4, 5, 3, 5, 2, 2, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {}, {"3": ["5"], "7": ["4"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"2": ["(¬0)"]}, {"4": ["2"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, false, false, "Contradiction in the premises", true, true, false, false, false]}
{"id": "118", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, quiet things are smart.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.2: Charlie is cold.\nConclusion 7: Charlie is kind.\n\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are red.\nPremise 9.2: Charlie is kind.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [false, true, false, false, false, true, false, false, false], "logic_premises": "[[((5∧6)→7), 3], [(4→5), 2], [0, 1], [0, 1], [0], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [0], [((5∧6)→7), 3]]", "logic_conclusion": "[4, 3, 2, 2, 1, 5, 4, 1, 4]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is cold .", "5": "Charlie is big .", "6": "Charlie is smart .", "7": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["5"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {}, {"2": ["(¬0)"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [false, true, false, false, false, true, false, false, false]}
{"id": "119", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: Kind things are big.\nPremise 4.2: Charlie is kind.\nConclusion 4: Charlie is big.\n\nPremise 5.1: Kind, big things are red.\nPremise 5.2: Charlie is kind.\nPremise 5.3: Charlie is big.\nConclusion 5: Charlie is red.\n\n", "ground_truth": [false, false, true, true, true], "logic_premises": "[[0], [0, 1], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[1, 2, 5, 3, 5]", "correspondance": [{"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, false, "Contradiction in the premises", true, true]}
{"id": "120", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: Kind things are big.\nConclusion 5: Charlie is big.\n\nPremise 6.1: Kind, big things are red.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, false, false, false, false, false], "logic_premises": "[[(4→5), 2], [0], [0, 1], [0, 1], [(3→4)], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 1, 2, 2, 2, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {}, {}, {"2": ["(¬0)"]}, {"4": ["2"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, false, false, false, false, false]}
{"id": "121", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nConclusion 3: Charlie is smart.\n\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.2: Charlie is kind.\nConclusion 5: Charlie is big.\n\nPremise 6.2: Charlie is kind.\nPremise 6.3: Charlie is big.\nConclusion 6: Charlie is red.\n\n", "ground_truth": [true, true, false, false, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [((5∧6)→7), 3], [0, 1], [0], [0, 1]]", "logic_conclusion": "[5, 3, 4, 2, 1, 2]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}, {"2": ["(¬0)"]}, {}, {}], "predicted_steps": ["Contradiction in the premises", true, false, false, false, false]}
{"id": "122", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All cold, smart things are kind.\nPremise 1.2: Charlie is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is kind.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nConclusion 6: Charlie is big.\n\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, true, true, false, false, false, false], "logic_premises": "[[((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((5∧6)→7), 3], [0, 1], [(3→4)], [0, 1]]", "logic_conclusion": "[5, 3, 3, 4, 2, 2, 2]", "correspondance": [{"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}, {"2": ["(¬0)"]}, {"4": ["2"]}, {}], "predicted_steps": ["Contradiction in the premises", true, true, false, false, false, false]}
{"id": "123", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, false, true, true, true, false, true], "logic_premises": "[[0, 1], [((5∧6)→7), 3], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(3→4)], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[2, 4, 3, 5, 5, 2, 5]", "correspondance": [{"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, false, true, true, "Contradiction in the premises", false, true]}
{"id": "124", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [false, true, true, true, false, false, true], "logic_premises": "[[(3→4)], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4], [0, 1], [0], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[2, 5, 3, 5, 2, 1, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"2": ["(¬0)"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, "Contradiction in the premises", true, true, false, false, true]}
{"id": "125", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All cold, quiet things are smart.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is quiet.\nConclusion 4: Charlie is smart.\n\nPremise 5.1: All cold, smart things are kind.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is smart.\nConclusion 5: Charlie is kind.\n\nPremise 6.1: Kind things are big.\nPremise 6.2: Charlie is kind.\nConclusion 6: Charlie is big.\n\nPremise 7.1: Kind, big things are red.\nPremise 7.2: Charlie is kind.\nPremise 7.3: Charlie is big.\nConclusion 7: Charlie is red.\n\n", "ground_truth": [true, true, false, true, true, true, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [0], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 1, 5, 5, 3, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, "Contradiction in the premises", false, true, "Contradiction in the premises", true, true]}
{"id": "126", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is cold.\nPremise 1.3: Charlie is quiet.\nConclusion 1: Charlie is smart.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [false, true, true, false, false, false, true, false], "logic_premises": "[[0, 1], [((6∧7)→8), 3, 4], [(4→5), 2], [0], [((5∧6)→7), 3], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[2, 5, 3, 1, 4, 4, 3, 4]", "correspondance": [{"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {}, {"3": ["5"], "7": ["4"]}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [false, "Contradiction in the premises", true, false, false, false, true, false]}
{"id": "127", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, false, false, true, false, true, true, false], "logic_premises": "[[(4→5), 2], [((5∧6)→7), 3], [((5∧6)→7), 3], [(4→5), 2], [0, 1], [((6∧7)→8), 3, 4], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 4, 4, 3, 2, 5, 3, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, false, false, true, false, "Contradiction in the premises", true, false]}
{"id": "128", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, smart things are kind.\nPremise 2.2: Charlie is cold.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [false, false, true, true, true, true, false, true], "logic_premises": "[[(3→4)], [((5∧6)→7), 3], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(3→4)], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[2, 4, 3, 3, 5, 5, 2, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is big .", "3": "Charlie is a Kind thing .", "4": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, false, true, true, true, "Contradiction in the premises", false, true]}
{"id": "129", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.1: Kind things are big.\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [true, true, false, true, true, false, true, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(4→5), 2], [((6∧7)→8), 3, 4], [0, 1], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5, 4, 3, 5, 2, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"2": ["(¬0)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, true, false, true, true, false, true, true]}
{"id": "130", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is smart.\nConclusion 2: Charlie is kind.\n\nPremise 3.1: All quiet things are cold.\nPremise 3.2: Charlie is quiet.\nConclusion 3: Charlie is cold.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All cold, quiet things are smart.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is smart.\nConclusion 6: Charlie is kind.\n\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.1: Kind, big things are red.\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [false, false, true, true, false, true, false, true], "logic_premises": "[[((5∧6)→7), 3], [0, 1], [(4→5), 2], [(4→5), 2], [((5∧6)→7), 3], [((6∧7)→8), 3, 4], [0], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[4, 2, 3, 3, 4, 5, 1, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is smart .", "4": "Charlie is cold .", "5": "Charlie is big .", "6": "Charlie is smart .", "7": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "7": ["4"]}, {"2": ["(¬0)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [false, false, true, true, false, "Contradiction in the premises", false, true]}
{"id": "131", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.2: Charlie is cold.\nPremise 5.3: Charlie is quiet.\nConclusion 5: Charlie is smart.\n\nPremise 6.1: All cold, smart things are kind.\nPremise 6.2: Charlie is cold.\nConclusion 6: Charlie is kind.\n\nPremise 7.2: Charlie is kind.\nConclusion 7: Charlie is big.\n\nPremise 8.2: Charlie is kind.\nPremise 8.3: Charlie is big.\nConclusion 8: Charlie is red.\n\n", "ground_truth": [false, true, true, false, false, false, false, false], "logic_premises": "[[0, 1], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [0], [0, 1], [((5∧6)→7), 3], [0], [0, 1]]", "logic_conclusion": "[2, 5, 5, 1, 2, 4, 1, 2]", "correspondance": [{"0": "Charlie is big .", "1": "Charlie is smart .", "2": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {}, {}], "predicted_steps": [false, true, "Contradiction in the premises", false, false, false, false, false]}
{"id": "132", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.1: Kind things are big.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are red.\nPremise 9.3: Charlie is big.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [true, true, false, true, true, false, false, true, false], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(4→5), 2], [(4→5), 2], [0, 1], [((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 5, 4, 3, 3, 2, 4, 3, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is big .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}], "predicted_steps": [true, true, false, true, true, false, false, true, false]}
{"id": "133", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, quiet things are smart.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are red.\nPremise 9.2: Charlie is kind.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [false, false, false, true, false, true, true, false, false], "logic_premises": "[[0], [0, 1], [0, 1], [(4→5), 2], [0], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [0], [((5∧6)→7), 3]]", "logic_conclusion": "[1, 2, 2, 3, 1, 5, 5, 1, 4]", "correspondance": [{"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is quiet .", "1": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is red .", "5": "Charlie is a Kind thing .", "6": "Charlie is a big thing .", "7": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{}, {}, {"2": ["(¬0)"]}, {"2": ["4"], "5": ["3"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [false, false, false, true, false, true, "Contradiction in the premises", false, false]}
{"id": "134", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All quiet things are cold.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, quiet things are smart.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is big.\n\nPremise 9.2: Charlie is kind.\nPremise 9.3: Charlie is big.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [false, false, false, false, false, true, false, false, false], "logic_premises": "[[(3→4)], [(3→4)], [((5∧6)→7), 3], [0, 1], [(3→4)], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [0], [0, 1]]", "logic_conclusion": "[2, 2, 4, 2, 2, 5, 4, 1, 2]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "Charlie is cold .", "1": "Charlie is smart .", "2": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"4": ["2"]}, {"3": ["6"], "7": ["4"]}, {"2": ["(¬0)"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["6"], "7": ["4"]}, {}, {}], "predicted_steps": [false, false, false, false, false, true, false, false, false]}
{"id": "135", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Charlie is cold.\nPremise 2.3: Charlie is quiet.\nConclusion 2: Charlie is smart.\n\nPremise 3.1: All cold, smart things are kind.\nPremise 3.3: Charlie is smart.\nConclusion 3: Charlie is kind.\n\nPremise 4.1: All quiet things are cold.\nPremise 4.2: Charlie is quiet.\nConclusion 4: Charlie is cold.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All cold, quiet things are smart.\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is big.\n\nPremise 9.1: Kind, big things are red.\nPremise 9.2: Charlie is kind.\nPremise 9.3: Charlie is big.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [true, true, false, true, true, true, true, false, true], "logic_premises": "[[((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [0], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[5, 5, 4, 3, 3, 5, 5, 1, 5]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is smart .", "5": "Charlie is cold .", "6": "Charlie is big .", "7": "Charlie is smart .", "8": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "Charlie is kind .", "1": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, true, false, true, true, true, "Contradiction in the premises", false, true]}
{"id": "136", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.2: Charlie is big.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.2: Charlie is cold.\nPremise 6.3: Charlie is quiet.\nConclusion 6: Charlie is smart.\n\nPremise 7.1: All cold, smart things are kind.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is smart.\nConclusion 7: Charlie is kind.\n\nPremise 8.1: Kind things are big.\nPremise 8.2: Charlie is kind.\nConclusion 8: Charlie is big.\n\nPremise 9.2: Charlie is kind.\nPremise 9.3: Charlie is big.\nConclusion 9: Charlie is red.\n\n", "ground_truth": [false, true, false, false, true, false, true, true, false], "logic_premises": "[[((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3], [((5∧6)→7), 3], [(4→5), 2], [0, 1], [((6∧7)→8), 3, 4], [(4→5), 2], [0, 1]]", "logic_conclusion": "[4, 3, 4, 4, 3, 2, 5, 3, 2]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is big .", "4": "Charlie is cold .", "5": "Charlie is big .", "6": "Charlie is smart .", "7": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is quiet .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is smart .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "Charlie is cold .", "1": "Charlie is quiet .", "2": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["5"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {}], "predicted_steps": [false, true, false, false, true, false, "Contradiction in the premises", true, false]}
{"id": "137", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Charlie is quiet.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nPremise 3.3: Charlie is quiet.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All quiet things are cold.\nPremise 6.2: Charlie is quiet.\nConclusion 6: Charlie is cold.\n\nPremise 7.1: All cold, quiet things are smart.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is quiet.\nConclusion 7: Charlie is smart.\n\nPremise 8.1: All cold, smart things are kind.\nPremise 8.2: Charlie is cold.\nConclusion 8: Charlie is kind.\n\nPremise 9.1: Kind things are big.\nPremise 9.2: Charlie is kind.\nConclusion 9: Charlie is big.\n\nPremise 10.1: Kind, big things are red.\nPremise 10.2: Charlie is kind.\nPremise 10.3: Charlie is big.\nConclusion 10: Charlie is red.\n\n", "ground_truth": [true, true, true, false, true, true, true, false, true, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 4, 3, 3, 5, 4, 3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is kind .", "5": "Charlie is a cold thing .", "6": "Charlie is a smart thing .", "7": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Charlie is kind .", "4": "Charlie is big .", "5": "Charlie is red .", "6": "Charlie is a Kind thing .", "7": "Charlie is a big thing .", "8": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, true, true, false, true, true, true, false, true, true]}
{"id": "138", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Charlie is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: If something is big and smart then it is cold.\nPremise 1.3: Charlie is smart.\nConclusion 1: Charlie is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Charlie is quiet.\nConclusion 2: Charlie is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Charlie is cold.\nConclusion 3: Charlie is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Charlie is cold.\nPremise 4.3: Charlie is smart.\nConclusion 4: Charlie is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Charlie is quiet.\nConclusion 5: Charlie is cold.\n\nPremise 6.1: All quiet things are cold.\nConclusion 6: Charlie is cold.\n\nPremise 7.1: All cold, quiet things are smart.\nPremise 7.2: Charlie is cold.\nPremise 7.3: Charlie is quiet.\nConclusion 7: Charlie is smart.\n\nPremise 8.1: All cold, smart things are kind.\nPremise 8.2: Charlie is cold.\nPremise 8.3: Charlie is smart.\nConclusion 8: Charlie is kind.\n\nPremise 9.1: Kind things are big.\nPremise 9.2: Charlie is kind.\nConclusion 9: Charlie is big.\n\nPremise 10.2: Charlie is kind.\nPremise 10.3: Charlie is big.\nConclusion 10: Charlie is red.\n\n", "ground_truth": [false, true, false, true, true, false, true, true, true, false], "logic_premises": "[[((5∧6)→7), 3], [(4→5), 2], [((5∧6)→7), 3], [((6∧7)→8), 3, 4], [(4→5), 2], [(3→4)], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [0, 1]]", "logic_conclusion": "[4, 3, 4, 5, 3, 2, 5, 5, 3, 2]", "correspondance": [{"0": "X is big .", "1": "X is smart .", "2": "X is cold .", "3": "Charlie is smart .", "4": "Charlie is cold .", "5": "Charlie is big .", "6": "Charlie is smart .", "7": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is a cold thing .", "6": "Charlie is a quiet thing .", "7": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is quiet .", "3": "Charlie is cold .", "4": "Charlie is a quiet thing .", "5": "Charlie is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Charlie is cold .", "3": "Charlie is a quiet thing .", "4": "Charlie is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Charlie is cold .", "4": "Charlie is quiet .", "5": "Charlie is smart .", "6": "Charlie is a cold thing .", "7": "Charlie is a quiet thing .", "8": "Charlie is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Charlie is cold .", "4": "Charlie is smart .", "5": "Charlie is kind .", "6": "Charlie is a cold thing .", "7": "Charlie is a smart thing .", "8": "Charlie is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Charlie is kind .", "3": "Charlie is big .", "4": "Charlie is a Kind thing .", "5": "Charlie is big ."}, {"0": "Charlie is kind .", "1": "Charlie is big .", "2": "Charlie is red ."}], "errors": [[]], "entailments_dict": [{"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}, {"3": ["5"], "7": ["4"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {}], "predicted_steps": [false, true, false, "Contradiction in the premises", true, false, true, "Contradiction in the premises", true, false]}
{"id": "139", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is big?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: Kind things are big.\nPremise 1.2: Erin is kind.\nConclusion 1: Erin is big.\n\n", "ground_truth": [true], "logic_premises": "[[(4→5), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X is a Kind thing .", "1": "X is big .", "2": "Erin is kind .", "3": "Erin is big .", "4": "Erin is a Kind thing .", "5": "Erin is big ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}], "predicted_steps": [true]}
{"id": "140", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is not cold?", "ground truth": "No", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Fiona is quiet.\nConclusion 1: Fiona is cold.\n\n", "ground_truth": [true], "logic_premises": "[[(4→5), 2]]", "logic_conclusion": "[3]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}], "predicted_steps": [true]}
{"id": "141", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is smart?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Fiona is quiet.\nConclusion 1: Fiona is cold.\n\nPremise 2.1: All cold, quiet things are smart.\nPremise 2.2: Fiona is cold.\nPremise 2.3: Fiona is quiet.\nConclusion 2: Fiona is smart.\n\n", "ground_truth": [true, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is cold .", "4": "Fiona is quiet .", "5": "Fiona is smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is smart ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, true]}
{"id": "142", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Harry is not red?", "ground truth": "No", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: Kind things are big.\nPremise 1.2: Harry is kind.\nConclusion 1: Harry is big.\n\nPremise 2.2: Harry is kind.\nPremise 2.3: Harry is big.\nConclusion 2: Harry is red.\n\n", "ground_truth": [true, false], "logic_premises": "[[(4→5), 2], [0, 1]]", "logic_conclusion": "[3, 2]", "correspondance": [{"0": "X is a Kind thing .", "1": "X is big .", "2": "Harry is kind .", "3": "Harry is big .", "4": "Harry is a Kind thing .", "5": "Harry is big ."}, {"0": "Harry is kind .", "1": "Harry is big .", "2": "Harry is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {}], "predicted_steps": [true, false]}
{"id": "143", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is kind?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nConclusion 1: Fiona is cold.\n\nPremise 2.1: All quiet things are cold.\nConclusion 2: Fiona is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Fiona is cold.\nPremise 3.3: Fiona is quiet.\nConclusion 3: Fiona is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Fiona is cold.\nPremise 4.3: Fiona is smart.\nConclusion 4: Fiona is kind.\n\n", "ground_truth": [false, false, true, true], "logic_premises": "[[(3→4)], [(3→4)], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[2, 2, 5, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is cold .", "3": "Fiona is a quiet thing .", "4": "Fiona is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is cold .", "3": "Fiona is a quiet thing .", "4": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is cold .", "4": "Fiona is quiet .", "5": "Fiona is smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Fiona is cold .", "4": "Fiona is smart .", "5": "Fiona is kind .", "6": "Fiona is a cold thing .", "7": "Fiona is a smart thing .", "8": "Fiona is kind ."}], "errors": [[]], "entailments_dict": [{"4": ["2"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}], "predicted_steps": [false, false, true, "Contradiction in the premises"]}
{"id": "144", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Erin is not cold?", "ground truth": "No", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: Kind things are big.\nPremise 1.2: Erin is kind.\nConclusion 1: Erin is big.\n\nPremise 2.1: Kind, big things are red.\nPremise 2.2: Erin is kind.\nPremise 2.3: Erin is big.\nConclusion 2: Erin is red.\n\nPremise 3.1: All red things are cold.\nPremise 3.2: Erin is red.\nConclusion 3: Erin is cold.\n\n", "ground_truth": [true, true, true], "logic_premises": "[[(4→5), 2], [((6∧7)→8), 3, 4], [(4→5), 2]]", "logic_conclusion": "[3, 5, 3]", "correspondance": [{"0": "X is a Kind thing .", "1": "X is big .", "2": "Erin is kind .", "3": "Erin is big .", "4": "Erin is a Kind thing .", "5": "Erin is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Erin is kind .", "4": "Erin is big .", "5": "Erin is red .", "6": "Erin is a Kind thing .", "7": "Erin is a big thing .", "8": "Erin is red ."}, {"0": "X is a red thing .", "1": "X is cold .", "2": "Erin is red .", "3": "Erin is cold .", "4": "Erin is a red thing .", "5": "Erin is cold ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [true, true, true]}
{"id": "145", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is big?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Fiona is quiet.\nConclusion 1: Fiona is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Fiona is quiet.\nConclusion 2: Fiona is cold.\n\nPremise 3.2: Fiona is cold.\nPremise 3.3: Fiona is quiet.\nConclusion 3: Fiona is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Fiona is cold.\nConclusion 4: Fiona is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Fiona is kind.\nConclusion 5: Fiona is big.\n\n", "ground_truth": [false, true, false, false, true], "logic_premises": "[[0], [(4→5), 2], [0, 1], [((5∧6)→7), 3], [(4→5), 2]]", "logic_conclusion": "[1, 3, 2, 4, 3]", "correspondance": [{"0": "Fiona is quiet .", "1": "Fiona is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "Fiona is cold .", "1": "Fiona is quiet .", "2": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Fiona is cold .", "4": "Fiona is kind .", "5": "Fiona is a cold thing .", "6": "Fiona is a smart thing .", "7": "Fiona is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Fiona is kind .", "3": "Fiona is big .", "4": "Fiona is a Kind thing .", "5": "Fiona is big ."}], "errors": [[]], "entailments_dict": [{}, {"2": ["4"], "5": ["3"]}, {}, {"3": ["5", "(¬7)"], "7": ["4", "(¬3)"], "4": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [false, true, false, false, true]}
{"id": "146", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is not big?", "ground truth": "No", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.2: Fiona is quiet.\nConclusion 1: Fiona is cold.\n\nPremise 2.2: Fiona is quiet.\nConclusion 2: Fiona is cold.\n\nPremise 3.2: Fiona is cold.\nPremise 3.3: Fiona is quiet.\nConclusion 3: Fiona is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.3: Fiona is smart.\nConclusion 4: Fiona is kind.\n\nPremise 5.1: Kind things are big.\nPremise 5.2: Fiona is kind.\nConclusion 5: Fiona is big.\n\n", "ground_truth": [false, false, false, false, true], "logic_premises": "[[0], [0], [0, 1], [((5∧6)→7), 3], [(4→5), 2]]", "logic_conclusion": "[1, 1, 2, 4, 3]", "correspondance": [{"0": "Fiona is quiet .", "1": "Fiona is cold ."}, {"0": "Fiona is quiet .", "1": "Fiona is cold ."}, {"0": "Fiona is cold .", "1": "Fiona is quiet .", "2": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Fiona is smart .", "4": "Fiona is kind .", "5": "Fiona is a cold thing .", "6": "Fiona is a smart thing .", "7": "Fiona is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Fiona is kind .", "3": "Fiona is big .", "4": "Fiona is a Kind thing .", "5": "Fiona is big ."}], "errors": [[]], "entailments_dict": [{}, {}, {}, {"3": ["6"], "7": ["4"]}, {"2": ["4"], "5": ["3"]}], "predicted_steps": [false, false, false, false, true]}
{"id": "147", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is red?", "ground truth": "Yes", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Fiona is quiet.\nConclusion 1: Fiona is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Fiona is quiet.\nConclusion 2: Fiona is cold.\n\nPremise 3.1: All cold, quiet things are smart.\nPremise 3.2: Fiona is cold.\nPremise 3.3: Fiona is quiet.\nConclusion 3: Fiona is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Fiona is cold.\nPremise 4.3: Fiona is smart.\nConclusion 4: Fiona is kind.\n\nPremise 5.1: All quiet things are cold.\nPremise 5.2: Fiona is quiet.\nConclusion 5: Fiona is cold.\n\nPremise 6.1: All quiet things are cold.\nPremise 6.2: Fiona is quiet.\nConclusion 6: Fiona is cold.\n\nPremise 7.1: All cold, quiet things are smart.\nPremise 7.3: Fiona is quiet.\nConclusion 7: Fiona is smart.\n\nPremise 8.2: Fiona is cold.\nPremise 8.3: Fiona is smart.\nConclusion 8: Fiona is kind.\n\nPremise 9.1: Kind things are big.\nConclusion 9: Fiona is big.\n\nPremise 10.1: Kind, big things are red.\nPremise 10.2: Fiona is kind.\nPremise 10.3: Fiona is big.\nConclusion 10: Fiona is red.\n\n", "ground_truth": [true, true, true, true, true, true, false, false, false, true], "logic_premises": "[[(4→5), 2], [(4→5), 2], [((6∧7)→8), 3, 4], [((6∧7)→8), 3, 4], [(4→5), 2], [(4→5), 2], [((5∧6)→7), 3], [0, 1], [(3→4)], [((6∧7)→8), 3, 4]]", "logic_conclusion": "[3, 3, 5, 5, 3, 3, 4, 2, 2, 5]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is cold .", "4": "Fiona is quiet .", "5": "Fiona is smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Fiona is cold .", "4": "Fiona is smart .", "5": "Fiona is kind .", "6": "Fiona is a cold thing .", "7": "Fiona is a smart thing .", "8": "Fiona is kind ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is quiet .", "4": "Fiona is smart .", "5": "Fiona is a cold thing .", "6": "Fiona is a quiet thing .", "7": "Fiona is smart ."}, {"0": "Fiona is cold .", "1": "Fiona is smart .", "2": "Fiona is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Fiona is big .", "3": "Fiona is a Kind thing .", "4": "Fiona is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Fiona is kind .", "4": "Fiona is big .", "5": "Fiona is red .", "6": "Fiona is a Kind thing .", "7": "Fiona is a big thing .", "8": "Fiona is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {"3": ["6"], "7": ["4"]}, {"2": ["(¬0)"]}, {"4": ["2"]}, {"4": ["7"], "3": ["6"], "8": ["5"]}], "predicted_steps": [true, true, true, "Contradiction in the premises", true, true, false, false, false, true]}
{"id": "148", "options": ["Yes", "No", "Uncertain"], "question": "Is it true that Fiona is not red?", "ground truth": "No", "text": "Charlie is big. Charlie is cold. Charlie is kind. Charlie is quiet. Charlie is red. Charlie is rough. Charlie is smart. Erin is kind. Fiona is quiet. Fiona is rough. Harry is kind. Harry is rough. Kind things are big. All kind, smart things are rough. If something is red and quiet then it is big. All red things are cold. All cold, quiet things are smart. If something is big and smart then it is cold. All quiet things are cold. Kind, big things are red. All cold, smart things are kind.", "reasoning": "Premise 1.1: All quiet things are cold.\nPremise 1.2: Fiona is quiet.\nConclusion 1: Fiona is cold.\n\nPremise 2.1: All quiet things are cold.\nPremise 2.2: Fiona is quiet.\nConclusion 2: Fiona is cold.\n\nPremise 3.2: Fiona is cold.\nPremise 3.3: Fiona is quiet.\nConclusion 3: Fiona is smart.\n\nPremise 4.1: All cold, smart things are kind.\nPremise 4.2: Fiona is cold.\nPremise 4.3: Fiona is smart.\nConclusion 4: Fiona is kind.\n\nPremise 5.2: Fiona is quiet.\nConclusion 5: Fiona is cold.\n\nPremise 6.2: Fiona is quiet.\nConclusion 6: Fiona is cold.\n\nPremise 7.1: All cold, quiet things are smart.\nPremise 7.2: Fiona is cold.\nPremise 7.3: Fiona is quiet.\nConclusion 7: Fiona is smart.\n\nPremise 8.1: All cold, smart things are kind.\nPremise 8.3: Fiona is smart.\nConclusion 8: Fiona is kind.\n\nPremise 9.1: Kind things are big.\nConclusion 9: Fiona is big.\n\nPremise 10.1: Kind, big things are red.\nPremise 10.2: Fiona is kind.\nConclusion 10: Fiona is red.\n\n", "ground_truth": [true, true, false, true, false, false, true, false, false, false], "logic_premises": "[[(4→5), 2], [(4→5), 2], [0, 1], [((6∧7)→8), 3, 4], [0], [0], [((6∧7)→8), 3, 4], [((5∧6)→7), 3], [(3→4)], [((5∧6)→7), 3]]", "logic_conclusion": "[3, 3, 2, 5, 1, 1, 5, 4, 2, 4]", "correspondance": [{"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "X is a quiet thing .", "1": "X is cold .", "2": "Fiona is quiet .", "3": "Fiona is cold .", "4": "Fiona is a quiet thing .", "5": "Fiona is cold ."}, {"0": "Fiona is cold .", "1": "Fiona is quiet .", "2": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Fiona is cold .", "4": "Fiona is smart .", "5": "Fiona is kind .", "6": "Fiona is a cold thing .", "7": "Fiona is a smart thing .", "8": "Fiona is kind ."}, {"0": "Fiona is quiet .", "1": "Fiona is cold ."}, {"0": "Fiona is quiet .", "1": "Fiona is cold ."}, {"0": "X is a cold thing .", "1": "X is a quiet thing .", "2": "X is smart .", "3": "Fiona is cold .", "4": "Fiona is quiet .", "5": "Fiona is smart .", "6": "Fiona is a cold thing .", "7": "Fiona is a quiet thing .", "8": "Fiona is smart ."}, {"0": "X is a cold thing .", "1": "X is a smart thing .", "2": "X is kind .", "3": "Fiona is smart .", "4": "Fiona is kind .", "5": "Fiona is a cold thing .", "6": "Fiona is a smart thing .", "7": "Fiona is kind ."}, {"0": "X is a Kind thing .", "1": "X is big .", "2": "Fiona is big .", "3": "Fiona is a Kind thing .", "4": "Fiona is big ."}, {"0": "X is a Kind thing .", "1": "X is a big thing .", "2": "X is red .", "3": "Fiona is kind .", "4": "Fiona is red .", "5": "Fiona is a Kind thing .", "6": "Fiona is a big thing .", "7": "Fiona is red ."}], "errors": [[]], "entailments_dict": [{"2": ["4"], "5": ["3"]}, {"2": ["4"], "5": ["3"]}, {}, {"4": ["7"], "3": ["6", "(¬8)"], "8": ["5", "(¬3)"], "5": ["(¬3)"]}, {}, {}, {"4": ["7"], "3": ["6"], "8": ["5"]}, {"3": ["6"], "7": ["4"]}, {"4": ["2"]}, {"3": ["5"], "7": ["4"]}], "predicted_steps": [true, true, false, "Contradiction in the premises", false, false, true, false, false, false]}
